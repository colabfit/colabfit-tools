{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "from time import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from functools import partial\n",
    "# from itertools import chain, islice\n",
    "# from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "\n",
    "# from pprint import pprint\n",
    "\n",
    "import dateutil.parser\n",
    "import findspark\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import pyspark.sql.functions as sf\n",
    "from ase.atoms import Atoms\n",
    "from ase.io.cfg import read_cfg\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    BooleanType,\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    ")\n",
    "from colabfit.tools.schema import (\n",
    "    property_object_schema,\n",
    "    config_df_schema,\n",
    "    config_schema,\n",
    "    property_object_df_schema,\n",
    ")\n",
    "from colabfit.tools.configuration import AtomicConfiguration, config_schema\n",
    "from colabfit.tools.database import DataManager, PGDataLoader\n",
    "from colabfit.tools.dataset import Dataset, dataset_schema\n",
    "from colabfit.tools.property import Property, property_object_schema\n",
    "from colabfit.tools.property_definitions import (\n",
    "    atomic_forces_pd,\n",
    "    cauchy_stress_pd,\n",
    "    potential_energy_pd,\n",
    ")\n",
    "from colabfit.tools.schema import configuration_set_schema\n",
    "import pyarrow as pa\n",
    "\n",
    "with open(\"formation_energy.json\", \"r\") as f:\n",
    "    formation_energy_pd = json.load(f)\n",
    "findspark.init()\n",
    "format = \"jdbc\"\n",
    "load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up MTPU and Carolina Materials readers and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTPU data\n",
    "\n",
    "\n",
    "def convert_stress(keys, stress):\n",
    "    stresses = {k: s for k, s in zip(keys, stress)}\n",
    "    return [\n",
    "        [stresses[\"xx\"], stresses[\"xy\"], stresses[\"xz\"]],\n",
    "        [stresses[\"xy\"], stresses[\"yy\"], stresses[\"yz\"]],\n",
    "        [stresses[\"xz\"], stresses[\"yz\"], stresses[\"zz\"]],\n",
    "    ]\n",
    "\n",
    "\n",
    "SYMBOL_DICT = {\"0\": \"Si\", \"1\": \"O\"}\n",
    "\n",
    "\n",
    "def mtpu_reader(filepath):\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        energy = None\n",
    "        forces = None\n",
    "        coords = []\n",
    "        cell = []\n",
    "        symbols = []\n",
    "        config_count = 0\n",
    "        info = dict()\n",
    "        for line in f:\n",
    "            if line.strip().startswith(\"Size\"):\n",
    "                size = int(f.readline().strip())\n",
    "            elif line.strip().lower().startswith(\"supercell\"):\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "            elif line.strip().startswith(\"Energy\"):\n",
    "                energy = float(f.readline().strip())\n",
    "            elif line.strip().startswith(\"PlusStress\"):\n",
    "                stress_keys = line.strip().split()[-6:]\n",
    "                stress = [float(x) for x in f.readline().strip().split()]\n",
    "                stress = convert_stress(stress_keys, stress)\n",
    "            elif line.strip().startswith(\"AtomData:\"):\n",
    "                keys = line.strip().split()[1:]\n",
    "                if \"fx\" in keys:\n",
    "                    forces = []\n",
    "                for i in range(size):\n",
    "                    li = {\n",
    "                        key: val for key, val in zip(keys, f.readline().strip().split())\n",
    "                    }\n",
    "                    symbols.append(SYMBOL_DICT[li[\"type\"]])\n",
    "                    if \"cartes_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"cartes_x\"],\n",
    "                                    li[\"cartes_y\"],\n",
    "                                    li[\"cartes_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "                    elif \"direct_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"direct_x\"],\n",
    "                                    li[\"direct_y\"],\n",
    "                                    li[\"direct_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                    if \"fx\" in keys:\n",
    "                        forces.append(\n",
    "                            [float(f) for f in [li[\"fx\"], li[\"fy\"], li[\"fz\"]]]\n",
    "                        )\n",
    "\n",
    "            elif line.startswith(\"END_CFG\"):\n",
    "\n",
    "                info[\"energy\"] = energy\n",
    "                if forces:\n",
    "                    info[\"forces\"] = forces\n",
    "                info[\"stress\"] = stress\n",
    "\n",
    "                if \"Si\" in symbols and \"O\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"11x11x11\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_SiO2_{config_count}\"\n",
    "                elif \"Si\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"8x8x8\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 884,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_Si_{config_count}\"\n",
    "                elif \"O\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"gamma-point\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_O_{config_count}\"\n",
    "                if \"cartes_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        positions=coords, symbols=symbols, cell=cell, info=info\n",
    "                    )\n",
    "                elif \"direct_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        scaled_positions=coords, symbols=symbols, cell=cell, info=info\n",
    "                    )\n",
    "                config_count += 1\n",
    "                yield config\n",
    "                forces = None\n",
    "                stress = []\n",
    "                coords = []\n",
    "                cell = []\n",
    "                symbols = []\n",
    "                energy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "data = list(mtpu_configs)\n",
    "# data = [x for x in mtpu_configs]\n",
    "# data[0].configuration_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colabfit.tools.configuration\n",
    "from importlib import reload\n",
    "\n",
    "reload(colabfit.tools.configuration)\n",
    "AtomicConfiguration = colabfit.tools.configuration.AtomicConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carolina Materials data\n",
    "\n",
    "SOFTWARE = \"VASP\"\n",
    "METHODS = \"DFT-PBE\"\n",
    "CM_PI_METADATA = {\n",
    "    \"software\": {\"value\": SOFTWARE},\n",
    "    \"method\": {\"value\": METHODS},\n",
    "    \"input\": {\"value\": {\"IBRION\": 6, \"NFREE\": 4}},\n",
    "}\n",
    "\n",
    "CM_PROPERTY_MAP = {\n",
    "    \"formation-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": CM_PI_METADATA,\n",
    "}\n",
    "CO_MD = {\n",
    "    key: {\"field\": key}\n",
    "    for key in [\n",
    "        \"_symmetry_space_group_name_H-M\",\n",
    "        \"_symmetry_Int_Tables_number\",\n",
    "        \"_chemical_formula_structural\",\n",
    "        \"_chemical_formula_sum\",\n",
    "        \"_cell_volume\",\n",
    "        \"_cell_formula_units_Z\",\n",
    "        \"symmetry_dict\",\n",
    "        \"formula_pretty\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def load_row(txn, row):\n",
    "    try:\n",
    "        data = pickle.loads(txn.get(f\"{row}\".encode(\"ascii\")))\n",
    "        return data\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def config_from_row(row: dict, row_num: int):\n",
    "    coords = row.pop(\"cart_coords\")\n",
    "    a_num = row.pop(\"atomic_numbers\")\n",
    "    cell = [\n",
    "        row.pop(x)\n",
    "        for x in [\n",
    "            \"_cell_length_a\",\n",
    "            \"_cell_length_b\",\n",
    "            \"_cell_length_c\",\n",
    "            \"_cell_angle_alpha\",\n",
    "            \"_cell_angle_beta\",\n",
    "            \"_cell_angle_gamma\",\n",
    "        ]\n",
    "    ]\n",
    "    symmetry_dict = {str(key): val for key, val in row.pop(\"symmetry_dict\").items()}\n",
    "    for key in symmetry_dict:\n",
    "        key = str(key)\n",
    "    info = {}\n",
    "    info = row\n",
    "    info[\"symmetry_dict\"] = symmetry_dict\n",
    "    info[\"_name\"] = f\"carolina_materials_{row_num}\"\n",
    "    if row_num % 10 == 0:\n",
    "        info[\"_labels\"] = [row_num % 10, \"bcc\"]\n",
    "    else:\n",
    "        info[\"_labels\"] = [row_num % 10, \"fcc\"]\n",
    "    config = AtomicConfiguration(\n",
    "        scaled_positions=coords,\n",
    "        numbers=a_num,\n",
    "        cell=cell,\n",
    "        info=info,\n",
    "    )\n",
    "    return config\n",
    "    # return AtomicConfiguration.from_ase(config)\n",
    "\n",
    "\n",
    "def carmat_reader(fp: Path):\n",
    "    parent = fp.parent\n",
    "    env = lmdb.open(str(parent))\n",
    "    txn = env.begin()\n",
    "    row_num = 0\n",
    "    rows = []\n",
    "    while row_num <= 100000:\n",
    "        row = load_row(txn, row_num)\n",
    "        if row is False:\n",
    "            env.close()\n",
    "            break\n",
    "        rows.append(row)\n",
    "        yield config_from_row(row, row_num)\n",
    "        row_num += 1\n",
    "    env.close()\n",
    "    return False\n",
    "    # return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"Quantum ESPRESSO\"},\n",
    "    \"method\": {\"value\": \"DFT-PBE\"},\n",
    "    \"input\": {\"field\": \"input\"},\n",
    "}\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "    \"cauchy-stress\": [\n",
    "        {\n",
    "            \"stress\": {\"field\": \"stress\", \"units\": \"GPa\"},\n",
    "            \"volume-normalized\": {\"value\": True, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": PI_METADATA,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB and run loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 14:49:53 WARN Utils: Your hostname, arktos resolves to a loopback address: 127.0.1.1; using 172.24.21.25 instead (on interface enp5s0)\n",
      "24/05/21 14:49:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/05/21 14:49:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 14:49:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 17:14:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtomicConfiguration(name=Unified_training_set_SiO2_1061, symbols='Si4', pbc=False, cell=[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1062/1062 [00:00<00:00, 2495.36it/s]\n"
     ]
    }
   ],
   "source": [
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "\n",
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"Quantum ESPRESSO\"},\n",
    "    \"method\": {\"value\": \"DFT-PBE\"},\n",
    "    \"input\": {\"field\": \"input\"},\n",
    "}\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "    \"cauchy-stress\": [\n",
    "        {\n",
    "            \"stress\": {\"field\": \"stress\", \"units\": \"GPa\"},\n",
    "            \"volume-normalized\": {\"value\": True, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": PI_METADATA,\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"ColabfitIngestData\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "# loader = SparkDataLoader(table_prefix=\"ndb.colabfit.dev\")\n",
    "# print(loader.spark)\n",
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "mtpu_configs = list(mtpu_configs)\n",
    "print(mtpu_configs[0])\n",
    "co_po_rows = []\n",
    "for config in tqdm(mtpu_configs):\n",
    "    config.set_dataset_id(mtpu_ds_id)\n",
    "    co_po_rows.append(\n",
    "        (\n",
    "            config.spark_row,\n",
    "            Property.from_definition(\n",
    "                [potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "                configuration=config,\n",
    "                property_map=PROPERTY_MAP,\n",
    "            ).spark_row,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "author: Gregory Wolfe\n",
    "\n",
    "Properties\n",
    "----------\n",
    "potential energy\n",
    "\n",
    "Other properties added to metadata\n",
    "----------------------------------\n",
    "dipole, original scf energy without the energy correction subtracted\n",
    "\n",
    "File notes\n",
    "----------\n",
    "columns from txt files: system_id,frame_number,reference_energy\n",
    "\n",
    "header from extxyz files:\n",
    "Lattice=\"\"\n",
    "Properties=species:S:1:pos:R:3:move_mask:L:1:tags:I:1:forces:R:3\n",
    "energy=-181.54722937\n",
    "free_energy=-181.54878652\n",
    "pbc=\"T T T\"\n",
    "\n",
    "get:\n",
    "config.constraints\n",
    "config.arrays (tags, forces)\n",
    "config.info (energy, free_energy)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from ase.io import iread\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from colabfit.tools.configuration import AtomicConfiguration\n",
    "from colabfit.tools.database import DataManager, SparkDataLoader\n",
    "from colabfit.tools.property_definitions import (\n",
    "    atomic_forces_pd,\n",
    "    free_energy_pd,\n",
    "    potential_energy_pd,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "loader = SparkDataLoader(table_prefix=\"ndb.colabfit.dev\")\n",
    "access_key = os.getenv(\"SPARK_ID\")\n",
    "access_secret = os.getenv(\"SPARK_KEY\")\n",
    "endpoint = os.getenv(\"SPARK_ENDPOINT\")\n",
    "# loader.set_vastdb_session(\n",
    "PKL_FP = Path(\"data/oc20_data_mapping.pkl\")\n",
    "with open(PKL_FP, \"rb\") as f:\n",
    "    OC20_MAP = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     endpoint=endpoint, access_key=access_key, access_secret=access_secret\n",
    "# )\n",
    "\n",
    "DATASET_FP = Path(\"data/s2ef_train_200K/s2ef_train_200K\")\n",
    "DATASET_NAME = \"OC20_S2EF_train_200K\"\n",
    "LICENSE = \"https://creativecommons.org/licenses/by/4.0/legalcode\"\n",
    "PUBLICATION = \"https://doi.org/10.1021/acscatal.0c04525\"\n",
    "DATA_LINK = (\n",
    "    \"https://github.com/Open-Catalyst-Project/ocp/blob\"\n",
    "    \"/main/DATASET.md#open-catalyst-2020-oc20\"\n",
    ")\n",
    "AUTHORS = [\n",
    "    \"Lowik Chanussot\",\n",
    "    \"Abhishek Das\",\n",
    "    \"Siddharth Goyal\",\n",
    "    \"Thibaut Lavril\",\n",
    "    \"Muhammed Shuaibi\",\n",
    "    \"Morgane Riviere\",\n",
    "    \"Kevin Tran\",\n",
    "    \"Javier Heras-Domingo\",\n",
    "    \"Caleb Ho\",\n",
    "    \"Weihua Hu\",\n",
    "    \"Aini Palizhati\",\n",
    "    \"Anuroop Sriram\",\n",
    "    \"Brandon Wood\",\n",
    "    \"Junwoong Yoon\",\n",
    "    \"Devi Parikh\",\n",
    "    \"C. Lawrence Zitnick\",\n",
    "    \"Zachary Ulissi\",\n",
    "]\n",
    "DATASET_DESC = (\n",
    "    \"OC20_S2EF_train_200K is the 200K subset of the OC20 Structure to Energy and \"\n",
    "    \"Forces dataset. \"\n",
    ")\n",
    "ELEMENTS = None\n",
    "\n",
    "\n",
    "GLOB_STR = \"*.extxyz\"\n",
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"VASP\"},\n",
    "    \"method\": {\"value\": \"DFT-rPBE\"},\n",
    "    \"basis_set\": {\"value\": \"def2-TZVPP\"},\n",
    "    \"input\": {\n",
    "        \"value\": {\n",
    "            \"EDIFFG\": \"1E-3\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"reference-energy\": {\"field\": \"reference_energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"free-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "CO_METADATA = {\n",
    "    key: {\"field\": key}\n",
    "    for key in [\n",
    "        \"constraints\",\n",
    "        \"bulk_id\",\n",
    "        \"ads_id\",\n",
    "        \"bulk_mpid\",\n",
    "        \"bulk_symbols\",\n",
    "        \"ads_symbols\",\n",
    "        \"miller_index\",\n",
    "        \"shift\",\n",
    "        \"top\",\n",
    "        \"adsorption_site\",\n",
    "        \"class\",\n",
    "        \"anomaly\",\n",
    "        \"system_id\",\n",
    "        \"frame_number\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def oc_reader(fp: Path):\n",
    "    fp_num = f\"{int(fp.stem)}\"\n",
    "    prop_fp = fp.with_suffix(\".txt\")\n",
    "    with prop_fp.open(\"r\") as prop_f:\n",
    "        prop_lines = [x.strip() for x in prop_f.readlines()]\n",
    "\n",
    "        iter_configs = iread(fp, format=\"extxyz\")\n",
    "        for i, config in tqdm(enumerate(iter_configs)):\n",
    "            system_id, frame_number, reference_energy = prop_lines[i].split(\",\")\n",
    "            reference_energy = float(reference_energy)\n",
    "            config.info[\"constraints-fix-atoms\"] = config.constraints[0].index\n",
    "            config_data = OC20_MAP[system_id]\n",
    "            config.info.update(config_data)\n",
    "            config.info[\"reference_energy\"] = reference_energy\n",
    "            config.info[\"system_id\"] = system_id\n",
    "            config.info[\"frame_number\"] = frame_number\n",
    "            config.info[\"_name\"] = f\"{DATASET_NAME}__file_{fp_num}_config_{i}\"\n",
    "            yield AtomicConfiguration.from_ase(config, CO_METADATA)\n",
    "\n",
    "\n",
    "def oc_wrapper(dir_path: str):\n",
    "    dir_path = Path(dir_path)\n",
    "    if not dir_path.exists():\n",
    "        print(f\"Path {dir_path} does not exist\")\n",
    "        return\n",
    "    xyz_paths = sorted(list(dir_path.rglob(\"*.extxyz\")))\n",
    "    print(xyz_paths)\n",
    "    for xyz_path in xyz_paths:\n",
    "        print(f\"Reading {xyz_path}\")\n",
    "        reader = oc_reader(xyz_path)\n",
    "        for config in reader:\n",
    "            yield config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:20, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "config_generator = oc_wrapper(DATASET_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/s2ef_train_200K/s2ef_train_200K/0.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/1.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/10.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/11.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/12.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/13.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/14.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/15.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/16.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/17.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/18.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/19.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/2.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/20.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/21.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/22.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/23.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/24.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/25.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/26.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/27.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/28.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/29.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/3.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/30.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/31.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/32.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/33.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/34.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/35.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/36.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/37.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/38.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/39.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/4.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/5.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/6.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/7.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/8.extxyz'), PosixPath('data/s2ef_train_200K/s2ef_train_200K/9.extxyz')]\n",
      "Reading data/s2ef_train_200K/s2ef_train_200K/0.extxyz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "c = next(config_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CO_483305315274248878',\n",
       " 'hash': 483305315274248878,\n",
       " 'last_modified': datetime.datetime(2024, 6, 14, 14, 12),\n",
       " 'dataset_ids': None,\n",
       " 'metadata': \"{'ads_id': 47, 'ads_symbols': '*CHCH2OH', 'adsorption_site': ((2.3, 17.76, 15.94),), 'anomaly': 1, 'bulk_id': 9692, 'bulk_mpid': 'mp-1227346', 'bulk_symbols': 'Ca2CuAg', 'class': 0, 'frame_number': 'frame258', 'miller_index': (2, 1, 0), 'shift': 0.197, 'system_id': 'random1331004', 'top': True}\",\n",
       " 'chemical_formula_hill': 'C2H4Ag16Ca32Cu16O',\n",
       " 'chemical_formula_reduced': 'Ag16C2Ca32Cu16H4O',\n",
       " 'chemical_formula_anonymous': 'A32B16C16D4E2F',\n",
       " 'elements': ['Ag', 'C', 'Ca', 'Cu', 'H', 'O'],\n",
       " 'elements_ratios': [0.22535211267605634,\n",
       "  0.028169014084507043,\n",
       "  0.4507042253521127,\n",
       "  0.22535211267605634,\n",
       "  0.056338028169014086,\n",
       "  0.014084507042253521],\n",
       " 'atomic_numbers': array([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 47, 47, 47,\n",
       "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,  6,  6,  1,  1,\n",
       "         1,  1,  8]),\n",
       " 'nsites': 71,\n",
       " 'nelements': 6,\n",
       " 'nperiodic_dimensions': 3,\n",
       " 'cell': array([[ 9.18446134,  0.        ,  0.        ],\n",
       "        [ 0.        , 22.63986204, -4.15391219],\n",
       "        [ 0.        ,  0.        , 29.07738533]]),\n",
       " 'dimension_types': [1, 1, 1],\n",
       " 'pbc': array([ True,  True,  True]),\n",
       " 'positions': array([[0.00000000e+00, 1.59977838e+00, 1.37598341e+01],\n",
       "        [0.00000000e+00, 1.29197094e+01, 9.60592198e+00],\n",
       "        [2.29611534e+00, 4.05467998e+00, 1.16828782e+01],\n",
       "        [2.29611534e+00, 1.53746110e+01, 1.16828781e+01],\n",
       "        [0.00000000e+00, 7.25974389e+00, 1.16828779e+01],\n",
       "        [0.00000000e+00, 1.85796749e+01, 7.52896576e+00],\n",
       "        [2.29611534e+00, 9.71464549e+00, 9.60592194e+00],\n",
       "        [2.29611534e+00, 2.10345765e+01, 9.60592190e+00],\n",
       "        [9.17763995e+00, 1.59095314e+00, 1.76928380e+01],\n",
       "        [0.00000000e+00, 1.29197094e+01, 1.37598341e+01],\n",
       "        [2.29611534e+00, 4.05467998e+00, 1.58367903e+01],\n",
       "        [2.29066491e+00, 1.52837240e+01, 1.56835040e+01],\n",
       "        [9.18348026e+00, 7.34652543e+00, 1.56380827e+01],\n",
       "        [0.00000000e+00, 1.85796749e+01, 1.16828782e+01],\n",
       "        [2.29611534e+00, 9.71464549e+00, 1.37598341e+01],\n",
       "        [2.54997008e+00, 2.09973677e+01, 1.39245556e+01],\n",
       "        [4.59223067e+00, 1.59977838e+00, 1.37598341e+01],\n",
       "        [4.59223067e+00, 1.29197094e+01, 9.60592198e+00],\n",
       "        [6.88834601e+00, 4.05467998e+00, 1.16828782e+01],\n",
       "        [6.88834601e+00, 1.53746110e+01, 1.16828781e+01],\n",
       "        [4.59223067e+00, 7.25974389e+00, 1.16828779e+01],\n",
       "        [4.59223067e+00, 1.85796749e+01, 7.52896576e+00],\n",
       "        [6.88834601e+00, 9.71464549e+00, 9.60592194e+00],\n",
       "        [6.88834601e+00, 2.10345765e+01, 9.60592190e+00],\n",
       "        [4.58193103e+00, 1.46827135e+00, 1.78536554e+01],\n",
       "        [4.59223067e+00, 1.29197094e+01, 1.37598341e+01],\n",
       "        [6.88834601e+00, 4.05467998e+00, 1.58367903e+01],\n",
       "        [6.88545014e+00, 1.52588950e+01, 1.56568226e+01],\n",
       "        [4.59315922e+00, 7.34715006e+00, 1.56364433e+01],\n",
       "        [4.59223067e+00, 1.85796749e+01, 1.16828782e+01],\n",
       "        [6.88834601e+00, 9.71464549e+00, 1.37598341e+01],\n",
       "        [6.61873210e+00, 2.10385505e+01, 1.37841739e+01],\n",
       "        [2.29611534e+00, 7.78434980e-01, 1.16828782e+01],\n",
       "        [2.29611534e+00, 1.20983660e+01, 1.16828781e+01],\n",
       "        [2.29611534e+00, 6.43840049e+00, 9.60592194e+00],\n",
       "        [2.29611534e+00, 1.77583315e+01, 9.60592190e+00],\n",
       "        [2.29611534e+00, 7.78434980e-01, 1.58367903e+01],\n",
       "        [2.29701918e+00, 1.21503507e+01, 1.56275487e+01],\n",
       "        [2.29611534e+00, 6.43840049e+00, 1.37598341e+01],\n",
       "        [2.32833957e+00, 1.78593662e+01, 1.39852975e+01],\n",
       "        [6.88834601e+00, 7.78434980e-01, 1.16828782e+01],\n",
       "        [6.88834601e+00, 1.20983660e+01, 1.16828781e+01],\n",
       "        [6.88834601e+00, 6.43840049e+00, 9.60592194e+00],\n",
       "        [6.88834601e+00, 1.77583315e+01, 9.60592190e+00],\n",
       "        [6.88834601e+00, 7.78434980e-01, 1.58367903e+01],\n",
       "        [6.88928190e+00, 1.21335486e+01, 1.56256148e+01],\n",
       "        [6.88834601e+00, 6.43840049e+00, 1.37598341e+01],\n",
       "        [6.87812517e+00, 1.77172311e+01, 1.36592380e+01],\n",
       "        [0.00000000e+00, 4.88703790e+00, 9.60592198e+00],\n",
       "        [0.00000000e+00, 1.62069689e+01, 9.60592194e+00],\n",
       "        [0.00000000e+00, 1.05470034e+01, 1.16828779e+01],\n",
       "        [0.00000000e+00, 2.18669344e+01, 7.52896572e+00],\n",
       "        [0.00000000e+00, 4.88703790e+00, 1.37598341e+01],\n",
       "        [1.75316700e-02, 1.62383822e+01, 1.38201758e+01],\n",
       "        [6.80367000e-03, 1.06176602e+01, 1.58513687e+01],\n",
       "        [0.00000000e+00, 2.18669344e+01, 1.16828781e+01],\n",
       "        [4.59223067e+00, 4.88703790e+00, 9.60592198e+00],\n",
       "        [4.59223067e+00, 1.62069689e+01, 9.60592194e+00],\n",
       "        [4.59223067e+00, 1.05470034e+01, 1.16828779e+01],\n",
       "        [4.59223067e+00, 2.18669344e+01, 7.52896572e+00],\n",
       "        [4.59223067e+00, 4.88703790e+00, 1.37598341e+01],\n",
       "        [4.57866733e+00, 1.62222062e+01, 1.38296923e+01],\n",
       "        [4.58642150e+00, 1.06173274e+01, 1.58515025e+01],\n",
       "        [4.59223067e+00, 2.18669344e+01, 1.16828781e+01],\n",
       "        [1.30185946e+00, 1.93611430e+01, 1.64378742e+01],\n",
       "        [2.36653517e+00, 1.89932830e+01, 1.56623408e+01],\n",
       "        [1.39650304e+00, 1.97013721e+01, 1.74863291e+01],\n",
       "        [2.68550340e-01, 1.92958342e+01, 1.60637991e+01],\n",
       "        [4.62397042e+00, 2.20464554e+01, 1.58633636e+01],\n",
       "        [3.34254960e+00, 1.90864397e+01, 1.61883295e+01],\n",
       "        [4.61136328e+00, 2.20368842e+01, 1.48823530e+01]]),\n",
       " 'names': {'OC20_S2EF_train_200K__file_0_config_0'},\n",
       " 'labels': None,\n",
       " 'configuration_set_ids': None}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.spark_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = AtomicConfiguration.from_ase(c, co_md_map=CO_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CO_1726117295053382799',\n",
       " 'hash': 1726117295053382799,\n",
       " 'last_modified': datetime.datetime(2024, 6, 14, 14, 5, 22),\n",
       " 'dataset_ids': None,\n",
       " 'metadata': \"{'ads_id': 1, 'ads_symbols': '*H', 'adsorption_site': ((7.82, 4.14, 29.21),), 'anomaly': 0, 'bulk_id': 6865, 'bulk_mpid': 'mp-541877', 'bulk_symbols': 'Te2Ta2Cl18', 'class': 3, 'frame_number': 'frame25', 'miller_index': (1, 0, 1), 'shift': 0.196, 'system_id': 'random498840', 'top': True}\",\n",
       " 'chemical_formula_hill': 'HCl36Ta4Te4',\n",
       " 'chemical_formula_reduced': 'Cl36HTa4Te4',\n",
       " 'chemical_formula_anonymous': 'A36B4C4D',\n",
       " 'elements': ['Cl', 'H', 'Ta', 'Te'],\n",
       " 'elements_ratios': [0.8,\n",
       "  0.022222222222222223,\n",
       "  0.08888888888888889,\n",
       "  0.08888888888888889],\n",
       " 'atomic_numbers': array([73, 73, 73, 73, 52, 52, 52, 52, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17,  1]),\n",
       " 'nsites': 45,\n",
       " 'nelements': 4,\n",
       " 'nperiodic_dimensions': 3,\n",
       " 'cell': array([[ 9.36696406,  0.        , -2.81254709],\n",
       "        [-0.93948514, 12.8372956 ,  7.99992296],\n",
       "        [ 0.        ,  0.        , 47.80884068]]),\n",
       " 'dimension_types': [1, 1, 1],\n",
       " 'pbc': array([ True,  True,  True]),\n",
       " 'positions': array([[ 6.21305914,  9.16594357, 26.01028686],\n",
       "        [ 6.15381   ,  2.2993255 , 27.66736495],\n",
       "        [ 2.21441978,  3.67135203, 22.09638903],\n",
       "        [ 1.74467721, 10.08999983, 32.0724556 ],\n",
       "        [ 6.15014849,  0.8415113 , 23.33626979],\n",
       "        [ 5.68040592,  7.2601591 , 21.36012619],\n",
       "        [ 2.27733043, 11.9957843 , 24.7704061 ],\n",
       "        [ 2.747073  ,  5.5771365 , 26.74654971],\n",
       "        [ 6.7943514 ,  2.29599743, 18.30873144],\n",
       "        [ 6.32460883,  8.71464523, 28.284798  ],\n",
       "        [ 1.63312752, 10.54129817, 29.79794494],\n",
       "        [ 2.10287009,  4.12265037, 19.82187837],\n",
       "        [ 3.91800801, 10.05031166, 26.38742687],\n",
       "        [ 4.38775058,  3.63166386, 28.36357047],\n",
       "        [ 4.50947091,  2.78698394, 21.71924903],\n",
       "        [ 4.03972834,  9.20563174, 31.69531559],\n",
       "        [ 8.30918928,  1.98887977, 28.17807152],\n",
       "        [ 8.25605904,  8.17631876, 25.53512929],\n",
       "        [-0.29832269, 11.07962464, 32.54761317],\n",
       "        [ 0.17141988,  4.66097684, 22.57154661],\n",
       "        [ 5.297902  ,  0.24514344, 27.98070335],\n",
       "        [ 5.12225509,  6.94243526, 25.64945919],\n",
       "        [ 2.83548126, 12.31350814, 32.43328375],\n",
       "        [ 3.30522383,  5.89486034, 22.45721719],\n",
       "        [ 5.79226352,  9.50007321, 23.60541189],\n",
       "        [ 6.26200609,  3.08142541, 25.58155549],\n",
       "        [ 2.6352154 ,  3.33722239, 24.50126449],\n",
       "        [ 2.19370593,  9.81969016, 34.3742255 ],\n",
       "        [ 7.08172445, 11.30703374, 26.16383101],\n",
       "        [ 7.52405503,  4.93162477, 28.40214949],\n",
       "        [ 1.34575447,  1.53026186, 21.94284488],\n",
       "        [ 0.8760119 ,  7.94890966, 31.91891145],\n",
       "        [ 7.01626682,  5.78390656, 22.63270923],\n",
       "        [ 6.52948004, 12.24935824, 32.65678697],\n",
       "        [ 1.4112121 ,  7.05338904, 25.47396667],\n",
       "        [ 1.94378777,  0.71786979, 27.66611888],\n",
       "        [ 5.0453018 , 12.27263136, 29.4575194 ],\n",
       "        [ 6.07654382,  6.23740406, 31.6352886 ],\n",
       "        [ 3.38217712,  0.56466424, 18.64915649],\n",
       "        [ 2.91243455,  6.98331204, 28.62522306],\n",
       "        [ 8.01689817,  2.01902007, 22.45604686],\n",
       "        [ 7.17399587,  7.76722483, 32.24372429],\n",
       "        [ 0.41058075, 10.81827553, 25.65062904],\n",
       "        [ 0.88032332,  4.39962773, 27.62677264],\n",
       "        [ 8.11829871,  4.71271743, 29.5265795 ]]),\n",
       " 'names': {'OC20_S2EF_train_200K__file_000_config_5'},\n",
       " 'labels': None,\n",
       " 'configuration_set_ids': None}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.spark_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CO_1726117295053382799',\n",
       " 'hash': 1726117295053382799,\n",
       " 'last_modified': datetime.datetime(2024, 6, 14, 14, 5, 22),\n",
       " 'dataset_ids': None,\n",
       " 'metadata': \"{'ads_id': 1, 'ads_symbols': '*H', 'adsorption_site': ((7.82, 4.14, 29.21),), 'anomaly': 0, 'bulk_id': 6865, 'bulk_mpid': 'mp-541877', 'bulk_symbols': 'Te2Ta2Cl18', 'class': 3, 'frame_number': 'frame25', 'miller_index': (1, 0, 1), 'shift': 0.196, 'system_id': 'random498840', 'top': True}\",\n",
       " 'chemical_formula_hill': 'HCl36Ta4Te4',\n",
       " 'chemical_formula_reduced': 'Cl36HTa4Te4',\n",
       " 'chemical_formula_anonymous': 'A36B4C4D',\n",
       " 'elements': ['Cl', 'H', 'Ta', 'Te'],\n",
       " 'elements_ratios': [0.8,\n",
       "  0.022222222222222223,\n",
       "  0.08888888888888889,\n",
       "  0.08888888888888889],\n",
       " 'atomic_numbers': array([73, 73, 73, 73, 52, 52, 52, 52, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17,  1]),\n",
       " 'nsites': 45,\n",
       " 'nelements': 4,\n",
       " 'nperiodic_dimensions': 3,\n",
       " 'cell': array([[ 9.36696406,  0.        , -2.81254709],\n",
       "        [-0.93948514, 12.8372956 ,  7.99992296],\n",
       "        [ 0.        ,  0.        , 47.80884068]]),\n",
       " 'dimension_types': [1, 1, 1],\n",
       " 'pbc': array([ True,  True,  True]),\n",
       " 'positions': array([[ 6.21305914,  9.16594357, 26.01028686],\n",
       "        [ 6.15381   ,  2.2993255 , 27.66736495],\n",
       "        [ 2.21441978,  3.67135203, 22.09638903],\n",
       "        [ 1.74467721, 10.08999983, 32.0724556 ],\n",
       "        [ 6.15014849,  0.8415113 , 23.33626979],\n",
       "        [ 5.68040592,  7.2601591 , 21.36012619],\n",
       "        [ 2.27733043, 11.9957843 , 24.7704061 ],\n",
       "        [ 2.747073  ,  5.5771365 , 26.74654971],\n",
       "        [ 6.7943514 ,  2.29599743, 18.30873144],\n",
       "        [ 6.32460883,  8.71464523, 28.284798  ],\n",
       "        [ 1.63312752, 10.54129817, 29.79794494],\n",
       "        [ 2.10287009,  4.12265037, 19.82187837],\n",
       "        [ 3.91800801, 10.05031166, 26.38742687],\n",
       "        [ 4.38775058,  3.63166386, 28.36357047],\n",
       "        [ 4.50947091,  2.78698394, 21.71924903],\n",
       "        [ 4.03972834,  9.20563174, 31.69531559],\n",
       "        [ 8.30918928,  1.98887977, 28.17807152],\n",
       "        [ 8.25605904,  8.17631876, 25.53512929],\n",
       "        [-0.29832269, 11.07962464, 32.54761317],\n",
       "        [ 0.17141988,  4.66097684, 22.57154661],\n",
       "        [ 5.297902  ,  0.24514344, 27.98070335],\n",
       "        [ 5.12225509,  6.94243526, 25.64945919],\n",
       "        [ 2.83548126, 12.31350814, 32.43328375],\n",
       "        [ 3.30522383,  5.89486034, 22.45721719],\n",
       "        [ 5.79226352,  9.50007321, 23.60541189],\n",
       "        [ 6.26200609,  3.08142541, 25.58155549],\n",
       "        [ 2.6352154 ,  3.33722239, 24.50126449],\n",
       "        [ 2.19370593,  9.81969016, 34.3742255 ],\n",
       "        [ 7.08172445, 11.30703374, 26.16383101],\n",
       "        [ 7.52405503,  4.93162477, 28.40214949],\n",
       "        [ 1.34575447,  1.53026186, 21.94284488],\n",
       "        [ 0.8760119 ,  7.94890966, 31.91891145],\n",
       "        [ 7.01626682,  5.78390656, 22.63270923],\n",
       "        [ 6.52948004, 12.24935824, 32.65678697],\n",
       "        [ 1.4112121 ,  7.05338904, 25.47396667],\n",
       "        [ 1.94378777,  0.71786979, 27.66611888],\n",
       "        [ 5.0453018 , 12.27263136, 29.4575194 ],\n",
       "        [ 6.07654382,  6.23740406, 31.6352886 ],\n",
       "        [ 3.38217712,  0.56466424, 18.64915649],\n",
       "        [ 2.91243455,  6.98331204, 28.62522306],\n",
       "        [ 8.01689817,  2.01902007, 22.45604686],\n",
       "        [ 7.17399587,  7.76722483, 32.24372429],\n",
       "        [ 0.41058075, 10.81827553, 25.65062904],\n",
       "        [ 0.88032332,  4.39962773, 27.62677264],\n",
       "        [ 8.11829871,  4.71271743, 29.5265795 ]]),\n",
       " 'names': {'OC20_S2EF_train_200K__file_000_config_5'},\n",
       " 'labels': None,\n",
       " 'configuration_set_ids': None}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.spark_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy': -873.69215716,\n",
       " 'free_energy': -873.71432778,\n",
       " 'constraints-fix-atoms': array([ 0,  2,  3,  5,  6,  8,  9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24,\n",
       "        26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45, 47, 48, 49,\n",
       "        52, 53, 55, 56, 57, 59, 60, 61, 64, 65, 67, 68, 69, 71, 72, 73, 76,\n",
       "        77, 79, 80, 81, 83, 84, 85, 88, 89, 91, 92, 93, 95]),\n",
       " 'bulk_id': 4510,\n",
       " 'ads_id': 38,\n",
       " 'bulk_mpid': 'mp-865717',\n",
       " 'bulk_symbols': 'Ti2ReIr',\n",
       " 'ads_symbols': '*CHCHOH',\n",
       " 'miller_index': (2, 1, 0),\n",
       " 'shift': 0.042,\n",
       " 'top': True,\n",
       " 'adsorption_site': ((0.0, 6.3, 21.58),),\n",
       " 'class': 0,\n",
       " 'anomaly': 0,\n",
       " 'reference_energy': -870.66148676,\n",
       " 'system_id': 'random2256251',\n",
       " 'frame_number': 'frame158',\n",
       " '_name': 'OC20_S2EF_train_200K__file_000_config_2'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtomicConfiguration(symbols='C2H3Ir24ORe24Ti48', pbc=True, cell=[[12.46844256, 0.0, -0.0], [-6.23422128, 13.89198995, -1.15766583], [0.0, 0.0, 33.57230904]], tags=...)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AtomicConfiguration(co_md_map=CO_METADATA, info=info, **cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import colabfit.tools.configuration\n",
    "\n",
    "reload(colabfit.tools.configuration)\n",
    "AtomicConfiguration = colabfit.tools.configuration.AtomicConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy': -545.14891475,\n",
       " 'free_energy': -545.14411776,\n",
       " 'constraints-fix-atoms': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 11, 15, 16, 17, 18, 19, 20, 21,\n",
       "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 41,\n",
       "        47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
       "        64, 65, 66, 67, 68, 69, 70, 71, 73, 80, 81, 82, 83, 84, 86, 88, 90,\n",
       "        92, 94]),\n",
       " 'bulk_id': 4754,\n",
       " 'ads_id': 10,\n",
       " 'bulk_mpid': 'mp-14433',\n",
       " 'bulk_symbols': 'N6Na2Ge4',\n",
       " 'ads_symbols': '*CH2*O',\n",
       " 'miller_index': (1, 0, 2),\n",
       " 'shift': 0.12,\n",
       " 'top': True,\n",
       " 'adsorption_site': ((6.14, 9.52, 26.78), (7.24, 10.17, 26.35)),\n",
       " 'class': 2,\n",
       " 'anomaly': 1,\n",
       " 'reference_energy': -541.3165906600001,\n",
       " 'system_id': 'random1832616',\n",
       " 'frame_number': 'frame148',\n",
       " '_name': {'OC20_S2EF_train_200K__file_000_config_1'}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import colabfit.tools.utilities\n",
    "import colabfit.tools.dataset\n",
    "import colabfit.tools.database\n",
    "import colabfit.tools.configuration_set\n",
    "\n",
    "reload(colabfit.tools.utilities)\n",
    "reload(colabfit.tools.dataset)\n",
    "reload(colabfit.tools.database)\n",
    "DataManager = colabfit.tools.database.DataManager\n",
    "ConfigurationSet = colabfit.tools.configuration_set.ConfigurationSet\n",
    "Dataset = colabfit.tools.dataset.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.rdd  \n",
    "you can only parallelize one time so don't try to do a dataframe select from an rdd  \n",
    "updating to sdk 5.1 in a couple weeks  \n",
    "boto3 and s3 are the amazon file system interactions, mostly for adding metadata TO FILES (not to the database) and interacting with the files as FileExistsError. \n",
    "Make sure to spark.stop() at end of  python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'carmat_reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m carmat_config_gen \u001b[38;5;241m=\u001b[39m \u001b[43mcarmat_reader\u001b[49m(Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/carolina_matdb/base/all/data.mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m carmat_ds_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDS_y7nrdsjtuw0g_0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# carmat_ds_id2 = \"duplicate_ds_id\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'carmat_reader' is not defined"
     ]
    }
   ],
   "source": [
    "carmat_config_gen = carmat_reader(Path(\"data/carolina_matdb/base/all/data.mdb\"))\n",
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\"\n",
    "dm = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=carmat_config_gen,\n",
    "    prop_defs=[formation_energy_pd],\n",
    "    prop_map=CM_PROPERTY_MAP,\n",
    "    dataset_id=carmat_ds_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: DS_y7nrdsjtuwom_0\n"
     ]
    }
   ],
   "source": [
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "dm2 = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=mtpu_configs,\n",
    "    prop_defs=[potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "    prop_map=PROPERTY_MAP,\n",
    "    dataset_id=mtpu_ds_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dm.gather_co_po_in_batches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_co_rows_cs_id(self, co_ids: list[str], cs_id: str):\n",
    "    with psycopg.connect(\n",
    "        \"\"\"dbname=colabfit user=%s password=%s host=localhost port=5432\"\"\"\n",
    "        % (\n",
    "            user,\n",
    "            password,\n",
    "        )\n",
    "    ) as conn:\n",
    "        # dbname=self.database_name,\n",
    "        # user=self.properties[\"user\"],\n",
    "        # password=self.properties[\"password\"],\n",
    "        # host=\"localhost\",\n",
    "        # port=\"5432\",\n",
    "        cur = conn.execute(\n",
    "            \"\"\"UPDATE configurations\n",
    "                SET configuration_set_ids = \n",
    "            \"\"\"\n",
    "        )\n",
    "        cur = conn.execute(\n",
    "            \"\"\"UPDATE configurations\n",
    "                SET configuration_set_ids = concat(%s::text, \n",
    "                rtrim(ltrim(replace(configuration_set_ids,%s,''), \n",
    "                \n",
    "                '['),']') || ', ', %s::text)\n",
    "            WHERE id = ANY(%s)\"\"\",\n",
    "            (\"[\", f\"{cs_id}\", f\"{cs_id}]\", co_ids),\n",
    "            # (\"[\", f\", {cs_id}\", f\", {cs_id}]\"),\n",
    "        )\n",
    "        # cur.fetchall()\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You were trying to get  postgresql to recognize the WHERE id = ANY() array syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(\n",
    "    dbname=\"colabfit\",\n",
    "    user=os.environ.get(\"PGS_USER\"),\n",
    "    password=os.environ.get(\"PGS_PASS\"),\n",
    "    host=\"localhost\",\n",
    ") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        # cur.execute(\n",
    "        #     \"UPDATE configurations SET configuration_set_ids = configuration_set_ids || %(cs_id)s WHERE id = ANY(%(co_ids)s)\",\n",
    "        #     {\"cs_id\": cs[\"id\"], \"co_ids\": co_ids},\n",
    "        # )\n",
    "        # data = cur.fetchall()\n",
    "        cur.execute(\n",
    "            \"SELECT * FROM public.configurations WHERE id = ANY(%s)\",\n",
    "            [co_ids],\n",
    "        )\n",
    "        data2 = cur.fetchall()\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert appears to be this for postgres:\n",
    "```\n",
    "update the_table\n",
    "    set id = id || array[5,6]\n",
    "where id = 4;\n",
    "```\n",
    "* ~~Check for upsert function from pyspark to concatenate lists of relationships instead of primary key id collision~~\n",
    "* There is no pyspark-upsert function. Will have to manage this possibly through a different sql-based library\n",
    "* Written: find duplicates, but convert to access database, not download full dataframe\n",
    "* I see this being used with batches of hashes during upload: something like\n",
    "    ``` for batch in batches:\n",
    "            hash_duplicates = find_duplicates(batch, loader/database)\n",
    "            hash_duplicates.make_change_to_append_dataset-ids\n",
    "            hash_duplicates.write-to-database\n",
    "* Where would be the best place to catch duplicates? Keeping in mind that this might be a bulk operation (i.e. on the order of millions, like with ANI1/ANI2x variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/30 09:52:06 WARN Utils: Your hostname, arktos resolves to a loopback address: 127.0.1.1; using 172.24.21.25 instead (on interface enp5s0)\n",
      "24/05/30 09:52:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/05/30 09:52:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/30 09:52:08 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "dm2 = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=mtpu_configs,\n",
    "    prop_defs=[potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "    prop_map=PROPERTY_MAP,\n",
    "    dataset_id=mtpu_ds_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "def write_value_to_file(path_prefix, extension, BUCKET_DIR, write_column, row):\n",
    "    \"\"\"i.e.: partial(_write_value(\n",
    "    'CO/positions',\n",
    "    'txt',\n",
    "    '/save/here'\n",
    "    'positions',\n",
    "    )\n",
    "    \"\"\"\n",
    "    id = row[\"id\"]\n",
    "    value = row[write_column]\n",
    "    row_dict = row.copy()\n",
    "    split = id[-4:]\n",
    "    filename = f\"{id}.{extension}\"\n",
    "    full_path = Path(BUCKET_DIR) / path_prefix / split / filename\n",
    "    full_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    full_path.write_text(str(value))\n",
    "    # row_dict = row.asDict()\n",
    "    row_dict[write_column] = str(full_path)\n",
    "    return Row(**row_dict)\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "part_write = partial(\n",
    "    write_value_to_file,\n",
    "    \"CO/positions\",\n",
    "    \"txt\",\n",
    "    \"/scratch/gw2338/vast/data-lake-main/spark/scripts\",\n",
    "    \"positions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "co_rows = [x.spark_row for x in configs]\n",
    "rdd = sc.parallelize(co_rows)\n",
    "rdd.foreachPartition(part_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = list(mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\")))\n",
    "dm2.configs = config_list[:50]\n",
    "dm2.load_co_po_to_vastdb(loader)\n",
    "dm2.configs = config_list[25:]\n",
    "dm2.load_co_po_to_vastdb(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import colabfit.tools.utilities\n",
    "import colabfit.tools.dataset\n",
    "import colabfit.tools.database\n",
    "import colabfit.tools.configuration_set\n",
    "\n",
    "reload(colabfit.tools.utilities)\n",
    "reload(colabfit.tools.dataset)\n",
    "reload(colabfit.tools.database)\n",
    "DataManager = colabfit.tools.database.DataManager\n",
    "ConfigurationSet = colabfit.tools.configuration_set.ConfigurationSet\n",
    "Dataset = colabfit.tools.dataset.Dataset\n",
    "##############\n",
    "\n",
    "import json\n",
    "import lmdb\n",
    "import pickle\n",
    "from colabfit.tools.database import DataManager, SparkDataLoader\n",
    "\n",
    "loader = SparkDataLoader(table_prefix=\"ndb.colabfit.dev\")\n",
    "load_dotenv()\n",
    "access_key = os.getenv(\"SPARK_ID\")\n",
    "access_secret = os.getenv(\"SPARK_KEY\")\n",
    "endpoint = os.getenv(\"SPARK_ENDPOINT\")\n",
    "loader.set_vastdb_session(\n",
    "    endpoint=endpoint, access_key=access_key, access_secret=access_secret\n",
    ")\n",
    "\n",
    "with open(\"formation_energy.json\", \"r\") as f:\n",
    "    formation_energy_pd = json.load(f)\n",
    "\n",
    "carmat_config_gen = carmat_reader(Path(\"data/carolina_matdb/base/all/data.mdb\"))\n",
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\"\n",
    "\n",
    "\n",
    "dm = DataManager(\n",
    "    nprocs=1,\n",
    "    configs=carmat_config_gen,\n",
    "    prop_defs=[formation_energy_pd],\n",
    "    prop_map=CM_PROPERTY_MAP,\n",
    "    dataset_id=carmat_ds_id,\n",
    ")\n",
    "dm.configs = carmat_reader(Path(\"data/carolina_matdb/base/all/data.mdb\"))\n",
    "\n",
    "match = [\n",
    "    (r\".*3.*\", None, \"3_configurations\", \"Carmat with 3\"),\n",
    "    (r\".*4.*\", None, \"4_configurations\", \"Carmat with 4\"),\n",
    "]\n",
    "# dm.load_co_po_to_vastdb(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = dm2.gather_co_po_in_batches()\n",
    "batch = next(batches)\n",
    "cos, pos = zip(*batch)\n",
    "rdd = loader.spark.sparkContext.parallelize(cos)\n",
    "ids_coll = rdd.map(lambda x: x[\"id\"]).collect()\n",
    "loader.spark.read.table(loader.config_table).select(sf.col(\"id\")).filter(\n",
    "    sf.col(\"id\").isin(broadcast_ids.value)\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.utilities import unstringify\n",
    "from colabfit.tools.schema import (\n",
    "    configuration_set_df_schema,\n",
    "    dataset_df_schema,\n",
    "    property_object_df_schema,\n",
    "    config_df_schema,\n",
    ")\n",
    "\n",
    "\n",
    "def read_table(self, table_name: str, unstring: bool = False):\n",
    "    \"\"\"\n",
    "    Include self.table_prefix in the table name when passed to this function.\n",
    "    Ex: loader.read_table(loader.config_table, unstring=True)\n",
    "    Arguments:\n",
    "        table_name {str} -- Name of the table to read from database\n",
    "    Keyword Arguments:\n",
    "        unstring {bool} -- Convert stringified lists to lists (default: {False})\n",
    "    Returns:\n",
    "        DataFrame -- Spark DataFrame\n",
    "    \"\"\"\n",
    "    schema_dict = {\n",
    "        self.config_table: config_df_schema,\n",
    "        self.config_set_table: configuration_set_df_schema,\n",
    "        self.dataset_table: dataset_df_schema,\n",
    "        self.prop_object_table: property_object_df_schema,\n",
    "    }\n",
    "    if unstring:\n",
    "        df = self.spark.read.table(table_name)\n",
    "        return df.rdd.map(unstringify).toDF(schema_dict[table_name])\n",
    "    else:\n",
    "        return self.spark.read.table(table_name)\n",
    "\n",
    "\n",
    "def get_pos_cos_by_filter(self, filter_conditions):\n",
    "    po_df = self.read_table(self.prop_object_table, unstring=True).withColumnRenamed(\n",
    "        \"id\", \"po_id\"\n",
    "    )\n",
    "    po_df = po_df.withColumn(\n",
    "        \"configuration_id\", sf.explode(sf.col(\"configuration_ids\"))\n",
    "    ).drop(\"configuration_ids\")\n",
    "    co_df = self.read_table(self.config_table, unstring=True).withColumnRenamed(\n",
    "        \"id\", \"co_id\"\n",
    "    )\n",
    "    for i, (column, operand, condition) in enumerate(filter_conditions):\n",
    "        if operand == \"in\":\n",
    "            po_df = po_df.filter(sf.col(column).isin(condition))\n",
    "        elif operand == \"like\":\n",
    "            po_df = po_df.filter(sf.col(column).like(condition))\n",
    "        elif operand == \"rlike\":\n",
    "            po_df = po_df.filter(sf.col(column).rlike(condition))\n",
    "        elif operand == \"==\":\n",
    "            po_df = po_df.filter(sf.col(column) == condition)\n",
    "        elif operand == \"array_contains\":\n",
    "            po_df = po_df.filter(sf.array_contains(sf.col(column), condition))\n",
    "        elif operand == \">\":\n",
    "            po_df = po_df.filter(sf.col(column) > condition)\n",
    "        elif operand == \"<\":\n",
    "            po_df = po_df.filter(sf.col(column) < condition)\n",
    "        elif operand == \">=\":\n",
    "            po_df = po_df.filter(sf.col(column) >= condition)\n",
    "        elif operand == \"<=\":\n",
    "            po_df = po_df.filter(sf.col(column) <= condition)\n",
    "        else:\n",
    "            raise ValueError(f\"Operand {operand} not implemented in get_pos_cos_filter\")\n",
    "    co_po_df = co_df.join(po_df, co_df[\"co_id\"] == po_df[\"configuration_id\"], \"inner\")\n",
    "    return co_po_df\n",
    "\n",
    "\n",
    "get_pos_cos_by_filter(\n",
    "    loader, [(\"dataset_ids\", \"array_contains\", mtpu_ds_id), (\"method\", \"like\", \"DFT%\")]\n",
    ")\n",
    "df = get_pos_cos_by_filter(\n",
    "    loader,\n",
    "    [\n",
    "        (\"dataset_ids\", \"array_contains\", mtpu_ds_id),\n",
    "        (\"method\", \"like\", \"DFT%\"),\n",
    "        (\"potential_energy\", \"<\", -56729.0),\n",
    "    ],\n",
    "    [(\"nsites\", \">=\", 63)],\n",
    ")\n",
    "\n",
    "\n",
    "def get_pos_cos_by_filter(\n",
    "    self,\n",
    "    po_filter_conditions: list[tuple],\n",
    "    co_filter_conditions: list[tuple] = None,\n",
    "):\n",
    "    po_df = self.read_table(self.prop_object_table, unstring=True).withColumnRenamed(\n",
    "        \"id\", \"po_id\"\n",
    "    )\n",
    "    po_df = po_df.withColumn(\n",
    "        \"configuration_id\", sf.explode(sf.col(\"configuration_ids\"))\n",
    "    ).drop(\"configuration_ids\")\n",
    "    co_df = self.read_table(self.config_table, unstring=True).withColumnRenamed(\n",
    "        \"id\", \"co_id\"\n",
    "    )\n",
    "    po_df = get_filtered_table(self, po_df, po_filter_conditions)\n",
    "    if co_filter_conditions is not None:\n",
    "        co_df = get_filtered_table(self, co_df, co_filter_conditions)\n",
    "    co_po_df = co_df.join(po_df, co_df[\"co_id\"] == po_df[\"configuration_id\"], \"inner\")\n",
    "    return co_po_df\n",
    "\n",
    "\n",
    "def get_filtered_table(\n",
    "    self, df: DataFrame, filter_conditions: list[tuple[str, str, str]]\n",
    "):\n",
    "    for i, (column, operand, condition) in enumerate(filter_conditions):\n",
    "        if operand == \"in\":\n",
    "            df = df.filter(sf.col(column).isin(condition))\n",
    "        elif operand == \"like\":\n",
    "            df = df.filter(sf.col(column).like(condition))\n",
    "        elif operand == \"rlike\":\n",
    "            df = df.filter(sf.col(column).rlike(condition))\n",
    "        elif operand == \"==\":\n",
    "            df = df.filter(sf.col(column) == condition)\n",
    "        elif operand == \"array_contains\":\n",
    "            df = df.filter(sf.array_contains(sf.col(column), condition))\n",
    "        elif operand == \">\":\n",
    "            df = df.filter(sf.col(column) > condition)\n",
    "        elif operand == \"<\":\n",
    "            df = df.filter(sf.col(column) < condition)\n",
    "        elif operand == \">=\":\n",
    "            df = df.filter(sf.col(column) >= condition)\n",
    "        elif operand == \"<=\":\n",
    "            df = df.filter(sf.col(column) <= condition)\n",
    "        else:\n",
    "            raise ValueError(f\"Operand {operand} not implemented in get_pos_cos_filter\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df1 = read_filter_table(loader, [(\"id\", \"==\", \"CO_47706510123393079\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = mtpu_ds_id\n",
    "name_label_match = [\n",
    "    (\".*Si.*3.*\", None, \"All_si_with_zero\", \"All Si with zero description\"),\n",
    "    (\".*Si.*4.*\", None, \"All_si_with_two\", \"All Si with two description\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time()\n",
    "dm.create_configuration_sets(loader, match)\n",
    "end = time()\n",
    "print(f\"Time elapsed: {end - begin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_configuration_sets(\n",
    "    self,\n",
    "    loader,\n",
    "    # below args in order:\n",
    "    # [config-name-regex-pattern], [config-label-regex-pattern], \\\n",
    "    # [config-set-name], [config-set-description]\n",
    "    name_label_match: list[tuple],\n",
    "):\n",
    "    config_set_rows = []\n",
    "    # Load unstrung dataframe of configs, filter for just includes ds-id\n",
    "    config_df = loader.read_table(table_name=loader.config_table, unstring=True)\n",
    "    config_df = config_df.filter(\n",
    "        sf.array_contains(sf.col(\"dataset_ids\"), self.dataset_id)\n",
    "    )\n",
    "    for i, (names_match, label_match, cs_name, cs_desc) in tqdm(\n",
    "        enumerate(name_label_match), desc=\"Creating Configuration Sets\"\n",
    "    ):\n",
    "        print(\n",
    "            f\"names match: {names_match}, label {label_match}, cs_name {cs_name}, cs_desc {cs_desc}\"\n",
    "        )\n",
    "        if names_match:\n",
    "            config_set_query = config_df.withColumn(\n",
    "                \"names_exploded\", sf.explode(sf.col(\"names\"))\n",
    "            ).filter(sf.col(\"names_exploded\").rlike(names_match))\n",
    "        # Currently an AND operation on labels: labels col contains x AND y\n",
    "        if label_match is not None:\n",
    "            if isinstance(label_match, str):\n",
    "                label_match = [label_match]\n",
    "            for label in label_match:\n",
    "                config_set_query = config_set_query.filter(\n",
    "                    sf.array_contains(sf.col(\"labels\"), label)\n",
    "                )\n",
    "        co_ids = [x[\"id\"] for x in config_set_query.select(\"id\").distinct().collect()]\n",
    "        loader.find_existing_rows_append_elem(\n",
    "            table_name=loader.config_table,\n",
    "            ids=co_ids,\n",
    "            cols=\"configuration_set_ids\",\n",
    "            elems=cs_name,\n",
    "            edit_schema=config_df_schema,\n",
    "            write_schema=config_schema,\n",
    "        )\n",
    "        config_set = ConfigurationSet(\n",
    "            name=cs_name,\n",
    "            description=cs_desc,\n",
    "            config_df=config_set_query,\n",
    "            dataset_id=self.dataset_id,\n",
    "        )\n",
    "        config_set_rows.append(config_set.spark_row)\n",
    "    loader.write_table(\n",
    "        config_set_rows, loader.config_set_table, schema=configuration_set_schema\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.utilities import _write_value\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_write = partial(\n",
    "    _write_value,\n",
    "    \"CO/positions\",\n",
    "    \"txt\",\n",
    "    \"/scratch/gw2338/vast/data-lake-main/spark/scripts\",\n",
    "    \"positions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import dataset_schema\n",
    "from colabfit.tools.dataset import Dataset\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    self,\n",
    "    loader,\n",
    "    name: str,\n",
    "    authors: list[str],\n",
    "    publication_link: str,\n",
    "    data_link: str,\n",
    "    description: str,\n",
    "    other_links: list[str] = None,\n",
    "    dataset_id: str = None,\n",
    "    labels: list[str] = None,\n",
    "    data_license: str = \"CC-BY-ND-4.0\",\n",
    "):\n",
    "    cs_ids = loader.read_table(loader.config_set_table).select(\"id\").collect()\n",
    "    if len(cs_ids) == 0:\n",
    "        cs_ids = None\n",
    "    else:\n",
    "        cs_ids = [x[\"id\"] for x in cs_ids]\n",
    "    config_df = loader.read_table(loader.config_table, unstring=True)\n",
    "    config_df = config_df.filter(sf.array_contains(sf.col(\"dataset_ids\"), dataset_id))\n",
    "    prop_df = loader.read_table(loader.prop_object_table, unstring=True)\n",
    "    prop_df = prop_df.filter(sf.array_contains(sf.col(\"dataset_ids\"), dataset_id))\n",
    "    ds = Dataset(\n",
    "        name=name,\n",
    "        authors=authors,\n",
    "        config_df=config_df,\n",
    "        prop_df=prop_df,\n",
    "        publication_link=publication_link,\n",
    "        data_link=data_link,\n",
    "        description=description,\n",
    "        other_links=other_links,\n",
    "        dataset_id=dataset_id,\n",
    "        labels=labels,\n",
    "        data_license=data_license,\n",
    "        configuration_set_ids=cs_ids,\n",
    "    )\n",
    "    loader.write_table([ds.spark_row], loader.dataset_table, schema=dataset_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "create_dataset(\n",
    "    dm,\n",
    "    loader,\n",
    "    \"carolina_materials\",\n",
    "    [\"author one\", \"author two\"],\n",
    "    \"https://www.carolina_materials.com\",\n",
    "    \"https://www.carolina_materials.com/data\",\n",
    "    \"Carolina Materials is a ... description\",\n",
    "    dataset_id=dm.dataset_id,\n",
    ")\n",
    "print(f\"Time elapsed: {time() - t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import colabfit.tools.dataset\n",
    "import colabfit.tools.database\n",
    "import colabfit.tools.configuration_set\n",
    "import colabfit.tools.schema\n",
    "\n",
    "reload(colabfit.tools.configuration_set)\n",
    "reload(colabfit.tools.dataset)\n",
    "reload(colabfit.tools.database)\n",
    "reload(colabfit.tools.schema)\n",
    "configuration_set_schema = colabfit.tools.schema.configuration_set_schema\n",
    "DataManager = colabfit.tools.database.DataManager\n",
    "ConfigurationSet = colabfit.tools.configuration_set.ConfigurationSet\n",
    "Dataset = colabfit.tools.dataset.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_hash(spark_rows: dict, loader):\n",
    "    # hashes = loader.spark.createDataFrame([x[\"hash\"] for x in spark_rows])\n",
    "    hashes = [x[\"hash\"] for x in spark_rows]\n",
    "    duplicates = loader.spark.read.jdbc(\n",
    "        url=url,\n",
    "        table=\"configurations\",\n",
    "        properties=properties,\n",
    "    ).filter(sf.col(\"hash\").isin(hashes))\n",
    "    # dupl_hashes = df.filter(df.hash.isin(hashes)).select(\"hash\").collect()\n",
    "    return duplicates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
