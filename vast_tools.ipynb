{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "from itertools import chain, islice\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import dateutil.parser\n",
    "import findspark\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import pyspark\n",
    "import pyspark.sql.functions as sf\n",
    "from ase.atoms import Atoms\n",
    "from ase.io.cfg import read_cfg\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    BooleanType,\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    ")\n",
    "\n",
    "from colabfit.tools.configuration import AtomicConfiguration, config_schema\n",
    "from colabfit.tools.database import DataManager, PGDataLoader\n",
    "from colabfit.tools.dataset import Dataset, dataset_schema\n",
    "from colabfit.tools.property import Property, property_object_schema\n",
    "from colabfit.tools.property_definitions import (\n",
    "    atomic_forces_pd,\n",
    "    cauchy_stress_pd,\n",
    "    potential_energy_pd,\n",
    ")\n",
    "from colabfit.tools.schema import configuration_set_schema\n",
    "\n",
    "with open(\"formation_energy.json\", \"r\") as f:\n",
    "    formation_energy_pd = json.load(f)\n",
    "findspark.init()\n",
    "format = \"jdbc\"\n",
    "load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up MTPU and Carolina Materials readers and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTPU data\n",
    "\n",
    "\n",
    "def convert_stress(keys, stress):\n",
    "    stresses = {k: s for k, s in zip(keys, stress)}\n",
    "    return [\n",
    "        [stresses[\"xx\"], stresses[\"xy\"], stresses[\"xz\"]],\n",
    "        [stresses[\"xy\"], stresses[\"yy\"], stresses[\"yz\"]],\n",
    "        [stresses[\"xz\"], stresses[\"yz\"], stresses[\"zz\"]],\n",
    "    ]\n",
    "\n",
    "\n",
    "SYMBOL_DICT = {\"0\": \"Si\", \"1\": \"O\"}\n",
    "\n",
    "\n",
    "def mtpu_reader(filepath):\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        energy = None\n",
    "        forces = None\n",
    "        coords = []\n",
    "        cell = []\n",
    "        symbols = []\n",
    "        config_count = 0\n",
    "        for line in f:\n",
    "            if line.strip().startswith(\"Size\"):\n",
    "                size = int(f.readline().strip())\n",
    "            elif line.strip().lower().startswith(\"supercell\"):\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "            elif line.strip().startswith(\"Energy\"):\n",
    "                energy = float(f.readline().strip())\n",
    "            elif line.strip().startswith(\"PlusStress\"):\n",
    "                stress_keys = line.strip().split()[-6:]\n",
    "                stress = [float(x) for x in f.readline().strip().split()]\n",
    "                stress = convert_stress(stress_keys, stress)\n",
    "            elif line.strip().startswith(\"AtomData:\"):\n",
    "                keys = line.strip().split()[1:]\n",
    "                if \"fx\" in keys:\n",
    "                    forces = []\n",
    "                for i in range(size):\n",
    "                    li = {\n",
    "                        key: val for key, val in zip(keys, f.readline().strip().split())\n",
    "                    }\n",
    "                    symbols.append(SYMBOL_DICT[li[\"type\"]])\n",
    "                    if \"cartes_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"cartes_x\"],\n",
    "                                    li[\"cartes_y\"],\n",
    "                                    li[\"cartes_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "                    elif \"direct_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"direct_x\"],\n",
    "                                    li[\"direct_y\"],\n",
    "                                    li[\"direct_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                    if \"fx\" in keys:\n",
    "                        forces.append(\n",
    "                            [float(f) for f in [li[\"fx\"], li[\"fy\"], li[\"fz\"]]]\n",
    "                        )\n",
    "\n",
    "            elif line.startswith(\"END_CFG\"):\n",
    "                if \"cartes_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        positions=coords, symbols=symbols, cell=cell\n",
    "                    )\n",
    "                elif \"direct_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        scaled_positions=coords, symbols=symbols, cell=cell\n",
    "                    )\n",
    "                config.info[\"energy\"] = energy\n",
    "                if forces:\n",
    "                    config.info[\"forces\"] = forces\n",
    "                config.info[\"stress\"] = stress\n",
    "\n",
    "                if \"Si\" in symbols and \"O\" in symbols:\n",
    "                    config.info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"11x11x11\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    config.info[\"_name\"] = f\"{filepath.stem}_SiO2_{config_count}\"\n",
    "                elif \"Si\" in symbols:\n",
    "                    config.info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"8x8x8\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 884,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    config.info[\"_name\"] = f\"{filepath.stem}_Si_{config_count}\"\n",
    "                elif \"O\" in symbols:\n",
    "                    config.info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"gamma-point\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    config.info[\"_name\"] = f\"{filepath.stem}_O_{config_count}\"\n",
    "                config_count += 1\n",
    "                yield config\n",
    "                forces = None\n",
    "                stress = []\n",
    "                coords = []\n",
    "                cell = []\n",
    "                symbols = []\n",
    "                energy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "# data = [x for x in mtpu_configs]\n",
    "# data[0].configuration_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carolina Materials data\n",
    "\n",
    "SOFTWARE = \"VASP\"\n",
    "METHODS = \"DFT-PBE\"\n",
    "CM_PI_METADATA = {\n",
    "    \"software\": {\"value\": SOFTWARE},\n",
    "    \"method\": {\"value\": METHODS},\n",
    "    \"input\": {\"value\": {\"IBRION\": 6, \"NFREE\": 4}},\n",
    "}\n",
    "\n",
    "CM_PROPERTY_MAP = {\n",
    "    \"formation-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": CM_PI_METADATA,\n",
    "}\n",
    "CO_MD = {\n",
    "    key: {\"field\": key}\n",
    "    for key in [\n",
    "        \"_symmetry_space_group_name_H-M\",\n",
    "        \"_symmetry_Int_Tables_number\",\n",
    "        \"_chemical_formula_structural\",\n",
    "        \"_chemical_formula_sum\",\n",
    "        \"_cell_volume\",\n",
    "        \"_cell_formula_units_Z\",\n",
    "        \"symmetry_dict\",\n",
    "        \"formula_pretty\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def load_row(txn, row):\n",
    "    try:\n",
    "        data = pickle.loads(txn.get(f\"{row}\".encode(\"ascii\")))\n",
    "        return data\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def config_from_row(row: dict, row_num: int):\n",
    "    coords = row.pop(\"cart_coords\")\n",
    "    a_num = row.pop(\"atomic_numbers\")\n",
    "    cell = [\n",
    "        row.pop(x)\n",
    "        for x in [\n",
    "            \"_cell_length_a\",\n",
    "            \"_cell_length_b\",\n",
    "            \"_cell_length_c\",\n",
    "            \"_cell_angle_alpha\",\n",
    "            \"_cell_angle_beta\",\n",
    "            \"_cell_angle_gamma\",\n",
    "        ]\n",
    "    ]\n",
    "    symmetry_dict = {str(key): val for key, val in row.pop(\"symmetry_dict\").items()}\n",
    "    for key in symmetry_dict:\n",
    "        key = str(key)\n",
    "    info = {}\n",
    "    info = row\n",
    "    info[\"symmetry_dict\"] = symmetry_dict\n",
    "    info[\"_name\"] = f\"carolina_materials_{row_num}\"\n",
    "    if row_num % 10 == 0:\n",
    "        info[\"_labels\"] = [row_num % 10, \"bcc\"]\n",
    "    else:\n",
    "        info[\"_labels\"] = [row_num % 10, \"fcc\"]\n",
    "\n",
    "    config = AtomicConfiguration(\n",
    "        scaled_positions=coords,\n",
    "        numbers=a_num,\n",
    "        cell=cell,\n",
    "        info=info,\n",
    "    )\n",
    "    return config\n",
    "    # return AtomicConfiguration.from_ase(config)\n",
    "\n",
    "\n",
    "def carmat_reader(fp: Path):\n",
    "    parent = fp.parent\n",
    "    env = lmdb.open(str(parent))\n",
    "    txn = env.begin()\n",
    "    row_num = 0\n",
    "    rows = []\n",
    "    while row_num <= 10000:\n",
    "        row = load_row(txn, row_num)\n",
    "        if row is False:\n",
    "            env.close()\n",
    "            break\n",
    "        rows.append(row)\n",
    "        yield config_from_row(row, row_num)\n",
    "        row_num += 1\n",
    "    env.close()\n",
    "    return False\n",
    "    # return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"Quantum ESPRESSO\"},\n",
    "    \"method\": {\"value\": \"DFT-PBE\"},\n",
    "    \"input\": {\"field\": \"input\"},\n",
    "}\n",
    "\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "    \"cauchy-stress\": [\n",
    "        {\n",
    "            \"stress\": {\"field\": \"stress\", \"units\": \"GPa\"},\n",
    "            \"volume-normalized\": {\"value\": True, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": PI_METADATA,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB and run loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 15:09:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "24/05/03 15:09:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: DS_y7nrdsjtuw0g_0\n"
     ]
    }
   ],
   "source": [
    "carmat_config_gen = carmat_reader(Path(\"data/carolina_matdb/base/all/data.mdb\"))\n",
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\"\n",
    "carmat_ds_id2 = \"duplicate_ds_id\"\n",
    "dm = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=carmat_config_gen,\n",
    "    prop_defs=[formation_energy_pd],\n",
    "    prop_map=CM_PROPERTY_MAP,\n",
    "    dataset_id=carmat_ds_id,\n",
    ")\n",
    "# dm_dup = DataManager(\n",
    "#     nprocs=4,\n",
    "#     configs=carmat_config_gen,\n",
    "#     prop_defs=[formation_energy_pd],\n",
    "#     prop_map=CM_PROPERTY_MAP,\n",
    "#     dataset_id=carmat_ds_id2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: DS_y7nrdsjtuwom_0\n"
     ]
    }
   ],
   "source": [
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "dm2 = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=mtpu_configs,\n",
    "    prop_defs=[potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "    prop_map=PROPERTY_MAP,\n",
    "    dataset_id=mtpu_ds_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dm.gather_co_po_in_batches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = [x[0] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_dataframe = loader.spark.createDataFrame(cos, schema=config_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+----------+---------------------+\n",
      "|id                    |hash               |last_modified      |dataset_ids          |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements               |elements_ratios     |atomic_numbers                    |nsites|nelements|nperiodic_dimensions|cell                                                                                                                               |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |names                   |labels    |configuration_set_ids|\n",
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+----------+---------------------+\n",
      "|CO_2035392092515548233|2035392092515548233|2024-05-03 15:09:57|['DS_y7nrdsjtuw0g_0']|NULL    |H6BrCaRh2            |BrCaH6Rh2               |A6B2CD                    |['Br', 'Ca', 'H', 'Rh']|[0.1, 0.1, 0.6, 0.2]|[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]|10    |4        |0                   |[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]|[0, 0, 0]      |[False, False, False]|[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]|['carolina_materials_0']|[0, 'bcc']|NULL                 |\n",
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------+----------+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cos_dataframe.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set_query = (\n",
    "    cos_dataframe.withColumn(\n",
    "        \"names_unstrung\", sf.from_json(sf.col(\"names\"), ArrayType(StringType()))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"labels_unstrung\",\n",
    "        sf.from_json(sf.col(\"labels\"), ArrayType(StringType())),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"dataset_ids_unstrung\", sf.from_json(\"dataset_ids\", ArrayType(StringType()))\n",
    "    )\n",
    "    .drop(\"names\", \"labels\", \"dataset_ids\")\n",
    "    .withColumnRenamed(\"names_unstrung\", \"names\")\n",
    "    .withColumnRenamed(\"labels_unstrung\", \"labels\")\n",
    "    .withColumnRenamed(\"dataset_ids_unstrung\", \"dataset_ids\")\n",
    "    .filter(sf.array_contains(sf.col(\"dataset_ids\"), carmat_ds_id))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "|id                    |hash               |last_modified      |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements               |elements_ratios     |atomic_numbers                    |nsites|nelements|nperiodic_dimensions|cell                                                                                                                               |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |configuration_set_ids|names                 |labels  |dataset_ids        |\n",
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "|CO_2035392092515548233|2035392092515548233|2024-05-03 15:09:57|NULL    |H6BrCaRh2            |BrCaH6Rh2               |A6B2CD                    |['Br', 'Ca', 'H', 'Rh']|[0.1, 0.1, 0.6, 0.2]|[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]|10    |4        |0                   |[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]|[0, 0, 0]      |[False, False, False]|[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]|NULL                 |[carolina_materials_0]|[0, bcc]|[DS_y7nrdsjtuw0g_0]|\n",
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_set_query.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "|id                   |hash              |last_modified      |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements                |elements_ratios     |atomic_numbers                          |nsites|nelements|nperiodic_dimensions|cell                                                                                                                            |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |configuration_set_ids|labels  |dataset_ids        |labels_exploded|names_exploded        |\n",
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "|CO_623768866906050502|623768866906050502|2024-05-03 15:09:57|NULL    |Cd6MgSeTe2           |Cd6MgSeTe2              |A6B2CD                    |['Cd', 'Mg', 'Se', 'Te']|[0.6, 0.1, 0.1, 0.2]|[48, 48, 48, 48, 48, 48, 12, 34, 52, 52]|10    |4        |0                   |[[8.10975373, 0.0, 0.0], [4.054876866668527, 7.023251338917589, 0.0], [4.054875643331443, 2.341084015070624, 6.621585529535167]]|[0, 0, 0]      |[False, False, False]|[[2.0274378216657216, 1.170542007535312, 3.3107927647675837], [6.082314686665722, 1.170542007535312, 3.3107927647675837], [6.082315298334263, 3.5116256694587946, 0.0], [2.0274384333342637, 3.5116256694587946, 0.0], [4.054876254999986, 4.682167676994107, 3.3107927647675837], [4.054876865, 0.0, 0.0], [0.0, 0.0, 0.0], [8.109753119999985, 4.682167676994107, 3.3107927647675837], [12.164629679999976, 7.02325151549116, 4.9661891471513755], [4.054876559999992, 2.3410838384970534, 1.6553963823837918]]|NULL                 |[1, fcc]|[DS_y7nrdsjtuw0g_0]|1              |carolina_materials_101|\n",
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_match = \"fcc|1\"\n",
    "names_match = \"materials_10\"\n",
    "if names_match:\n",
    "    config_set_query = (\n",
    "        config_set_query.withColumn(\"labels_exploded\", sf.explode(sf.col(\"labels\")))\n",
    "        .withColumn(\"names_exploded\", sf.explode(sf.col(\"names\")))\n",
    "        .drop(\"names\")\n",
    "        .filter(sf.regexp_like(sf.col(\"names_exploded\"), sf.lit(rf\"{names_match}\")))\n",
    "    )\n",
    "if label_match:\n",
    "    config_set_query = config_set_query.filter(\n",
    "        sf.regexp_like(sf.col(\"labels_exploded\"), sf.lit(rf\"{label_match}\"))\n",
    "    )\n",
    "config_set_query.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.configuration_set import ConfigurationSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = ConfigurationSet(\n",
    "    name=\"test\", config_df=config_set_query, description=\"test description\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurationSet(description='test description', nconfigurations=110)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.utilities import _empty_dict_from_schema\n",
    "from colabfit.tools.schema import configuration_set_schema\n",
    "import dateutil.parser\n",
    "\n",
    "cs = _empty_dict_from_schema(configuration_set_schema)\n",
    "cs[\"nconfigurations\"] = 200\n",
    "cs[\"dataset_id\"] = carmat_ds_id\n",
    "cs[\"name\"] = \"test\"\n",
    "cs[\"description\"] = \"test description for test\"\n",
    "cs[\"nelements\"] = 25\n",
    "cs[\"last_modified\"] = dateutil.parser.parse(\n",
    "    datetime.datetime.now(tz=datetime.timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    ")\n",
    "cs[\"id\"] = \"CS_y7nrdsjtuw0g_0\"\n",
    "cs[\"hash\"] = hash(cs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.write_table([cs], \"configuration_sets\", configuration_set_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ids = [x[0] for x in config_set_query.select(\"id\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data to PostgreSQL: : 0batch [00:00, ?batch/s]24/05/03 15:10:44 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "Loading data to PostgreSQL: : 2batch [00:04,  2.20s/batch]\n"
     ]
    }
   ],
   "source": [
    "dm.load_data_to_pg_in_batches(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(\n",
    "    dbname=\"colabfit\",\n",
    "    user=os.environ.get(\"PGS_USER\"),\n",
    "    password=os.environ.get(\"PGS_PASS\"),\n",
    "    host=\"localhost\",\n",
    ") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        # cur.execute(\n",
    "        #     \"UPDATE configurations SET configuration_set_ids = configuration_set_ids || %(cs_id)s WHERE id = ANY(%(co_ids)s)\",\n",
    "        #     {\"cs_id\": cs[\"id\"], \"co_ids\": co_ids},\n",
    "        # )\n",
    "        # data = cur.fetchall()\n",
    "        cur.execute(\n",
    "            \"SELECT * FROM public.configurations WHERE id = ANY(%s)\",\n",
    "            [co_ids],\n",
    "        )\n",
    "        data2 = cur.fetchall()\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ids.append(\"CO_215290934057753943\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2.load_data_to_pg_in_batches(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert appears to be this for postgres:\n",
    "```\n",
    "update the_table\n",
    "    set id = id || array[5,6]\n",
    "where id = 4;\n",
    "```\n",
    "* ~~Check for upsert function from pyspark to concatenate lists of relationships instead of primary key id collision~~\n",
    "* There is no pyspark-upsert function. Will have to manage this possibly through a different sql-based library\n",
    "* Written: find duplicates, but convert to access database, not download full dataframe\n",
    "* I see this being used with batches of hashes during upload: something like\n",
    "    ``` for batch in batches:\n",
    "            hash_duplicates = find_duplicates(batch, loader/database)\n",
    "            hash_duplicates.make_change_to_append_dataset-ids\n",
    "            hash_duplicates.write-to-database\n",
    "* Where would be the best place to catch duplicates? Keeping in mind that this might be a bulk operation (i.e. on the order of millions, like with ANI1/ANI2x variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import colabfit.tools.dataset\n",
    "import colabfit.tools.database\n",
    "\n",
    "reload(colabfit.tools.dataset)\n",
    "reload(colabfit.tools.database)\n",
    "DataManager = colabfit.tools.database.DataManager\n",
    "\n",
    "Dataset = colabfit.tools.dataset.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_hash(spark_rows: dict, loader):\n",
    "    # hashes = loader.spark.createDataFrame([x[\"hash\"] for x in spark_rows])\n",
    "    hashes = [x[\"hash\"] for x in spark_rows]\n",
    "    duplicates = loader.spark.read.jdbc(\n",
    "        url=url,\n",
    "        table=\"configurations\",\n",
    "        properties=properties,\n",
    "    ).filter(sf.col(\"hash\").isin(hashes))\n",
    "    # dupl_hashes = df.filter(df.hash.isin(hashes)).select(\"hash\").collect()\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_rows = [x.spark_row for x in dm_dup.configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = (\n",
    "    loader.spark.read.jdbc(\n",
    "        url=loader.url, table=loader.config_table, properties=loader.properties\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"ds_ids_unstrung\",\n",
    "        sf.from_json(sf.col(\"dataset_ids\"), sf.ArrayType(sf.StringType())),\n",
    "    )\n",
    "    .filter(sf.array_contains(\"ds_ids_unstrung\", dm.dataset_id))\n",
    "    .drop(\"ds_ids_unstrung\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes = find_duplicate_hash(dupl_rows, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[\"hash\"] for x in dup_hashes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can we make the configuration and the property instance/data object at the same time?\n",
    "In this way, we would only have to pass through the data one time.\n",
    "\n",
    "Workflow:\n",
    "create database access object\n",
    "create data reader as function? of the database access object\n",
    "reader returns ase.Atoms-style objects (AtomicConfiguration)\n",
    "DOs and PIs are now one object\n",
    "These DOs point to a configuration\n",
    "The configuration may already exist in the database, so we keep track of the hash added to the DO\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = json.load(Path(\"sample_db/co_ds1.json\").open(\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"sample_db/co_ds1.json\"), \"r\") as f:\n",
    "    co_json = spark.sparkContext.parallelize(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = co_json.map(_parse_config).map(stringify_lists)\n",
    "co_df = spark.createDataFrame(co, config_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_configs(co_path, spark):\n",
    "    with open(co_path, \"r\") as f:\n",
    "        co_json = spark.sparkContext.parallelize(json.load(f))\n",
    "    co = co_json.map(_parse_config).map(stringify_lists)\n",
    "    co_df = spark.createDataFrame(co, config_schema)\n",
    "    return co_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_configs(\"sample_db/co_ds1.json\", spark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
