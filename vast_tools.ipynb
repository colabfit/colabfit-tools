{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from functools import partial\n",
    "# from itertools import chain, islice\n",
    "# from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "\n",
    "# from pprint import pprint\n",
    "\n",
    "import dateutil.parser\n",
    "import findspark\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import pyspark.sql.functions as sf\n",
    "from ase.atoms import Atoms\n",
    "from ase.io.cfg import read_cfg\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    BooleanType,\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    ")\n",
    "\n",
    "from colabfit.tools.configuration import AtomicConfiguration, config_schema\n",
    "from colabfit.tools.database import DataManager, PGDataLoader\n",
    "from colabfit.tools.dataset import Dataset, dataset_schema\n",
    "from colabfit.tools.property import Property, property_object_schema\n",
    "from colabfit.tools.property_definitions import (\n",
    "    atomic_forces_pd,\n",
    "    cauchy_stress_pd,\n",
    "    potential_energy_pd,\n",
    ")\n",
    "from colabfit.tools.schema import configuration_set_schema\n",
    "import pyarrow as pa\n",
    "\n",
    "with open(\"formation_energy.json\", \"r\") as f:\n",
    "    formation_energy_pd = json.load(f)\n",
    "findspark.init()\n",
    "format = \"jdbc\"\n",
    "load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up MTPU and Carolina Materials readers and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTPU data\n",
    "\n",
    "\n",
    "def convert_stress(keys, stress):\n",
    "    stresses = {k: s for k, s in zip(keys, stress)}\n",
    "    return [\n",
    "        [stresses[\"xx\"], stresses[\"xy\"], stresses[\"xz\"]],\n",
    "        [stresses[\"xy\"], stresses[\"yy\"], stresses[\"yz\"]],\n",
    "        [stresses[\"xz\"], stresses[\"yz\"], stresses[\"zz\"]],\n",
    "    ]\n",
    "\n",
    "\n",
    "SYMBOL_DICT = {\"0\": \"Si\", \"1\": \"O\"}\n",
    "\n",
    "\n",
    "def mtpu_reader(filepath):\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        energy = None\n",
    "        forces = None\n",
    "        coords = []\n",
    "        cell = []\n",
    "        symbols = []\n",
    "        config_count = 0\n",
    "        info = dict()\n",
    "        for line in f:\n",
    "            if line.strip().startswith(\"Size\"):\n",
    "                size = int(f.readline().strip())\n",
    "            elif line.strip().lower().startswith(\"supercell\"):\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "                cell.append([float(x) for x in f.readline().strip().split()])\n",
    "            elif line.strip().startswith(\"Energy\"):\n",
    "                energy = float(f.readline().strip())\n",
    "            elif line.strip().startswith(\"PlusStress\"):\n",
    "                stress_keys = line.strip().split()[-6:]\n",
    "                stress = [float(x) for x in f.readline().strip().split()]\n",
    "                stress = convert_stress(stress_keys, stress)\n",
    "            elif line.strip().startswith(\"AtomData:\"):\n",
    "                keys = line.strip().split()[1:]\n",
    "                if \"fx\" in keys:\n",
    "                    forces = []\n",
    "                for i in range(size):\n",
    "                    li = {\n",
    "                        key: val for key, val in zip(keys, f.readline().strip().split())\n",
    "                    }\n",
    "                    symbols.append(SYMBOL_DICT[li[\"type\"]])\n",
    "                    if \"cartes_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"cartes_x\"],\n",
    "                                    li[\"cartes_y\"],\n",
    "                                    li[\"cartes_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "                    elif \"direct_x\" in keys:\n",
    "                        coords.append(\n",
    "                            [\n",
    "                                float(c)\n",
    "                                for c in [\n",
    "                                    li[\"direct_x\"],\n",
    "                                    li[\"direct_y\"],\n",
    "                                    li[\"direct_z\"],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                    if \"fx\" in keys:\n",
    "                        forces.append(\n",
    "                            [float(f) for f in [li[\"fx\"], li[\"fy\"], li[\"fz\"]]]\n",
    "                        )\n",
    "\n",
    "            elif line.startswith(\"END_CFG\"):\n",
    "\n",
    "                info[\"energy\"] = energy\n",
    "                if forces:\n",
    "                    info[\"forces\"] = forces\n",
    "                info[\"stress\"] = stress\n",
    "\n",
    "                if \"Si\" in symbols and \"O\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"11x11x11\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_SiO2_{config_count}\"\n",
    "                elif \"Si\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"8x8x8\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 884,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_Si_{config_count}\"\n",
    "                elif \"O\" in symbols:\n",
    "                    info[\"input\"] = {\n",
    "                        \"kpoint-scheme\": \"Monkhorst-Pack\",\n",
    "                        \"kpoints\": \"gamma-point\",\n",
    "                        \"kinetic-energy-cutoff\": {\n",
    "                            \"val\": 1224,\n",
    "                            \"units\": \"eV\",\n",
    "                        },\n",
    "                    }\n",
    "                    info[\"_name\"] = f\"{filepath.stem}_O_{config_count}\"\n",
    "                if \"cartes_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        positions=coords, symbols=symbols, cell=cell, info=info\n",
    "                    )\n",
    "                elif \"direct_x\" in keys:\n",
    "                    config = AtomicConfiguration(\n",
    "                        scaled_positions=coords, symbols=symbols, cell=cell, info=info\n",
    "                    )\n",
    "                config_count += 1\n",
    "                yield config\n",
    "                forces = None\n",
    "                stress = []\n",
    "                coords = []\n",
    "                cell = []\n",
    "                symbols = []\n",
    "                energy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "data = list(mtpu_configs)\n",
    "# data = [x for x in mtpu_configs]\n",
    "# data[0].configuration_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colabfit.tools.configuration\n",
    "from importlib import reload\n",
    "\n",
    "reload(colabfit.tools.configuration)\n",
    "AtomicConfiguration = colabfit.tools.configuration.AtomicConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtomicConfiguration(name=Unified_training_set_SiO2_1061, symbols='Si4', pbc=False, cell=[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]])\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mserialize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "loader.spark.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CO_47706510123393079',\n",
       " 'hash': 47706510123393079,\n",
       " 'last_modified': datetime.datetime(2024, 5, 20, 17, 14, 38),\n",
       " 'dataset_ids': None,\n",
       " 'metadata': None,\n",
       " 'chemical_formula_hill': 'Si4',\n",
       " 'chemical_formula_reduced': 'Si',\n",
       " 'chemical_formula_anonymous': 'A',\n",
       " 'elements': \"['Si']\",\n",
       " 'elements_ratios': '[1.0]',\n",
       " 'atomic_numbers': '[14, 14, 14, 14]',\n",
       " 'nsites': 4,\n",
       " 'nelements': 1,\n",
       " 'nperiodic_dimensions': 0,\n",
       " 'cell': '[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]]',\n",
       " 'dimension_types': '[0, 0, 0]',\n",
       " 'pbc': '[False, False, False]',\n",
       " 'positions': '[[1.892001, 1.11132, 0.400465], [1.955509, -1.11132, 3.581973], [1.895339, -1.11132, -0.400508], [1.958847, 1.11132, 2.781]]',\n",
       " 'names': \"['Unified_training_set_Si_0']\",\n",
       " 'labels': None,\n",
       " 'configuration_set_ids': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].spark_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carolina Materials data\n",
    "\n",
    "SOFTWARE = \"VASP\"\n",
    "METHODS = \"DFT-PBE\"\n",
    "CM_PI_METADATA = {\n",
    "    \"software\": {\"value\": SOFTWARE},\n",
    "    \"method\": {\"value\": METHODS},\n",
    "    \"input\": {\"value\": {\"IBRION\": 6, \"NFREE\": 4}},\n",
    "}\n",
    "\n",
    "CM_PROPERTY_MAP = {\n",
    "    \"formation-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": CM_PI_METADATA,\n",
    "}\n",
    "CO_MD = {\n",
    "    key: {\"field\": key}\n",
    "    for key in [\n",
    "        \"_symmetry_space_group_name_H-M\",\n",
    "        \"_symmetry_Int_Tables_number\",\n",
    "        \"_chemical_formula_structural\",\n",
    "        \"_chemical_formula_sum\",\n",
    "        \"_cell_volume\",\n",
    "        \"_cell_formula_units_Z\",\n",
    "        \"symmetry_dict\",\n",
    "        \"formula_pretty\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def load_row(txn, row):\n",
    "    try:\n",
    "        data = pickle.loads(txn.get(f\"{row}\".encode(\"ascii\")))\n",
    "        return data\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def config_from_row(row: dict, row_num: int):\n",
    "    coords = row.pop(\"cart_coords\")\n",
    "    a_num = row.pop(\"atomic_numbers\")\n",
    "    cell = [\n",
    "        row.pop(x)\n",
    "        for x in [\n",
    "            \"_cell_length_a\",\n",
    "            \"_cell_length_b\",\n",
    "            \"_cell_length_c\",\n",
    "            \"_cell_angle_alpha\",\n",
    "            \"_cell_angle_beta\",\n",
    "            \"_cell_angle_gamma\",\n",
    "        ]\n",
    "    ]\n",
    "    symmetry_dict = {str(key): val for key, val in row.pop(\"symmetry_dict\").items()}\n",
    "    for key in symmetry_dict:\n",
    "        key = str(key)\n",
    "    info = {}\n",
    "    info = row\n",
    "    info[\"symmetry_dict\"] = symmetry_dict\n",
    "    info[\"_name\"] = f\"carolina_materials_{row_num}\"\n",
    "    if row_num % 10 == 0:\n",
    "        info[\"_labels\"] = [row_num % 10, \"bcc\"]\n",
    "    else:\n",
    "        info[\"_labels\"] = [row_num % 10, \"fcc\"]\n",
    "    config = AtomicConfiguration(\n",
    "        scaled_positions=coords,\n",
    "        numbers=a_num,\n",
    "        cell=cell,\n",
    "        info=info,\n",
    "    )\n",
    "    return config\n",
    "    # return AtomicConfiguration.from_ase(config)\n",
    "\n",
    "\n",
    "def carmat_reader(fp: Path):\n",
    "    parent = fp.parent\n",
    "    env = lmdb.open(str(parent))\n",
    "    txn = env.begin()\n",
    "    row_num = 0\n",
    "    rows = []\n",
    "    while row_num <= 10000:\n",
    "        row = load_row(txn, row_num)\n",
    "        if row is False:\n",
    "            env.close()\n",
    "            break\n",
    "        rows.append(row)\n",
    "        yield config_from_row(row, row_num)\n",
    "        row_num += 1\n",
    "    env.close()\n",
    "    return False\n",
    "    # return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"Quantum ESPRESSO\"},\n",
    "    \"method\": {\"value\": \"DFT-PBE\"},\n",
    "    \"input\": {\"field\": \"input\"},\n",
    "}\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "    \"cauchy-stress\": [\n",
    "        {\n",
    "            \"stress\": {\"field\": \"stress\", \"units\": \"GPa\"},\n",
    "            \"volume-normalized\": {\"value\": True, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": PI_METADATA,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB and run loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 14:49:53 WARN Utils: Your hostname, arktos resolves to a loopback address: 127.0.1.1; using 172.24.21.25 instead (on interface enp5s0)\n",
      "24/05/21 14:49:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/05/21 14:49:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/21 14:49:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 17:14:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtomicConfiguration(name=Unified_training_set_SiO2_1061, symbols='Si4', pbc=False, cell=[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1062/1062 [00:00<00:00, 2495.36it/s]\n"
     ]
    }
   ],
   "source": [
    "mtpu_configs = mtpu_reader(Path(\"data/mtpu_2023/Unified_training_set.cfg\"))\n",
    "\n",
    "PI_METADATA = {\n",
    "    \"software\": {\"value\": \"Quantum ESPRESSO\"},\n",
    "    \"method\": {\"value\": \"DFT-PBE\"},\n",
    "    \"input\": {\"field\": \"input\"},\n",
    "}\n",
    "PROPERTY_MAP = {\n",
    "    \"potential-energy\": [\n",
    "        {\n",
    "            \"energy\": {\"field\": \"energy\", \"units\": \"eV\"},\n",
    "            \"per-atom\": {\"value\": False, \"units\": None},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        }\n",
    "    ],\n",
    "    \"atomic-forces\": [\n",
    "        {\n",
    "            \"forces\": {\"field\": \"forces\", \"units\": \"eV/angstrom\"},\n",
    "            # \"_metadata\": PI_METADATA,\n",
    "        },\n",
    "    ],\n",
    "    \"cauchy-stress\": [\n",
    "        {\n",
    "            \"stress\": {\"field\": \"stress\", \"units\": \"GPa\"},\n",
    "            \"volume-normalized\": {\"value\": True, \"units\": None},\n",
    "        }\n",
    "    ],\n",
    "    \"_metadata\": PI_METADATA,\n",
    "}\n",
    "spark = SparkSession.builder.appName(\"ColabfitIngestData\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "# loader = SparkDataLoader(table_prefix=\"ndb.colabfit.dev\")\n",
    "# print(loader.spark)\n",
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "mtpu_configs = list(mtpu_configs)\n",
    "print(mtpu_configs[0])\n",
    "co_po_rows = []\n",
    "for config in tqdm(mtpu_configs):\n",
    "    config.set_dataset_id(mtpu_ds_id)\n",
    "    co_po_rows.append(\n",
    "        (\n",
    "            config.spark_row,\n",
    "            Property.from_definition(\n",
    "                [potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "                configuration=config,\n",
    "                property_map=PROPERTY_MAP,\n",
    "            ).spark_row,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CO_47706510123393079',\n",
       " 'hash': 47706510123393079,\n",
       " 'last_modified': datetime.datetime(2024, 5, 20, 17, 14, 41),\n",
       " 'dataset_ids': \"['DS_y7nrdsjtuwom_0']\",\n",
       " 'metadata': None,\n",
       " 'chemical_formula_hill': 'Si4',\n",
       " 'chemical_formula_reduced': 'Si',\n",
       " 'chemical_formula_anonymous': 'A',\n",
       " 'elements': \"['Si']\",\n",
       " 'elements_ratios': '[1.0]',\n",
       " 'atomic_numbers': '[14, 14, 14, 14]',\n",
       " 'nsites': 4,\n",
       " 'nelements': 1,\n",
       " 'nperiodic_dimensions': 0,\n",
       " 'cell': '[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]]',\n",
       " 'dimension_types': '[0, 0, 0]',\n",
       " 'pbc': '[False, False, False]',\n",
       " 'positions': '[[1.892001, 1.11132, 0.400465], [1.955509, -1.11132, 3.581973], [1.895339, -1.11132, -0.400508], [1.958847, 1.11132, 2.781]]',\n",
       " 'names': \"['Unified_training_set_Si_0']\",\n",
       " 'labels': None,\n",
       " 'configuration_set_ids': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_po_rows[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 5, 20, 17, 10, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateutil.parser.parse(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making co po rows\n",
      "making cos dataframes...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+--------+---------------+----------------+------+---------+--------------------+---------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------+------+---------------------+\n",
      "|id                  |hash             |last_modified      |dataset_ids          |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements|elements_ratios|atomic_numbers  |nsites|nelements|nperiodic_dimensions|cell                                                                                   |dimension_types|pbc                  |positions                                                                                                                   |names                        |labels|configuration_set_ids|\n",
      "+--------------------+-----------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+--------+---------------+----------------+------+---------+--------------------+---------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------+------+---------------------+\n",
      "|CO_47706510123393079|47706510123393079|2024-05-20 14:50:48|['DS_y7nrdsjtuwom_0']|NULL    |Si4                  |Si                      |A                         |['Si']  |[1.0]          |[14, 14, 14, 14]|4     |1        |0                   |[[3.85085, 0.0, 0.077017], [-1.925425, 3.334933, -0.038508], [0.127258, 0.0, 6.362934]]|[0, 0, 0]      |[False, False, False]|[[1.892001, 1.11132, 0.400465], [1.955509, -1.11132, 3.581973], [1.895339, -1.11132, -0.400508], [1.958847, 1.11132, 2.781]]|['Unified_training_set_Si_0']|NULL  |NULL                 |\n",
      "+--------------------+-----------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+--------+---------------+----------------+------+---------+--------------------+---------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------+-----------------------------+------+---------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "making pos dataframes...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 14:52:03 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+-------------------+------------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------+-------+---------------------+------------------+---------------------+-------------------------+--------------------------+-------------------------------+-------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------+---------------------------------------------------------------------------------------------------+------------------+-------------------------------+----------------------------------------------------------------+-----------+----------------+--------------------+---------------------+--------------------------+-----------------------+--------+-------------+--------------------+----------------+---------------------+-------------------------+--------------------------+-------------------------------+----------------------------+-----------------+----------------------+--------------------------+---------------------------+--------------------------------+-----------------------------+------------------+-----------------------+---------------------------+----------------------------+---------------------------------+------------------------------+\n",
      "|id                    |hash               |last_modified      |configuration_ids       |dataset_ids          |metadata                                                                                                                                      |software        |method |chemical_formula_hill|potential_energy  |potential_energy_unit|potential_energy_per_atom|potential_energy_reference|potential_energy_reference_unit|potential_energy_property_id                                       |atomic_forces                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |atomic_forces_unit|atomic_forces_property_id                                       |cauchy_stress                                                                                      |cauchy_stress_unit|cauchy_stress_volume_normalized|cauchy_stress_property_id                                       |free_energy|free_energy_unit|free_energy_per_atom|free_energy_reference|free_energy_reference_unit|free_energy_property_id|band_gap|band_gap_unit|band_gap_property_id|formation_energy|formation_energy_unit|formation_energy_per_atom|formation_energy_reference|formation_energy_reference_unit|formation_energy_property_id|adsorption_energy|adsorption_energy_unit|adsorption_energy_per_atom|adsorption_energy_reference|adsorption_energy_reference_unit|adsorption_energy_property_id|atomization_energy|atomization_energy_unit|atomization_energy_per_atom|atomization_energy_reference|atomization_energy_reference_unit|atomization_energy_property_id|\n",
      "+----------------------+-------------------+-------------------+------------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------+-------+---------------------+------------------+---------------------+-------------------------+--------------------------+-------------------------------+-------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------+---------------------------------------------------------------------------------------------------+------------------+-------------------------------+----------------------------------------------------------------+-----------+----------------+--------------------+---------------------+--------------------------+-----------------------+--------+-------------+--------------------+----------------+---------------------+-------------------------+--------------------------+-------------------------------+----------------------------+-----------------+----------------------+--------------------------+---------------------------+--------------------------------+-----------------------------+------------------+-----------------------+---------------------------+----------------------------+---------------------------------+------------------------------+\n",
      "|PO_2003168523045662242|2003168523045662242|2024-05-20 14:50:49|['CO_47706510123393079']|['DS_y7nrdsjtuwom_0']|{\"input\": {\"source-value\": {\"kpoint-scheme\": \"Monkhorst-Pack\", \"kpoints\": \"11x11x11\", \"kinetic-energy-cutoff\": {\"val\": 1224, \"units\": \"eV\"}}}}|Quantum ESPRESSO|DFT-PBE|Si4                  |-56728.65951244888|eV                   |false                    |NULL                      |NULL                           |tag:staff@noreply.colabfit.org,2022-05-30:property/potential-energy|[[-1.307001, -3.305329, 0.501694], [-1.815857, -0.600617, 0.624189], [1.912557, 0.354473, 1.447459], [-0.161398, -0.273099, -2.429205], [-0.92455, -0.150098, 0.4599], [4.065101, -1.468665, -3.960276], [2.140853, 0.431131, 0.288465], [3.324277, -2.891591, 6.727858], [-1.078694, -4.629049, 1.169419], [-1.319787, 0.148004, 0.923578], [1.263415, 4.336363, 1.627108], [1.799871, 1.279145, 3.09007], [-0.688661, 0.127691, -1.924473], [1.194187, 2.289872, -3.352281], [-1.132798, -1.485129, 0.445502], [-3.700676, 1.345486, -1.056471], [-1.382872, -2.926083, -0.069224], [0.153473, 3.059506, -1.609438], [-2.283929, -0.769204, 1.476819], [-1.397038, -0.067624, -4.369371], [2.339723, -0.435861, -0.297768], [1.034636, -0.324537, 0.326179], [-5.133888, -2.526026, 1.197923], [3.327067, -2.021916, 0.959912], [0.281083, 0.820745, 1.70475], [0.483573, 0.641728, -2.615248], [-0.569336, 4.593918, 0.945771], [-0.362087, -2.471122, -2.876315], [0.434516, -1.037523, -0.742051], [2.361054, 3.398039, 1.149889], [1.469941, -0.626202, 0.979442], [-0.513217, -2.419993, -1.786941], [1.223426, 2.576385, 1.050371], [2.192966, 0.197594, 0.779511], [-2.130271, 2.12008, -1.317546], [1.468473, -0.740308, 2.839747], [-0.719811, 1.336904, 0.589685], [-1.737935, -0.920449, -3.555091], [-3.184143, -1.577162, -0.659712], [3.319108, 0.17994, 0.426615], [-1.380915, 0.769328, 0.060247], [-0.798862, 1.113912, -0.07444], [2.863421, -4.495103, -4.21856], [-3.172958, 0.875188, 1.625066], [-1.210005, -0.178851, 2.872404], [-0.89463, 3.455713, -0.493049], [0.417235, 2.109289, 0.865831], [-1.176894, -1.682496, 0.878017], [5.26725, -0.585063, 2.4077], [0.274311, -3.93142, -3.758984], [3.242884, 1.330637, -2.186739], [-0.655241, 1.091822, 1.32207], [-1.175391, 3.262142, 1.374119], [-3.891631, 1.331415, -3.549729], [2.275142, -1.386012, -0.591006], [3.842275, -0.315738, -1.404016], [0.159816, -0.384073, 0.392911], [0.004942, -0.219493, -0.943408], [3.054466, 4.167322, 5.853929], [-0.752007, 1.722995, 1.342288], [2.723765, 1.526727, -0.339283], [-2.756187, -5.377137, 1.949582], [-1.504227, 0.572646, -0.960834], [0.341653, -0.487391, 0.151487], [-1.928436, -2.331554, -1.026119], [-3.53059, 1.574378, 0.276592], [1.346006, -0.957666, -0.560385], [-1.912128, 0.036422, -0.277023], [4.138143, 2.68424, -1.648554], [0.764966, 1.081516, -3.072373], [0.522132, 0.351893, -2.518365], [1.460958, 1.254345, 1.338509], [-0.573278, 1.468714, 2.025487], [0.872767, -0.764276, 2.133547], [-1.475243, -0.814517, -4.110673], [-0.515327, 0.728365, 2.820466], [0.215699, -1.506708, -0.584225], [-2.697704, 3.967172, -2.796206], [-2.063341, -1.264931, -2.566189], [1.193726, -1.179186, 1.46878], [-1.219672, 0.521594, -1.831927], [-0.179224, 0.330899, -0.120923], [2.41263, 1.498779, -3.003183], [1.179377, -0.822224, 1.833346], [0.45806, -2.752634, 0.196653], [2.510036, 0.095603, 2.500775], [-1.548816, -6.459747, -1.487248], [-2.018716, -0.219173, 2.716091], [-1.246968, 5.872639, -1.533989], [-0.504326, -0.628763, 4.180711], [0.227025, -2.519621, 1.982248], [0.156642, -1.849839, -1.251047], [-1.222998, 1.777937, 2.598652], [-1.109044, -1.776168, 2.011233], [-1.768196, -0.760899, 1.304636], [-1.287724, 3.50763, -2.685344]]|eV/angstrom       |tag:staff@noreply.colabfit.org,2022-05-30:property/atomic-forces|[[-51.55233, 5.42229, -7.89991], [5.42229, -37.25612, -32.74397], [-7.89991, -32.74397, -32.09729]]|GPa               |true                           |tag:staff@noreply.colabfit.org,2022-05-30:property/cauchy-stress|NULL       |NULL            |NULL                |NULL                 |NULL                      |NULL                   |NULL    |NULL         |NULL                |NULL            |NULL                 |NULL                     |NULL                      |NULL                           |NULL                        |NULL             |NULL                  |NULL                      |NULL                       |NULL                            |NULL                         |NULL              |NULL                   |NULL                       |NULL                        |NULL                             |NULL                          |\n",
      "+----------------------+-------------------+-------------------+------------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------+-------+---------------------+------------------+---------------------+-------------------------+--------------------------+-------------------------------+-------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------+---------------------------------------------------------------------------------------------------+------------------+-------------------------------+----------------------------------------------------------------+-----------+----------------+--------------------+---------------------+--------------------------+-----------------------+--------+-------------+--------------------+----------------+---------------------+-------------------------+--------------------------+-------------------------------+----------------------------+-----------------+----------------------+--------------------------+---------------------------+--------------------------------+-----------------------------+------------------+-----------------------+---------------------------+----------------------------+---------------------------------+------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "gpw_test_configs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 30.40% for 25 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 29.23% for 26 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 28.15% for 27 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 27.14% for 28 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 26.21% for 29 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 25.33% for 30 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 24.52% for 31 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 23.75% for 32 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 24.52% for 31 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 25.33% for 30 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 26.21% for 29 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 27.14% for 28 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 28.15% for 27 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 29.23% for 26 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 30.40% for 25 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/20 14:52:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpw_test_propobjects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 30.40% for 25 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/20 14:52:05 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"making co po rows\")\n",
    "    co_rows, po_rows = list(zip(*co_po_rows))\n",
    "    print(\"making cos dataframes...\")\n",
    "    cos_dataframe = spark.createDataFrame(co_rows, schema=config_schema)\n",
    "    print(\"Done!\")\n",
    "    print(cos_dataframe.show(1, False))\n",
    "    print(\"making pos dataframes...\")\n",
    "    pos_dataframe = spark.createDataFrame(po_rows, schema=property_object_schema)\n",
    "    print(\"Done!\")\n",
    "    pos_dataframe.show(1, False)\n",
    "    try:\n",
    "        # loader.write_table(\n",
    "        #     co_rows,\n",
    "        #     loader.config_table,\n",
    "        #     config_schema,\n",
    "        # )\n",
    "        # loader.write_table(\n",
    "        #     po_rows,\n",
    "        #     loader.prop_object_table,\n",
    "        #     property_object_schema,\n",
    "        # )\n",
    "        print(loader.config_table)\n",
    "        cos_dataframe.write.mode(\"append\").saveAsTable(loader.config_table)\n",
    "        print(loader.prop_object_table)\n",
    "        pos_dataframe.write.mode(\"append\").saveAsTable(loader.prop_object_table)\n",
    "    except:\n",
    "        print(\"loader write failed\")\n",
    "except:\n",
    "    print(\"error getting df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = loader.spark.read.jdbc(\n",
    "    url=url, table=\"configurations\", properties=properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_elem(col_array, elem):\n",
    "    print(col_array)\n",
    "    unstrung = eval(col_array)\n",
    "    unstrung.append(elem)\n",
    "    unstrung = list(set(unstrung))\n",
    "    return str(unstrung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+----------------+-----------------+----------------------------+------+---------+--------------------+-------------------------------------------------------------------------------------------------+---------------+---------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+----------+---------------------+\n",
      "|id                    |hash               |last_modified      |dataset_ids          |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements        |elements_ratios  |atomic_numbers              |nsites|nelements|nperiodic_dimensions|cell                                                                                             |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                            |names                      |labels    |configuration_set_ids|\n",
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+----------------+-----------------+----------------------------+------+---------+--------------------+-------------------------------------------------------------------------------------------------+---------------+---------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+----------+---------------------+\n",
      "|CO_1000272601413209564|1000272601413209564|2024-05-03 15:10:43|['DS_y7nrdsjtuw0g_0']|NULL    |In2N4Y2              |InN2Y                   |A2BC                      |['In', 'N', 'Y']|[0.25, 0.5, 0.25]|[39, 39, 49, 49, 7, 7, 7, 7]|8     |3        |0                   |[[3.42184625, 0.0, 0.0], [-1.7109231249999994, 2.9634057803445177, 0.0], [0.0, 0.0, 11.13673602]]|[0, 0, 0]      |[False, False, False]|[[0.0, 0.0, 0.0], [0.0, 0.0, 5.56836801], [-1.710923098524749e-08, 1.9756038634410311, 2.784184005], [1.7109231421092315, 0.9878019169034866, 8.352552015], [-1.710923098524749e-08, 1.9756038634410311, 6.919232818060203], [1.7109231421092315, 0.9878019169034866, 4.217503201939798], [1.7109231421092315, 0.9878019169034866, 1.350864808060202], [-1.710923098524749e-08, 1.9756038634410311, 9.7858712119398]]|['carolina_materials_4263']|[3, 'fcc']|NULL                 |\n",
      "+----------------------+-------------------+-------------------+---------------------+--------+---------------------+------------------------+--------------------------+----------------+-----------------+----------------------------+------+---------+--------------------+-------------------------------------------------------------------------------------------------+---------------+---------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+----------+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_df.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT: find a way to check wehther cs-ids is null and handle the column =+ cs_id as array\n",
    "# OR find a way to use the lambda function to use the user-defined function (append element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.BINARY_ARRAY_DIFF_TYPES] Cannot resolve \"array_union(configuration_set_ids, dataset_ids)\" due to data type mismatch: Input to function `array_union` should have been two \"ARRAY\" with same element type, but it's [\"STRING\", \"STRING\"].;\n'Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, CASE WHEN (has_labels#2158 = true) THEN array_union(configuration_set_ids#62, dataset_ids#45) END AS configuration_set_ids#2210, filter_labels#2111, labels_unstrung#2134, has_labels#2158, new_cs_id#2184]\n+- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, labels_unstrung#2134, has_labels#2158, test_config_set_id AS new_cs_id#2184]\n   +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, labels_unstrung#2134, forall(filter_labels#2111, lambdafunction(array_contains(labels_unstrung#2134, lambda x_28#2159), lambda x_28#2159, false)) AS has_labels#2158]\n      +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, from_json(ArrayType(StringType,true), labels#61, Some(America/New_York)) AS labels_unstrung#2134]\n         +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, array(fcc, cast(6 as string)) AS filter_labels#2111]\n            +- Relation [id#42,hash#43,last_modified#44,dataset_ids#45,metadata#46,chemical_formula_hill#47,chemical_formula_reduced#48,chemical_formula_anonymous#49,elements#50,elements_ratios#51,atomic_numbers#52,nsites#53,nelements#54,nperiodic_dimensions#55,cell#56,dimension_types#57,pbc#58,positions#59,names#60,labels#61,configuration_set_ids#62] JDBCRelation(configurations) [numPartitions=1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfcc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m      2\u001b[0m config_set_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_config_set_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[43mconfig_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels_unstrung\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArrayType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels_unstrung\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_cs_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_set_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfiguration_set_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhas_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_union\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfiguration_set_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# .otherwise(config_df[\"configuration_set_ids\"]),\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# .withColumn(\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     \"configuration_set_ids\",\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     sf.transform_values(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     10, False\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py:5174\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5171\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5172\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5173\u001b[0m     )\n\u001b[0;32m-> 5174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.BINARY_ARRAY_DIFF_TYPES] Cannot resolve \"array_union(configuration_set_ids, dataset_ids)\" due to data type mismatch: Input to function `array_union` should have been two \"ARRAY\" with same element type, but it's [\"STRING\", \"STRING\"].;\n'Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, CASE WHEN (has_labels#2158 = true) THEN array_union(configuration_set_ids#62, dataset_ids#45) END AS configuration_set_ids#2210, filter_labels#2111, labels_unstrung#2134, has_labels#2158, new_cs_id#2184]\n+- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, labels_unstrung#2134, has_labels#2158, test_config_set_id AS new_cs_id#2184]\n   +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, labels_unstrung#2134, forall(filter_labels#2111, lambdafunction(array_contains(labels_unstrung#2134, lambda x_28#2159), lambda x_28#2159, false)) AS has_labels#2158]\n      +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, filter_labels#2111, from_json(ArrayType(StringType,true), labels#61, Some(America/New_York)) AS labels_unstrung#2134]\n         +- Project [id#42, hash#43, last_modified#44, dataset_ids#45, metadata#46, chemical_formula_hill#47, chemical_formula_reduced#48, chemical_formula_anonymous#49, elements#50, elements_ratios#51, atomic_numbers#52, nsites#53, nelements#54, nperiodic_dimensions#55, cell#56, dimension_types#57, pbc#58, positions#59, names#60, labels#61, configuration_set_ids#62, array(fcc, cast(6 as string)) AS filter_labels#2111]\n            +- Relation [id#42,hash#43,last_modified#44,dataset_ids#45,metadata#46,chemical_formula_hill#47,chemical_formula_reduced#48,chemical_formula_anonymous#49,elements#50,elements_ratios#51,atomic_numbers#52,nsites#53,nelements#54,nperiodic_dimensions#55,cell#56,dimension_types#57,pbc#58,positions#59,names#60,labels#61,configuration_set_ids#62] JDBCRelation(configurations) [numPartitions=1]\n"
     ]
    }
   ],
   "source": [
    "labels = [\"fcc\", 6]\n",
    "config_set_id = \"test_config_set_id\"\n",
    "config_df.withColumn(\"filter_labels\", sf.lit(labels)).withColumn(\n",
    "    \"labels_unstrung\", sf.from_json(sf.col(\"labels\"), ArrayType(StringType()))\n",
    ").withColumn(\n",
    "    \"has_labels\",\n",
    "    sf.forall(\n",
    "        \"filter_labels\",\n",
    "        lambda x: sf.array_contains(col=sf.col(\"labels_unstrung\"), value=x),\n",
    "    ),\n",
    ").withColumn(\n",
    "    \"new_cs_id\", sf.lit([config_set_id])\n",
    ").withColumn(\n",
    "    \"configuration_set_ids\",\n",
    "    sf.when(\n",
    "        condition=sf.col(\"has_labels\") == True,\n",
    "        value=sf.array_union(config_df[\"configuration_set_ids\"], sf.col(\"dataset_ids\")),\n",
    "    ),\n",
    "    # .otherwise(config_df[\"configuration_set_ids\"]),\n",
    ")\n",
    "# .withColumn(\n",
    "#     \"configuration_set_ids\",\n",
    "#     sf.transform_values(\n",
    "#         \"configuration_set_ids\", lambda k, cs_ids: append_elem(cs_ids, config_set_id)\n",
    "#     ),\n",
    "# )\n",
    "# .show(\n",
    "#     10, False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = config_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='CO_1000272601413209564', hash='1000272601413209564', last_modified=datetime.datetime(2024, 5, 3, 15, 10, 43), dataset_ids=\"['DS_y7nrdsjtuw0g_0']\", metadata=None, chemical_formula_hill='In2N4Y2', chemical_formula_reduced='InN2Y', chemical_formula_anonymous='A2BC', elements=\"['In', 'N', 'Y']\", elements_ratios='[0.25, 0.5, 0.25]', atomic_numbers='[39, 39, 49, 49, 7, 7, 7, 7]', nsites=8, nelements=3, nperiodic_dimensions=0, cell='[[3.42184625, 0.0, 0.0], [-1.7109231249999994, 2.9634057803445177, 0.0], [0.0, 0.0, 11.13673602]]', dimension_types='[0, 0, 0]', pbc='[False, False, False]', positions='[[0.0, 0.0, 0.0], [0.0, 0.0, 5.56836801], [-1.710923098524749e-08, 1.9756038634410311, 2.784184005], [1.7109231421092315, 0.9878019169034866, 8.352552015], [-1.710923098524749e-08, 1.9756038634410311, 6.919232818060203], [1.7109231421092315, 0.9878019169034866, 4.217503201939798], [1.7109231421092315, 0.9878019169034866, 1.350864808060202], [-1.710923098524749e-08, 1.9756038634410311, 9.7858712119398]]', names=\"['carolina_materials_4263']\", labels=\"[3, 'fcc']\", configuration_set_ids=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_rdd = config_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rdd = config_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO_1000272601413209564\n",
      "1000272601413209564\n",
      "2024-05-03 15:10:43\n",
      "['DS_y7nrdsjtuw0g_0']\n",
      "None\n",
      "In2N4Y2\n",
      "InN2Y\n",
      "A2BC\n",
      "['In', 'N', 'Y']\n",
      "[0.25, 0.5, 0.25]\n",
      "[39, 39, 49, 49, 7, 7, 7, 7]\n",
      "8\n",
      "3\n",
      "0\n",
      "[[3.42184625, 0.0, 0.0], [-1.7109231249999994, 2.9634057803445177, 0.0], [0.0, 0.0, 11.13673602]]\n",
      "[0, 0, 0]\n",
      "[False, False, False]\n",
      "[[0.0, 0.0, 0.0], [0.0, 0.0, 5.56836801], [-1.710923098524749e-08, 1.9756038634410311, 2.784184005], [1.7109231421092315, 0.9878019169034866, 8.352552015], [-1.710923098524749e-08, 1.9756038634410311, 6.919232818060203], [1.7109231421092315, 0.9878019169034866, 4.217503201939798], [1.7109231421092315, 0.9878019169034866, 1.350864808060202], [-1.710923098524749e-08, 1.9756038634410311, 9.7858712119398]]\n",
      "['carolina_materials_4263']\n",
      "[3, 'fcc']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for x in first_rdd[0]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row({'id': 'CO_1000272601413209564', 'hash': '1000272601413209564', 'last_modified': datetime.datetime(2024, 5, 3, 15, 10, 43), 'dataset_ids': \"['DS_y7nrdsjtuw0g_0']\", 'metadata': None, 'chemical_formula_hill': 'In2N4Y2', 'chemical_formula_reduced': 'InN2Y', 'chemical_formula_anonymous': 'A2BC', 'elements': \"['In', 'N', 'Y']\", 'elements_ratios': '[0.25, 0.5, 0.25]', 'atomic_numbers': '[39, 39, 49, 49, 7, 7, 7, 7]', 'nsites': 8, 'nelements': 3, 'nperiodic_dimensions': 0, 'cell': '[[3.42184625, 0.0, 0.0], [-1.7109231249999994, 2.9634057803445177, 0.0], [0.0, 0.0, 11.13673602]]', 'dimension_types': '[0, 0, 0]', 'pbc': '[False, False, False]', 'positions': '[[0.0, 0.0, 0.0], [0.0, 0.0, 5.56836801], [-1.710923098524749e-08, 1.9756038634410311, 2.784184005], [1.7109231421092315, 0.9878019169034866, 8.352552015], [-1.710923098524749e-08, 1.9756038634410311, 6.919232818060203], [1.7109231421092315, 0.9878019169034866, 4.217503201939798], [1.7109231421092315, 0.9878019169034866, 1.350864808060202], [-1.710923098524749e-08, 1.9756038634410311, 9.7858712119398]]', 'names': \"['carolina_materials_4263']\", 'labels': \"[3, 'fcc']\", 'configuration_set_ids': None})>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Row(first_rdd[0].asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='CO_1000272601413209564', hash='1000272601413209564', last_modified=datetime.datetime(2024, 5, 3, 15, 10, 43), dataset_ids=['DS_y7nrdsjtuw0g_0'], metadata=None, chemical_formula_hill='In2N4Y2', chemical_formula_reduced='InN2Y', chemical_formula_anonymous='A2BC', elements=['In', 'N', 'Y'], elements_ratios=[0.25, 0.5, 0.25], atomic_numbers=[39, 39, 49, 49, 7, 7, 7, 7], nsites=8, nelements=3, nperiodic_dimensions=0, cell=[[3.42184625, 0.0, 0.0], [-1.7109231249999994, 2.9634057803445177, 0.0], [0.0, 0.0, 11.13673602]], dimension_types=[0, 0, 0], pbc=[False, False, False], positions=[[0.0, 0.0, 0.0], [0.0, 0.0, 5.56836801], [-1.710923098524749e-08, 1.9756038634410311, 2.784184005], [1.7109231421092315, 0.9878019169034866, 8.352552015], [-1.710923098524749e-08, 1.9756038634410311, 6.919232818060203], [1.7109231421092315, 0.9878019169034866, 4.217503201939798], [1.7109231421092315, 0.9878019169034866, 1.350864808060202], [-1.710923098524749e-08, 1.9756038634410311, 9.7858712119398]], names=['carolina_materials_4263'], labels=[3, 'fcc'], configuration_set_ids=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_rdd.map(unstringify).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconfig_rdd\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "config_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstringify(row):\n",
    "    row_dict = row.asDict()\n",
    "    for key, val in row_dict.items():\n",
    "        if isinstance(val, str) and len(val) > 0 and val[0] in [\"{\", \"[\"]:\n",
    "            dval = eval(row[key])\n",
    "            row_dict[key] = dval\n",
    "    new_row = Row(**row_dict)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.rdd  \n",
    "you can only parallelize one time so don't try to do a dataframe select from an rdd  \n",
    "updating to sdk 5.1 in a couple weeks  \n",
    "boto3 and s3 are the amazon file system interactions, mostly for adding metadata TO FILES (not to the database) and interacting with the files as FileExistsError. \n",
    "Make sure to spark.stop() at end of  python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: DS_y7nrdsjtuw0g_0\n"
     ]
    }
   ],
   "source": [
    "carmat_config_gen = carmat_reader(Path(\"data/carolina_matdb/base/all/data.mdb\"))\n",
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\"\n",
    "# carmat_ds_id2 = \"duplicate_ds_id\"\n",
    "dm = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=carmat_config_gen,\n",
    "    prop_defs=[formation_energy_pd],\n",
    "    prop_map=CM_PROPERTY_MAP,\n",
    "    dataset_id=carmat_ds_id,\n",
    ")\n",
    "# dm_dup = DataManager(\n",
    "#     nprocs=4,\n",
    "#     configs=carmat_config_gen,\n",
    "#     prop_defs=[formation_energy_pd],\n",
    "#     prop_map=CM_PROPERTY_MAP,\n",
    "#     dataset_id=carmat_ds_id2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: DS_y7nrdsjtuwom_0\n"
     ]
    }
   ],
   "source": [
    "mtpu_ds_id = \"DS_y7nrdsjtuwom_0\"\n",
    "dm2 = DataManager(\n",
    "    nprocs=4,\n",
    "    configs=mtpu_configs,\n",
    "    prop_defs=[potential_energy_pd, atomic_forces_pd, cauchy_stress_pd],\n",
    "    prop_map=PROPERTY_MAP,\n",
    "    dataset_id=mtpu_ds_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dm.gather_co_po_in_batches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = [x[0] for x in batch]\n",
    "cos_dataframe = loader.spark.createDataFrame(cos, schema=config_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rows = loader.spark.createDataFrame(cos, schema=config_schema).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'id': ['CO_2035392092515548233', 'CO_395357802651642160', 'CO_1353971176978508405', 'CO_673544646621950284', 'CO_1180491453360028556', 'CO_1235470615381239321', 'CO_1125763852340156480', 'CO_2185718778256801767', 'CO_1547613879869181226', 'CO_2262213674274439455', 'CO_2212061042677459331'], 'hash': ['2035392092515548233', '395357802651642160', '1353971176978508405', '673544646621950284', '1180491453360028556', '1235470615381239321', '1125763852340156480', '2185718778256801767', '1547613879869181226', '2262213674274439455', '2212061042677459331'], 'last_modified': [datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24), datetime.datetime(2024, 5, 8, 15, 17, 24)], 'dataset_ids': [\"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\", \"['DS_y7nrdsjtuw0g_0']\"], 'metadata': [None, None, None, None, None, None, None, None, None, None, None], 'chemical_formula_hill': ['H6BrCaRh2', 'H24Al4Co4Ti4', 'FeGe6InSn2', 'Au4F24Li4', 'Na2OsRuV6', 'Cr6FeOsRu2', 'FeMg2NiTi6', 'Au2InKPt6', 'Cl6MoSb2Sc', 'BCrIr2N6', 'Cr2NiPbSe6'], 'chemical_formula_reduced': ['BrCaH6Rh2', 'AlCoH6Ti', 'FeGe6InSn2', 'AuF6Li', 'Na2OsRuV6', 'Cr6FeOsRu2', 'FeMg2NiTi6', 'Au2InKPt6', 'Cl6MoSb2Sc', 'BCrIr2N6', 'Cr2NiPbSe6'], 'chemical_formula_anonymous': ['A6B2CD', 'A6BCD', 'A6B2CD', 'A6BC', 'A6B2CD', 'A6B2CD', 'A6B2CD', 'A6B2CD', 'A6B2CD', 'A6B2CD', 'A6B2CD'], 'elements': [\"['Br', 'Ca', 'H', 'Rh']\", \"['Al', 'Co', 'H', 'Ti']\", \"['Fe', 'Ge', 'In', 'Sn']\", \"['Au', 'F', 'Li']\", \"['Na', 'Os', 'Ru', 'V']\", \"['Cr', 'Fe', 'Os', 'Ru']\", \"['Fe', 'Mg', 'Ni', 'Ti']\", \"['Au', 'In', 'K', 'Pt']\", \"['Cl', 'Mo', 'Sb', 'Sc']\", \"['B', 'Cr', 'Ir', 'N']\", \"['Cr', 'Ni', 'Pb', 'Se']\"], 'elements_ratios': ['[0.1, 0.1, 0.6, 0.2]', '[0.1111111111111111, 0.1111111111111111, 0.6666666666666666, 0.1111111111111111]', '[0.1, 0.6, 0.1, 0.2]', '[0.125, 0.75, 0.125]', '[0.2, 0.1, 0.1, 0.6]', '[0.6, 0.1, 0.1, 0.2]', '[0.1, 0.2, 0.1, 0.6]', '[0.2, 0.1, 0.1, 0.6]', '[0.6, 0.1, 0.2, 0.1]', '[0.1, 0.1, 0.2, 0.6]', '[0.2, 0.1, 0.1, 0.6]'], 'atomic_numbers': ['[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]', '[22, 22, 22, 22, 13, 13, 13, 13, 27, 27, 27, 27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]', '[26, 32, 32, 32, 32, 32, 32, 49, 50, 50]', '[3, 3, 3, 3, 79, 79, 79, 79, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]', '[11, 11, 76, 44, 23, 23, 23, 23, 23, 23]', '[24, 24, 24, 24, 24, 24, 26, 76, 44, 44]', '[26, 12, 12, 28, 22, 22, 22, 22, 22, 22]', '[79, 79, 49, 19, 78, 78, 78, 78, 78, 78]', '[17, 17, 17, 17, 17, 17, 42, 51, 51, 21]', '[5, 24, 77, 77, 7, 7, 7, 7, 7, 7]', '[24, 24, 28, 82, 34, 34, 34, 34, 34, 34]'], 'nsites': [10, 36, 10, 32, 10, 10, 10, 10, 10, 10, 10], 'nelements': [4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4], 'nperiodic_dimensions': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'cell': ['[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]', '[[6.15561698, 0.0, 0.0], [0.0, 6.15561698, 0.0], [0.0, 0.0, 6.15561698]]', '[[7.43156319, 0.0, 0.0], [3.715781595000001, 6.435922512369321, 0.0], [3.715781595000001, 2.1453075041231076, 6.067845935583344]]', '[[7.15089046, 0.0, 0.0], [0.0, 7.15089046, 0.0], [0.0, 0.0, 7.15089046]]', '[[6.54034444, 0.0, 0.0], [3.270172219497596, 5.6641035341639325, 0.0], [3.2701714405023883, 1.888034661305724, 5.34016844849794]]', '[[6.07158833, 0.0, 0.0], [3.035794165000001, 5.258149735101135, 0.0], [3.035794165000001, 1.7527165783670453, 4.957431112245681]]', '[[6.56086252, 0.0, 0.0], [3.2804312600000007, 5.681873613057189, 0.0], [3.2804312600000007, 1.8939578710190634, 5.356921815516864]]', '[[7.12091764, 0.0, 0.0], [3.560458820000001, 6.166895574496731, 0.0], [3.560458820000001, 2.0556318581655777, 5.814204906127931]]', '[[6.99866541, 0.0, 0.0], [3.499332705000001, 6.061022037647434, 0.0], [3.499332705000001, 2.0203406792158116, 5.714386378322141]]', '[[5.43784303, 0.0, 0.0], [2.7189215150000003, 4.7093102057721445, 0.0], [2.7189215150000003, 1.5697700685907152, 4.439980241616666]]', '[[7.06578183, 0.0, 0.0], [3.5328909150000007, 6.119146562378499, 0.0], [3.5328909150000007, 2.0397155207928335, 5.76918670577625]]'], 'dimension_types': ['[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]', '[0, 0, 0]'], 'pbc': ['[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]', '[False, False, False]'], 'positions': ['[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]', '[[1.538904245, 1.538904245, 4.616712735], [1.538904245, 4.616712735, 1.538904245], [4.616712735, 1.538904245, 1.538904245], [4.616712735, 4.616712735, 4.616712735], [0.0, 0.0, 0.0], [0.0, 3.07780849, 3.07780849], [3.07780849, 0.0, 3.07780849], [3.07780849, 3.07780849, 0.0], [1.538904245, 1.538904245, 1.538904245], [1.538904245, 4.616712735, 4.616712735], [4.616712735, 1.538904245, 4.616712735], [4.616712735, 4.616712735, 1.538904245], [3.07780849, 1.3692779705893465, 0.0], [0.0, 1.7085305194106533, 0.0], [1.7085305194106533, 0.0, 0.0], [4.447086460589347, 0.0, 0.0], [3.07780849, 0.0, 4.786339009410653], [3.07780849, 0.0, 1.3692779705893465], [3.07780849, 4.447086460589347, 3.07780849], [0.0, 4.786339009410653, 3.07780849], [1.7085305194106533, 3.07780849, 3.07780849], [4.447086460589347, 3.07780849, 3.07780849], [3.07780849, 3.07780849, 1.7085305194106533], [3.07780849, 3.07780849, 4.447086460589347], [0.0, 1.3692779705893465, 3.07780849], [3.07780849, 1.7085305194106533, 3.07780849], [4.786339009410653, 0.0, 3.07780849], [1.3692779705893465, 0.0, 3.07780849], [0.0, 0.0, 1.7085305194106533], [0.0, 0.0, 4.447086460589347], [0.0, 4.447086460589347, 0.0], [3.07780849, 4.786339009410653, 0.0], [4.786339009410653, 3.07780849, 0.0], [1.3692779705893465, 3.07780849, 0.0], [0.0, 3.07780849, 4.786339009410653], [0.0, 3.07780849, 1.3692779705893465]]', '[[0.0, 0.0, 0.0], [1.8578907975000005, 1.0726537520615538, 3.033922967791672], [5.573672392500001, 1.0726537520615538, 3.033922967791672], [5.573672392500001, 3.2179612561846604, 0.0], [1.8578907975000005, 3.2179612561846604, 0.0], [3.715781595000001, 4.290615008246214, 3.033922967791672], [3.715781595, 0.0, 0.0], [7.431563190000001, 4.290615008246214, 3.033922967791672], [11.147344785000001, 6.435922512369322, 4.550884451687509], [3.7157815950000006, 2.145307504123107, 1.516961483895836]]', '[[5.363167845, 1.787722615, 1.787722615], [5.363167845, 5.363167845, 5.363167845], [1.787722615, 1.787722615, 5.363167845], [1.787722615, 5.363167845, 1.787722615], [0.0, 0.0, 0.0], [0.0, 3.57544523, 3.57544523], [3.57544523, 0.0, 3.57544523], [3.57544523, 3.57544523, 0.0], [3.620749124438093, 1.787722615, 5.363167845], [5.363167845, 3.530141335561907, 5.363167845], [7.105586565561907, 1.787722615, 5.363167845], [5.363167845, 0.0453038944380932, 5.363167845], [5.363167845, 1.787722615, 7.105586565561907], [5.363167845, 1.787722615, 3.620749124438093], [3.620749124438093, 5.363167845, 1.787722615], [5.363167845, 7.105586565561907, 1.787722615], [7.105586565561907, 5.363167845, 1.787722615], [5.363167845, 3.620749124438093, 1.787722615], [5.363167845, 5.363167845, 3.530141335561907], [5.363167845, 5.363167845, 0.0453038944380932], [0.0453038944380932, 1.787722615, 1.787722615], [1.787722615, 3.530141335561907, 1.787722615], [3.530141335561907, 1.787722615, 1.787722615], [1.787722615, 0.0453038944380932, 1.787722615], [1.787722615, 1.787722615, 3.530141335561907], [1.787722615, 1.787722615, 0.0453038944380932], [0.0453038944380932, 5.363167845, 5.363167845], [1.787722615, 7.105586565561907, 5.363167845], [3.530141335561907, 5.363167845, 5.363167845], [1.787722615, 3.620749124438093, 5.363167845], [1.787722615, 5.363167845, 7.105586565561907], [1.787722615, 5.363167845, 3.620749124438093]]', '[[9.810516074999988, 5.664103646602243, 4.005126336373455], [3.270172024999996, 1.8880345488674142, 1.335042112124485], [6.540344049999992, 3.7760690977348284, 2.67008422424897], [0.0, 0.0, 0.0], [6.540343852814592, 5.685263151876927, 4.020088366930772], [6.540344247185392, 1.8668750435927293, 1.320080081567168], [8.193755028579922, 4.730666067956665, 1.320080081567168], [4.886933071420062, 2.821472127512991, 4.020088366930772], [8.193754634717157, 2.821472127512991, 4.020088366930772], [4.886933465282827, 4.730666067956665, 1.320080081567168]]', '[[1.5178970825000004, 0.8763582891835227, 2.4787155561228404], [4.553691247500001, 0.8763582891835227, 2.4787155561228404], [4.553691247500001, 2.6290748675505675, 0.0], [1.5178970825000004, 2.6290748675505675, 0.0], [3.035794165000001, 3.50543315673409, 2.4787155561228404], [3.035794165, 0.0, 0.0], [0.0, 0.0, 0.0], [6.071588330000001, 3.50543315673409, 2.4787155561228404], [9.107382495000001, 5.258149735101135, 3.7180733341842607], [3.0357941650000004, 1.752716578367045, 1.2393577780614202]]', '[[6.560862520000001, 3.7879157420381264, 2.678460907758432], [9.84129378, 5.68187361305719, 4.017691361637648], [3.2804312600000003, 1.8939578710190632, 1.339230453879216], [0.0, 0.0, 0.0], [1.6402156300000004, 0.9469789355095317, 2.678460907758432], [4.92064689, 0.9469789355095317, 2.678460907758432], [4.92064689, 2.8409368065285947, 0.0], [1.6402156300000004, 2.8409368065285947, 0.0], [3.2804312600000007, 3.7879157420381264, 2.678460907758432], [3.28043126, 0.0, 0.0]]', '[[10.681376460000001, 6.166895574496731, 4.3606536795959485], [3.5604588200000005, 2.0556318581655773, 1.4535512265319828], [0.0, 0.0, 0.0], [7.120917640000001, 4.1112637163311545, 2.9071024530639655], [1.7802294100000005, 1.0278159290827888, 2.9071024530639655], [5.3406882300000005, 1.0278159290827888, 2.9071024530639655], [5.3406882300000005, 3.0834477872483657, 0.0], [1.7802294100000005, 3.0834477872483657, 0.0], [3.560458820000001, 4.1112637163311545, 2.9071024530639655], [3.56045882, 0.0, 0.0]]', '[[6.998665410000002, 6.008416891923776, 4.248592328475101], [6.998665410000001, 2.0729458249394694, 1.4657940498470403], [8.70277436993353, 5.0245491251777, 1.4657940498470403], [5.294556450066471, 3.0568135916855463, 4.248592328475101], [8.70277436993353, 3.0568135916855463, 4.248592328475101], [5.294556450066471, 5.0245491251777, 1.4657940498470403], [6.998665410000001, 4.040681358431623, 2.8571931891610705], [10.497998115000001, 6.061022037647435, 4.285789783741606], [3.4993327050000005, 2.0203406792158116, 1.4285965945805352], [0.0, 0.0, 0.0]]', '[[0.0, 0.0, 0.0], [5.43784303, 3.13954013718143, 2.219990120808333], [8.156764545, 4.7093102057721445, 3.329985181212499], [2.718921515, 1.569770068590715, 1.1099950604041664], [1.3594607575000002, 0.7848850342953576, 2.219990120808333], [4.0783822725, 0.7848850342953576, 2.219990120808333], [4.0783822725, 2.3546551028860723, 0.0], [1.3594607575000002, 2.3546551028860723, 0.0], [2.7189215150000003, 3.13954013718143, 2.219990120808333], [2.718921515, 0.0, 0.0]]', '[[10.598672745000002, 6.119146562378499, 4.326890029332188], [3.5328909150000003, 2.039715520792833, 1.4422966764440626], [7.065781830000001, 4.079431041585666, 2.884593352888125], [0.0, 0.0, 0.0], [7.065781830000001, 5.946989105985988, 4.205156324485215], [7.065781829999999, 2.211872977185344, 1.5640303812910343], [8.683134556813174, 5.013210073785827, 1.5640303812910343], [5.448429103186826, 3.1456520093855054, 4.205156324485215], [8.683134556813172, 3.1456520093855054, 4.205156324485215], [5.448429103186826, 5.013210073785827, 1.5640303812910343]]'], 'names': [\"['carolina_materials_0']\", \"['carolina_materials_1']\", \"['carolina_materials_2']\", \"['carolina_materials_3']\", \"['carolina_materials_4']\", \"['carolina_materials_5']\", \"['carolina_materials_6']\", \"['carolina_materials_7']\", \"['carolina_materials_8']\", \"['carolina_materials_9']\", \"['carolina_materials_10']\"], 'labels': [\"[0, 'bcc']\", \"[1, 'fcc']\", \"[2, 'fcc']\", \"[3, 'fcc']\", \"[4, 'fcc']\", \"[5, 'fcc']\", \"[6, 'fcc']\", \"[7, 'fcc']\", \"[8, 'fcc']\", \"[9, 'fcc']\", \"[0, 'bcc']\"], 'configuration_set_ids': [None, None, None, None, None, None, None, None, None, None, None]})\n"
     ]
    }
   ],
   "source": [
    "row_dict = defaultdict(list)\n",
    "for i, row in enumerate(rows):\n",
    "    if i > 10:\n",
    "        break\n",
    "    for key, val in row.asDict().items():\n",
    "        row_dict[key].append(val)\n",
    "print(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "config_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), False),\n",
    "        StructField(\"hash\", StringType(), False),\n",
    "        StructField(\"last_modified\", TimestampType(), False),\n",
    "        StructField(\"dataset_ids\", StringType(), True),  # ArrayType(StringType())\n",
    "        StructField(\"metadata\", StringType(), True),\n",
    "        StructField(\"chemical_formula_hill\", StringType(), True),\n",
    "        StructField(\"chemical_formula_reduced\", StringType(), True),\n",
    "        StructField(\"chemical_formula_anonymous\", StringType(), True),\n",
    "        StructField(\"elements\", StringType(), True),  # ArrayType(StringType())\n",
    "        StructField(\"elements_ratios\", StringType(), True),  # ArrayType(IntegerType())\n",
    "        StructField(\"atomic_numbers\", StringType(), True),  # ArrayType(IntegerType())\n",
    "        StructField(\"nsites\", IntegerType(), True),\n",
    "        StructField(\"nelements\", IntegerType(), True),\n",
    "        StructField(\"nperiodic_dimensions\", IntegerType(), True),\n",
    "        StructField(\"cell\", StringType(), True),  # ArrayType(ArrayType(DoubleType()))\n",
    "        StructField(\"dimension_types\", StringType(), True),  # ArrayType(IntegerType())\n",
    "        StructField(\"pbc\", StringType(), True),  # ArrayType(IntegerType())\n",
    "        StructField(\n",
    "            \"positions\", StringType(), True\n",
    "        ),  # ArrayType(ArrayType(DoubleType()))\n",
    "        StructField(\"names\", StringType(), True),  # ArrayType(StringType()),\n",
    "        StructField(\"labels\", StringType(), True),  # ArrayType(StringType())\n",
    "        StructField(\n",
    "            \"configuration_set_ids\", StringType(), True\n",
    "        ),  # ArrayType(StringType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def convert_type(spark_type):\n",
    "    type_name = spark_type.dataType.typeName()\n",
    "    if type_name in data_type_map:\n",
    "        print(data_type_map[type_name])\n",
    "        return pa.field(spark_type.name, data_type_map[type_name])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported PySpark data type: {spark_type}\")\n",
    "\n",
    "\n",
    "# data_type_map = {\n",
    "#     StringType: pa.string(),\n",
    "#     IntegerType: pa.int32(),\n",
    "#     FloatType: pa.float64(),\n",
    "#     DoubleType: pa.float64(),\n",
    "#     BooleanType: pa.bool_(),\n",
    "#     TimestampType: pa.timestamp(\"ns\"),\n",
    "#     # DateType: pa.date32(),\n",
    "#     ArrayType: lambda dt: pa.list_(convert_type(dt)),\n",
    "#     StructType: lambda st: pa.struct([convert_type(f) for f in st.fields]),\n",
    "# }\n",
    "data_type_map = {\n",
    "    \"string\": pa.string(),\n",
    "    \"integer\": pa.int32(),\n",
    "    \"float\": pa.float64(),\n",
    "    # DoubleType: pa.float64(),\n",
    "    # BooleanType: pa.bool_(),\n",
    "    \"timestamp\": pa.timestamp(\"ns\"),\n",
    "    # DateType: pa.date32(),\n",
    "    # ArrayType: lambda dt: pa.list_(convert_type(dt)),\n",
    "    \"struct\": lambda st: pa.struct([convert_type(f) for f in st.fields]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set_query = (\n",
    "    cos_dataframe.withColumn(\n",
    "        \"names_unstrung\", sf.from_json(sf.col(\"names\"), ArrayType(StringType()))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"labels_unstrung\",\n",
    "        sf.from_json(sf.col(\"labels\"), ArrayType(StringType())),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"dataset_ids_unstrung\", sf.from_json(\"dataset_ids\", ArrayType(StringType()))\n",
    "    )\n",
    "    .drop(\"names\", \"labels\", \"dataset_ids\")\n",
    "    .withColumnRenamed(\"names_unstrung\", \"names\")\n",
    "    .withColumnRenamed(\"labels_unstrung\", \"labels\")\n",
    "    .withColumnRenamed(\"dataset_ids_unstrung\", \"dataset_ids\")\n",
    "    .filter(sf.array_contains(sf.col(\"dataset_ids\"), carmat_ds_id))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "|id                    |hash               |last_modified      |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements               |elements_ratios     |atomic_numbers                    |nsites|nelements|nperiodic_dimensions|cell                                                                                                                               |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |configuration_set_ids|names                 |labels  |dataset_ids        |\n",
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "|CO_2035392092515548233|2035392092515548233|2024-05-08 15:42:38|NULL    |H6BrCaRh2            |BrCaH6Rh2               |A6B2CD                    |['Br', 'Ca', 'H', 'Rh']|[0.1, 0.1, 0.6, 0.2]|[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]|10    |4        |0                   |[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]|[0, 0, 0]      |[False, False, False]|[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]|NULL                 |[carolina_materials_0]|[0, bcc]|[DS_y7nrdsjtuw0g_0]|\n",
      "+----------------------+-------------------+-------------------+--------+---------------------+------------------------+--------------------------+-----------------------+--------------------+----------------------------------+------+---------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+----------------------+--------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_set_query.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "|id                   |hash              |last_modified      |metadata|chemical_formula_hill|chemical_formula_reduced|chemical_formula_anonymous|elements                |elements_ratios     |atomic_numbers                          |nsites|nelements|nperiodic_dimensions|cell                                                                                                                            |dimension_types|pbc                  |positions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |configuration_set_ids|labels  |dataset_ids        |labels_exploded|names_exploded        |\n",
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "|CO_623768866906050502|623768866906050502|2024-05-08 15:17:24|NULL    |Cd6MgSeTe2           |Cd6MgSeTe2              |A6B2CD                    |['Cd', 'Mg', 'Se', 'Te']|[0.6, 0.1, 0.1, 0.2]|[48, 48, 48, 48, 48, 48, 12, 34, 52, 52]|10    |4        |0                   |[[8.10975373, 0.0, 0.0], [4.054876866668527, 7.023251338917589, 0.0], [4.054875643331443, 2.341084015070624, 6.621585529535167]]|[0, 0, 0]      |[False, False, False]|[[2.0274378216657216, 1.170542007535312, 3.3107927647675837], [6.082314686665722, 1.170542007535312, 3.3107927647675837], [6.082315298334263, 3.5116256694587946, 0.0], [2.0274384333342637, 3.5116256694587946, 0.0], [4.054876254999986, 4.682167676994107, 3.3107927647675837], [4.054876865, 0.0, 0.0], [0.0, 0.0, 0.0], [8.109753119999985, 4.682167676994107, 3.3107927647675837], [12.164629679999976, 7.02325151549116, 4.9661891471513755], [4.054876559999992, 2.3410838384970534, 1.6553963823837918]]|NULL                 |[1, fcc]|[DS_y7nrdsjtuw0g_0]|1              |carolina_materials_101|\n",
      "+---------------------+------------------+-------------------+--------+---------------------+------------------------+--------------------------+------------------------+--------------------+----------------------------------------+------+---------+--------------------+--------------------------------------------------------------------------------------------------------------------------------+---------------+---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------+--------+-------------------+---------------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_match = \"fcc|1\"\n",
    "names_match = \"materials_10\"\n",
    "if names_match:\n",
    "    config_set_query = (\n",
    "        config_set_query.withColumn(\"labels_exploded\", sf.explode(sf.col(\"labels\")))\n",
    "        .withColumn(\"names_exploded\", sf.explode(sf.col(\"names\")))\n",
    "        .drop(\"names\")\n",
    "        .filter(sf.regexp_like(sf.col(\"names_exploded\"), sf.lit(rf\"{names_match}\")))\n",
    "    )\n",
    "if label_match:\n",
    "    config_set_query = config_set_query.filter(\n",
    "        sf.regexp_like(sf.col(\"labels_exploded\"), sf.lit(rf\"{label_match}\"))\n",
    "    )\n",
    "config_set_query.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\n[PARSE_SYNTAX_ERROR] Syntax error at or near '('.(line 1, pos 60)\n\n== SQL ==\nUPDATE config_table SET configuration_set_ids = array_append(configuration_set_ids, %s) WHERE id = %s\n------------------------------------------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUPDATE config_table SET configuration_set_ids = array_append(configuration_set_ids, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m) WHERE id = \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;241m%\u001b[39m (config_set\u001b[38;5;241m.\u001b[39mid, co_ids)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near '('.(line 1, pos 60)\n\n== SQL ==\nUPDATE config_table SET configuration_set_ids = array_append(configuration_set_ids, %s) WHERE id = %s\n------------------------------------------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "loader.spark.sql(\n",
    "    \"UPDATE config_table SET configuration_set_ids = array_append(configuration_set_ids, %s) WHERE id = %s\"\n",
    ") % (config_set.id, co_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.configuration_set import ConfigurationSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import colabfit.tools.configuration_set\n",
    "\n",
    "reload(colabfit.tools.configuration_set)\n",
    "ConfigurationSet = colabfit.tools.configuration_set.ConfigurationSet\n",
    "reload(colabfit.tools.database)\n",
    "from colabfit.tools.database import DataManager, PGDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ids = [x[0] for x in config_set_query.select(\"id\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CO_1180491453360028556',\n",
       " 'CO_879568364406847005',\n",
       " 'CO_881342345556419709',\n",
       " 'CO_395357802651642160',\n",
       " 'CO_107450829658643358',\n",
       " 'CO_2096618530829203889',\n",
       " 'CO_991509346356160256',\n",
       " 'CO_1491805601289580349',\n",
       " 'CO_917048308752776257',\n",
       " 'CO_1690862290738836150',\n",
       " 'CO_874500111687326151',\n",
       " 'CO_1125763852340156480',\n",
       " 'CO_797754777732167492',\n",
       " 'CO_1964436062852611062',\n",
       " 'CO_1559941325392132777',\n",
       " 'CO_1353971176978508405',\n",
       " 'CO_286992457615631475',\n",
       " 'CO_1552121326771475428',\n",
       " 'CO_1325933560876578330',\n",
       " 'CO_938770350513000754',\n",
       " 'CO_387863327590048542',\n",
       " 'CO_37932453843969185',\n",
       " 'CO_1638546733562907466',\n",
       " 'CO_1425676531260078729',\n",
       " 'CO_1105782185213068538',\n",
       " 'CO_326107300816987243',\n",
       " 'CO_1615978422284641163',\n",
       " 'CO_1047317511485860216',\n",
       " 'CO_48167453662657190',\n",
       " 'CO_1586766357518215377',\n",
       " 'CO_856131307896983346',\n",
       " 'CO_1554352833473561771',\n",
       " 'CO_2035392092515548233',\n",
       " 'CO_2162096324626582854',\n",
       " 'CO_127707683762503658',\n",
       " 'CO_617556824345540542',\n",
       " 'CO_59433596177554941',\n",
       " 'CO_1460354838643739968',\n",
       " 'CO_136467605327415650',\n",
       " 'CO_1135071293321342277',\n",
       " 'CO_841787241748058532',\n",
       " 'CO_605029711735679659',\n",
       " 'CO_1010611758166691856',\n",
       " 'CO_214185376754616867',\n",
       " 'CO_317250348994718832',\n",
       " 'CO_673544646621950284',\n",
       " 'CO_2167099522172622221',\n",
       " 'CO_1644769498282846866',\n",
       " 'CO_2032497799669891891',\n",
       " 'CO_1963975265037538901',\n",
       " 'CO_2262213674274439455',\n",
       " 'CO_2190529634182785571',\n",
       " 'CO_563095847311236520',\n",
       " 'CO_327247612523809682',\n",
       " 'CO_239622624826151532',\n",
       " 'CO_1430609521724441362',\n",
       " 'CO_1552565185279142468',\n",
       " 'CO_1079941838018600978',\n",
       " 'CO_308595752119487748',\n",
       " 'CO_1679931936552430934',\n",
       " 'CO_2123706393445453640',\n",
       " 'CO_634062981721297674',\n",
       " 'CO_304051967086874413',\n",
       " 'CO_2173104062481154715',\n",
       " 'CO_1018254598129634395',\n",
       " 'CO_1102304604278435316',\n",
       " 'CO_1351246373951899456',\n",
       " 'CO_1041039698219852306',\n",
       " 'CO_2284226135634673031',\n",
       " 'CO_444915867447615811',\n",
       " 'CO_1187677501740202156',\n",
       " 'CO_2025966802230431199',\n",
       " 'CO_1815404839234771369',\n",
       " 'CO_1718459276981952402',\n",
       " 'CO_1174732479090147539',\n",
       " 'CO_1719300653559835829',\n",
       " 'CO_1684899153450531667',\n",
       " 'CO_989071680899203485',\n",
       " 'CO_1547613879869181226',\n",
       " 'CO_2116473803830262738',\n",
       " 'CO_1297119512223967748',\n",
       " 'CO_1687959544212867145',\n",
       " 'CO_61576716534658773',\n",
       " 'CO_1406748820419026783',\n",
       " 'CO_2095297599535879065',\n",
       " 'CO_302678333704197145',\n",
       " 'CO_1187906194275625646',\n",
       " 'CO_1201309863912935325',\n",
       " 'CO_1922216762739652501',\n",
       " 'CO_1766495728633439201',\n",
       " 'CO_2185718778256801767',\n",
       " 'CO_1985622116550953234',\n",
       " 'CO_1779864385013928352',\n",
       " 'CO_365169254542735974',\n",
       " 'CO_1722050782079661576',\n",
       " 'CO_839993440316508608',\n",
       " 'CO_1810589422999004360',\n",
       " 'CO_1054909344078236861',\n",
       " 'CO_1047171435645733050',\n",
       " 'CO_2014006906189120081',\n",
       " 'CO_924753926225048018',\n",
       " 'CO_2017125241682724399',\n",
       " 'CO_2212061042677459331',\n",
       " 'CO_358460418735234895',\n",
       " 'CO_910235970341668149',\n",
       " 'CO_819393372733858311',\n",
       " 'CO_1934402735967578873',\n",
       " 'CO_318461301908713043',\n",
       " 'CO_99195291748313748',\n",
       " 'CO_342513275744996586',\n",
       " 'CO_1574443456192458541',\n",
       " 'CO_1750377268567354576',\n",
       " 'CO_1235470615381239321',\n",
       " 'CO_623768866906050502',\n",
       " 'CO_395317077366631497',\n",
       " 'CO_2001005134883292837',\n",
       " 'CO_450993817091908761',\n",
       " 'CO_435671140541231519',\n",
       " 'CO_2188733907476285599',\n",
       " 'CO_662435595682830050',\n",
       " 'CO_1798876475467037465',\n",
       " 'CO_1151196454506540694',\n",
       " 'CO_773477126713218182',\n",
       " 'CO_1760164698467056346',\n",
       " 'CO_201032826204010849',\n",
       " 'CO_95054913971174818',\n",
       " 'CO_804762005533678933',\n",
       " 'CO_2175475847735012681',\n",
       " 'CO_1922906590474643424',\n",
       " 'CO_104109532377306496',\n",
       " 'CO_674359878401721258',\n",
       " 'CO_1095474025394680735',\n",
       " 'CO_707344918040941371',\n",
       " 'CO_576986191851192833',\n",
       " 'CO_980985502509234263',\n",
       " 'CO_1275575258194123751',\n",
       " 'CO_695967646206254961',\n",
       " 'CO_2218528730164275833',\n",
       " 'CO_2207032321128668651',\n",
       " 'CO_1910726310049937830',\n",
       " 'CO_2106308473511869117',\n",
       " 'CO_1520968960689126169',\n",
       " 'CO_1722784389607902829',\n",
       " 'CO_1956058272248688737',\n",
       " 'CO_1125303585412654538',\n",
       " 'CO_242363702441497120',\n",
       " 'CO_1759603227324911152',\n",
       " 'CO_1153069182081072573',\n",
       " 'CO_1544736045927770138',\n",
       " 'CO_825843162496493229',\n",
       " 'CO_1589678671933965305',\n",
       " 'CO_7485534094663885',\n",
       " 'CO_2176972901038814602',\n",
       " 'CO_1105634525240684146',\n",
       " 'CO_487359911927142497',\n",
       " 'CO_190880188794030177',\n",
       " 'CO_1314241653325849538',\n",
       " 'CO_1563285587649065137',\n",
       " 'CO_1240464946698617569',\n",
       " 'CO_1009257703152363877',\n",
       " 'CO_2145985764733355204',\n",
       " 'CO_1863899344082606473',\n",
       " 'CO_886041775339294029',\n",
       " 'CO_45330255856949657',\n",
       " 'CO_1701877546274010488',\n",
       " 'CO_1376050968201193730',\n",
       " 'CO_1405548672760545239',\n",
       " 'CO_463831742553466364',\n",
       " 'CO_138709519005289773',\n",
       " 'CO_282720645951802718',\n",
       " 'CO_39156011932759465',\n",
       " 'CO_1265293222205251848',\n",
       " 'CO_1917440862059698733',\n",
       " 'CO_1023000223208719171',\n",
       " 'CO_1434438991843863341',\n",
       " 'CO_1315635236251998035',\n",
       " 'CO_1260353353403702639',\n",
       " 'CO_1300013301280701040',\n",
       " 'CO_1636459347184476075',\n",
       " 'CO_1849713850624984649',\n",
       " 'CO_2155737312862821955',\n",
       " 'CO_1517209754665966979',\n",
       " 'CO_1497729172022009050',\n",
       " 'CO_1833041308617257097',\n",
       " 'CO_1336423654166410257',\n",
       " 'CO_1890682455277121976',\n",
       " 'CO_187942668009605040',\n",
       " 'CO_1050806586718413277',\n",
       " 'CO_1811670663957149249',\n",
       " 'CO_217598719576107156',\n",
       " 'CO_405498451253444659',\n",
       " 'CO_1355332599440282522',\n",
       " 'CO_769417750540786055',\n",
       " 'CO_1791749558654517413',\n",
       " 'CO_461965863310672395',\n",
       " 'CO_1763865040656625610',\n",
       " 'CO_387891131556208340',\n",
       " 'CO_1110411853309271454',\n",
       " 'CO_246572172075101213',\n",
       " 'CO_2249568271056498384',\n",
       " 'CO_834880961048460769',\n",
       " 'CO_405921788989163310',\n",
       " 'CO_384072408045332548',\n",
       " 'CO_1829266069808932350',\n",
       " 'CO_364800111342854724',\n",
       " 'CO_819629503638337488',\n",
       " 'CO_1734190172507082019',\n",
       " 'CO_1541835900900356456',\n",
       " 'CO_368802462223639524',\n",
       " 'CO_1875680722326612358',\n",
       " 'CO_880377996728092327',\n",
       " 'CO_1990616418712564837',\n",
       " 'CO_2283422837494116052',\n",
       " 'CO_125891636222208360',\n",
       " 'CO_1419792325454667766',\n",
       " 'CO_1490474054122152647',\n",
       " 'CO_1178243452212485837',\n",
       " 'CO_755620643007099888',\n",
       " 'CO_1588581643408983413',\n",
       " 'CO_1444806779220022782',\n",
       " 'CO_21188830399824395',\n",
       " 'CO_2246146262357788739',\n",
       " 'CO_664644363081460354',\n",
       " 'CO_1741692841001294005',\n",
       " 'CO_1111065732538864085',\n",
       " 'CO_1464685165852597906',\n",
       " 'CO_1607235404570519488',\n",
       " 'CO_1456333929735103769',\n",
       " 'CO_1312959880045772373',\n",
       " 'CO_1945852040415113163',\n",
       " 'CO_1953220421078704490',\n",
       " 'CO_1920615363957803343',\n",
       " 'CO_2284255869686594279',\n",
       " 'CO_2107334660912344735',\n",
       " 'CO_1887666366899187038',\n",
       " 'CO_1302922985816014918',\n",
       " 'CO_359275624236136241',\n",
       " 'CO_657906170180803306',\n",
       " 'CO_1928275223999010778',\n",
       " 'CO_482142868729040634',\n",
       " 'CO_2262858911454388981',\n",
       " 'CO_1030328627776947473',\n",
       " 'CO_571981320162587794',\n",
       " 'CO_2080519252728412322',\n",
       " 'CO_167302678849332877',\n",
       " 'CO_2181790861244905437',\n",
       " 'CO_1770754735276106187',\n",
       " 'CO_1029864903755648042',\n",
       " 'CO_71079618869191760',\n",
       " 'CO_513675507024670610',\n",
       " 'CO_564291648072106836',\n",
       " 'CO_463564214892656966',\n",
       " 'CO_1647925455202470012',\n",
       " 'CO_465444092696711386',\n",
       " 'CO_341472912532488714',\n",
       " 'CO_1348188197292346480',\n",
       " 'CO_641391344206407728',\n",
       " 'CO_1056500982239757075',\n",
       " 'CO_489748577114449454',\n",
       " 'CO_471699346705682633',\n",
       " 'CO_1524725725298427925',\n",
       " 'CO_748118595287888900',\n",
       " 'CO_1786861595521171567',\n",
       " 'CO_1354619308182210684',\n",
       " 'CO_1893965291564853935',\n",
       " 'CO_380577776505324142',\n",
       " 'CO_1474124470114450382',\n",
       " 'CO_251512751200117826',\n",
       " 'CO_753208455144593146',\n",
       " 'CO_1162649866296573527',\n",
       " 'CO_2277764678949854965',\n",
       " 'CO_964217309958392317',\n",
       " 'CO_2165055075030514115',\n",
       " 'CO_1039106935945430254',\n",
       " 'CO_2143615152687721507',\n",
       " 'CO_601938759665264836',\n",
       " 'CO_1839619486339985741',\n",
       " 'CO_30850475183138066',\n",
       " 'CO_48476290737039939',\n",
       " 'CO_2029018192220525944',\n",
       " 'CO_2178205343171422433',\n",
       " 'CO_2250172640758938960',\n",
       " 'CO_1337779370042516797',\n",
       " 'CO_1637248196822946422',\n",
       " 'CO_2002374547902437399',\n",
       " 'CO_1310470668068455957',\n",
       " 'CO_2300556525869457402',\n",
       " 'CO_2206062539478963344',\n",
       " 'CO_1731110607212534399',\n",
       " 'CO_1760937909641611878',\n",
       " 'CO_775788993866720713',\n",
       " 'CO_308158454057126070',\n",
       " 'CO_1375610445967070477',\n",
       " 'CO_1237547909863381053',\n",
       " 'CO_644395201296824972',\n",
       " 'CO_1550729756819155029',\n",
       " 'CO_1614665453536576538',\n",
       " 'CO_653374481688828773',\n",
       " 'CO_550353587516313637',\n",
       " 'CO_1094997533985873625',\n",
       " 'CO_1918386992407386347',\n",
       " 'CO_588612742048116069',\n",
       " 'CO_1577027402547048153',\n",
       " 'CO_822027942456752108',\n",
       " 'CO_1343930644400137519',\n",
       " 'CO_1826899088479790463',\n",
       " 'CO_202592630670277388',\n",
       " 'CO_616256006168366717',\n",
       " 'CO_956788026600912377',\n",
       " 'CO_1395284368802120821',\n",
       " 'CO_1203347258317748274',\n",
       " 'CO_1112558695983332326',\n",
       " 'CO_760814761890752260',\n",
       " 'CO_289942017474395335',\n",
       " 'CO_1501033733121851360',\n",
       " 'CO_146410243827206174',\n",
       " 'CO_494913069415583575',\n",
       " 'CO_1908855835160793455',\n",
       " 'CO_1771171987999953467',\n",
       " 'CO_716383797673738062',\n",
       " 'CO_525511845320514570',\n",
       " 'CO_799339726083422032',\n",
       " 'CO_940297275479621412',\n",
       " 'CO_1298169223600661826',\n",
       " 'CO_1477262385477701700',\n",
       " 'CO_1062059890321330308',\n",
       " 'CO_484886477743153500',\n",
       " 'CO_1786988995391234522',\n",
       " 'CO_1120964130680942925',\n",
       " 'CO_1597151710441039389',\n",
       " 'CO_802098574162224409',\n",
       " 'CO_91246553750329928',\n",
       " 'CO_1297601297130928368',\n",
       " 'CO_632023927356678462',\n",
       " 'CO_603588937563565111',\n",
       " 'CO_1685110353135122290',\n",
       " 'CO_1678499356460476692',\n",
       " 'CO_366611044331915507',\n",
       " 'CO_2233522058269630681',\n",
       " 'CO_567807195119989839',\n",
       " 'CO_408506602256557832',\n",
       " 'CO_22428486719335216',\n",
       " 'CO_1826126210648775417',\n",
       " 'CO_1030901133292490704',\n",
       " 'CO_1700516276625961931',\n",
       " 'CO_65063410501865312',\n",
       " 'CO_1698480237987390138',\n",
       " 'CO_950718928611769177',\n",
       " 'CO_1635428653220148798',\n",
       " 'CO_58140051902531134',\n",
       " 'CO_754279404913066007',\n",
       " 'CO_415857299471400620',\n",
       " 'CO_860380236877536463',\n",
       " 'CO_641793371710462280',\n",
       " 'CO_1603384400670748943',\n",
       " 'CO_1741956772329693182',\n",
       " 'CO_1963917215832180662',\n",
       " 'CO_598676797206318263',\n",
       " 'CO_2194113875329107092',\n",
       " 'CO_2081071188057505811',\n",
       " 'CO_1380631795336305900',\n",
       " 'CO_1913547697838617322',\n",
       " 'CO_649747213286240832',\n",
       " 'CO_1675010966852816408',\n",
       " 'CO_2175934361747354554',\n",
       " 'CO_324415355480078174',\n",
       " 'CO_1133871796579108995',\n",
       " 'CO_671443790242012944',\n",
       " 'CO_598560776745900827',\n",
       " 'CO_72991244967899216',\n",
       " 'CO_229328302166149862',\n",
       " 'CO_315439919376725248',\n",
       " 'CO_1609866133304370243',\n",
       " 'CO_1678852348399908390',\n",
       " 'CO_1407199479844815215',\n",
       " 'CO_1947965866269680039',\n",
       " 'CO_2166065944031553990',\n",
       " 'CO_992917501545442482',\n",
       " 'CO_1120857767006007147',\n",
       " 'CO_1900269955448873203',\n",
       " 'CO_1545007965346910105',\n",
       " 'CO_1803992345574878710',\n",
       " 'CO_2120602658823467154',\n",
       " 'CO_1491025995192302045',\n",
       " 'CO_208038739607388885',\n",
       " 'CO_376734308961919227',\n",
       " 'CO_709103050614210539',\n",
       " 'CO_601455767083024549',\n",
       " 'CO_665635548566423021',\n",
       " 'CO_1764226881078535874',\n",
       " 'CO_2203865840980610857',\n",
       " 'CO_1815858441341830212',\n",
       " 'CO_365410107320043626',\n",
       " 'CO_359631187858447236',\n",
       " 'CO_2040554021688440684',\n",
       " 'CO_108964141742943804',\n",
       " 'CO_892788963504499033',\n",
       " 'CO_611301291938012052',\n",
       " 'CO_1534889364399848730',\n",
       " 'CO_1796798845748085046',\n",
       " 'CO_1320359966944384443',\n",
       " 'CO_2085762672582910931',\n",
       " 'CO_1795250489160342840',\n",
       " 'CO_145594415199086155',\n",
       " 'CO_435569513669503710',\n",
       " 'CO_1496698444081165084',\n",
       " 'CO_281107334305258260',\n",
       " 'CO_149011115247330588',\n",
       " 'CO_1199718177037309528',\n",
       " 'CO_2192434158656564353',\n",
       " 'CO_1571570885918901010',\n",
       " 'CO_220948665121515502',\n",
       " 'CO_611068609475420575',\n",
       " 'CO_2035213871956812169',\n",
       " 'CO_2207967763345184603',\n",
       " 'CO_967012784066559720',\n",
       " 'CO_1888548440344061265',\n",
       " 'CO_190199603879562716',\n",
       " 'CO_434623707293585394',\n",
       " 'CO_1815505708028171150',\n",
       " 'CO_1765028251413076773',\n",
       " 'CO_2092846824550429015',\n",
       " 'CO_1814849984388718735',\n",
       " 'CO_24551628886577667',\n",
       " 'CO_784716113366258913',\n",
       " 'CO_716804283304499991',\n",
       " 'CO_1038254327539026355',\n",
       " 'CO_549297401861099829',\n",
       " 'CO_2151975375172284254',\n",
       " 'CO_519588608968785140',\n",
       " 'CO_736335935775329287',\n",
       " 'CO_1934710932767726893',\n",
       " 'CO_891243186512933346',\n",
       " 'CO_787264008532732991',\n",
       " 'CO_786500368111179656',\n",
       " 'CO_1733357674782104088',\n",
       " 'CO_1519477553536634613',\n",
       " 'CO_1532298587548416626',\n",
       " 'CO_1899635594482050278',\n",
       " 'CO_2117773696099085620',\n",
       " 'CO_206695127169559299',\n",
       " 'CO_976508864864770330',\n",
       " 'CO_814420198522712066',\n",
       " 'CO_219760731703038292',\n",
       " 'CO_1208620186678355709',\n",
       " 'CO_1014701091051098771',\n",
       " 'CO_1347429093386583579',\n",
       " 'CO_339045273757621827',\n",
       " 'CO_1698822609125010474',\n",
       " 'CO_40646639554115665',\n",
       " 'CO_1752576222162269078',\n",
       " 'CO_1496862506850162717',\n",
       " 'CO_2132500110753964142',\n",
       " 'CO_851962220943789604',\n",
       " 'CO_1991176203201227218',\n",
       " 'CO_184241229901757961',\n",
       " 'CO_1559482310259229966',\n",
       " 'CO_24238068955771038',\n",
       " 'CO_1897678638936568828',\n",
       " 'CO_920026924132300302',\n",
       " 'CO_911820236095015536',\n",
       " 'CO_186116254317397654',\n",
       " 'CO_446896713486105910',\n",
       " 'CO_1221851040927803387',\n",
       " 'CO_854695426178704791',\n",
       " 'CO_2188573648071924375',\n",
       " 'CO_728639910380933551',\n",
       " 'CO_1820287387170943675',\n",
       " 'CO_519728780353137321',\n",
       " 'CO_1841732307762287946',\n",
       " 'CO_1041123072515781063',\n",
       " 'CO_2147868923793149181',\n",
       " 'CO_438340450519091408',\n",
       " 'CO_517615729936457803',\n",
       " 'CO_285722848248578714',\n",
       " 'CO_705416181738799810',\n",
       " 'CO_477694363814657591',\n",
       " 'CO_1678350865482337474',\n",
       " 'CO_343670455949246721',\n",
       " 'CO_2045278836524613621',\n",
       " 'CO_1505423253344656188',\n",
       " 'CO_387348833094314557',\n",
       " 'CO_1304836667398011495',\n",
       " 'CO_799172440891213150',\n",
       " 'CO_1045684412160755397',\n",
       " 'CO_1390468094840964091',\n",
       " 'CO_1032606371409042301',\n",
       " 'CO_1443593093098494699',\n",
       " 'CO_632452089883125792',\n",
       " 'CO_96623390091570438',\n",
       " 'CO_999228990968161936',\n",
       " 'CO_1118728269494287377',\n",
       " 'CO_155342012837930040',\n",
       " 'CO_1527527335709867085',\n",
       " 'CO_928071594297945547',\n",
       " 'CO_1326891034180506704',\n",
       " 'CO_808733976517665297',\n",
       " 'CO_1002140044104019634',\n",
       " 'CO_2089682043016473726',\n",
       " 'CO_1421604708223258253',\n",
       " 'CO_2139795628311718617',\n",
       " 'CO_790361341314799545',\n",
       " 'CO_1692356193141040061',\n",
       " 'CO_55802671663055980',\n",
       " 'CO_2200794198474082566',\n",
       " 'CO_1239929327320232023',\n",
       " 'CO_1631369285629252395',\n",
       " 'CO_1603600439341281419',\n",
       " 'CO_2044543485337031386',\n",
       " 'CO_2000304290862074317',\n",
       " 'CO_1280859786285782862',\n",
       " 'CO_1880901480082728400',\n",
       " 'CO_1618060397706805060',\n",
       " 'CO_1477705377100764461',\n",
       " 'CO_1028616448592104613',\n",
       " 'CO_229589485228204523',\n",
       " 'CO_1285525196932649996',\n",
       " 'CO_1134689943661546917',\n",
       " 'CO_502456018775913048',\n",
       " 'CO_383447040431647202',\n",
       " 'CO_1967627013156426381',\n",
       " 'CO_248249497482844545',\n",
       " 'CO_1837387611028906681',\n",
       " 'CO_575099695768619663',\n",
       " 'CO_1660964823652651924',\n",
       " 'CO_1096652213338673962',\n",
       " 'CO_880118050538167012',\n",
       " 'CO_722993557936165212',\n",
       " 'CO_892075210619605974',\n",
       " 'CO_409153375786030693',\n",
       " 'CO_275985595513409186',\n",
       " 'CO_175116265191155229',\n",
       " 'CO_2147114318096699889',\n",
       " 'CO_1570361599608092442',\n",
       " 'CO_522867156614826501',\n",
       " 'CO_987616657328072077',\n",
       " 'CO_1270687758673311153',\n",
       " 'CO_1316057869799273804',\n",
       " 'CO_330333114230750808',\n",
       " 'CO_1996099033331063961',\n",
       " 'CO_369353260523946956',\n",
       " 'CO_554147607752918628',\n",
       " 'CO_1723859612202373965',\n",
       " 'CO_1414292664841497328',\n",
       " 'CO_2033311259473393740',\n",
       " 'CO_788137898376444215',\n",
       " 'CO_1483031248265695838',\n",
       " 'CO_1059860752949014341',\n",
       " 'CO_1179826510359902364',\n",
       " 'CO_1764266615289587450',\n",
       " 'CO_284803620613103343',\n",
       " 'CO_329521925860036571',\n",
       " 'CO_2145874039226150399',\n",
       " 'CO_1375069382537985842',\n",
       " 'CO_1336316855740236140',\n",
       " 'CO_2013224103824744279',\n",
       " 'CO_535903339666832403',\n",
       " 'CO_846080640494047472',\n",
       " 'CO_1650700512374002235',\n",
       " 'CO_194235916013861653',\n",
       " 'CO_1479436767483401704',\n",
       " 'CO_1365348664443241838',\n",
       " 'CO_1589123288994828340',\n",
       " 'CO_774159765310550331',\n",
       " 'CO_1367604995279869333',\n",
       " 'CO_1492568524865962321',\n",
       " 'CO_1343706735582262108',\n",
       " 'CO_1011954133276979820',\n",
       " 'CO_2185232754516467354',\n",
       " 'CO_1691323459394540264',\n",
       " 'CO_1135422733631732711',\n",
       " 'CO_2217668352356367989',\n",
       " 'CO_2138181113562925186',\n",
       " 'CO_2186871170102782766',\n",
       " 'CO_1598833589860181218',\n",
       " 'CO_88029586906386780',\n",
       " 'CO_859461411845574782',\n",
       " 'CO_664988772683548492',\n",
       " 'CO_1076724411131327080',\n",
       " 'CO_51767955796502040',\n",
       " 'CO_547054327748740537',\n",
       " 'CO_2222951899302793462',\n",
       " 'CO_173819367290101788',\n",
       " 'CO_1186088183976837335',\n",
       " 'CO_23548868886677614',\n",
       " 'CO_1675782705156805995',\n",
       " 'CO_935927806468239539',\n",
       " 'CO_606536193855871962',\n",
       " 'CO_1175213403039478204',\n",
       " 'CO_951656008559893616',\n",
       " 'CO_2112785590317810664',\n",
       " 'CO_599019958360748911',\n",
       " 'CO_635314393358687345',\n",
       " 'CO_998022005415665748',\n",
       " 'CO_1510281155468915365',\n",
       " 'CO_127374668323543276',\n",
       " 'CO_1021870001253523753',\n",
       " 'CO_2030336984283533393',\n",
       " 'CO_1164450285794125898',\n",
       " 'CO_2038832775323606802',\n",
       " 'CO_375428878224479963',\n",
       " 'CO_920308378885542956',\n",
       " 'CO_866805550151251606',\n",
       " 'CO_1989887896351480148',\n",
       " 'CO_390046730224599196',\n",
       " 'CO_1877719872788990668',\n",
       " 'CO_2110042267263764280',\n",
       " 'CO_1804203614702453861',\n",
       " 'CO_908300577751618688',\n",
       " 'CO_236509892921848570',\n",
       " 'CO_1010311918131661590',\n",
       " 'CO_295859574627493997',\n",
       " 'CO_467297520230330316',\n",
       " 'CO_575260869372236797',\n",
       " 'CO_1517976337117758387',\n",
       " 'CO_125264192323072644',\n",
       " 'CO_14756734027603424',\n",
       " 'CO_226589123716559910',\n",
       " 'CO_471021201390462514',\n",
       " 'CO_2066530521043917221',\n",
       " 'CO_516040006302063901',\n",
       " 'CO_1655290298938321300',\n",
       " 'CO_588906321147678243',\n",
       " 'CO_1419925798834165472',\n",
       " 'CO_1730192319305214741',\n",
       " 'CO_1270941418601777113',\n",
       " 'CO_923270362140937417',\n",
       " 'CO_1393081751801131253',\n",
       " 'CO_1578052988112214641',\n",
       " 'CO_466742611857774892',\n",
       " 'CO_307127305387999250',\n",
       " 'CO_880382249446217876',\n",
       " 'CO_690661744295632109',\n",
       " 'CO_1678906991917188009',\n",
       " 'CO_2197425231666374227',\n",
       " 'CO_2241309753147127655',\n",
       " 'CO_1850380915993293510',\n",
       " 'CO_1422016241874707003',\n",
       " 'CO_2151143989026552876',\n",
       " 'CO_865892808130057642',\n",
       " 'CO_1079237946087930142',\n",
       " 'CO_731225438778818254',\n",
       " 'CO_1219615612025369794',\n",
       " 'CO_172228864789490345',\n",
       " 'CO_582202275029781193',\n",
       " 'CO_302830312510320085',\n",
       " 'CO_1358729279302135030',\n",
       " 'CO_1942219073131186136',\n",
       " 'CO_912285420515115328',\n",
       " 'CO_1445353663713625002',\n",
       " 'CO_2096704383429724708',\n",
       " 'CO_792633056167511873',\n",
       " 'CO_1024014875982816108',\n",
       " 'CO_221987841775696869',\n",
       " 'CO_691080275248857807',\n",
       " 'CO_1815380571110354301',\n",
       " 'CO_1521778880017741659',\n",
       " 'CO_2108719122015635152',\n",
       " 'CO_1792328026701218255',\n",
       " 'CO_1039899335232716192',\n",
       " 'CO_1980341562247151847',\n",
       " 'CO_1722306925140546535',\n",
       " 'CO_1913702412210215212',\n",
       " 'CO_1279152012597823286',\n",
       " 'CO_2054025936386567153',\n",
       " 'CO_1218217150625742347',\n",
       " 'CO_812231004166988119',\n",
       " 'CO_1829378085026436082',\n",
       " 'CO_1625414854932219535',\n",
       " 'CO_2264873568367839011',\n",
       " 'CO_982978938706037531',\n",
       " 'CO_738740354676074597',\n",
       " 'CO_1027946366787174134',\n",
       " 'CO_1813227663784099924',\n",
       " 'CO_921959668715580297',\n",
       " 'CO_1766223186788620248',\n",
       " 'CO_1303132829318600662',\n",
       " 'CO_1609484363511306970',\n",
       " 'CO_788653975078236366',\n",
       " 'CO_1259578937547904877',\n",
       " 'CO_99813389667335764',\n",
       " 'CO_215233715438100249',\n",
       " 'CO_961214996230105126',\n",
       " 'CO_506243460920828913',\n",
       " 'CO_1004297025183300977',\n",
       " 'CO_1093709447861566550',\n",
       " 'CO_1499380012486322230',\n",
       " 'CO_1775144452820278875',\n",
       " 'CO_1442568455343715112',\n",
       " 'CO_778309729324506763',\n",
       " 'CO_238080727131842008',\n",
       " 'CO_2067850649702145702',\n",
       " 'CO_1138085220634677629',\n",
       " 'CO_1929408762462570640',\n",
       " 'CO_729423864168049953',\n",
       " 'CO_1636314127586790802',\n",
       " 'CO_1488937488834415239',\n",
       " 'CO_1743773556146395677',\n",
       " 'CO_1890087145988015445',\n",
       " 'CO_1974433301129134904',\n",
       " 'CO_1832378281523382477',\n",
       " 'CO_1213615900533132762',\n",
       " 'CO_1396620620701348812',\n",
       " 'CO_1714403349073760549',\n",
       " 'CO_831832300818732597',\n",
       " 'CO_35948951992190548',\n",
       " 'CO_1645461083914883445',\n",
       " 'CO_2145139788063371758',\n",
       " 'CO_778629505810916243',\n",
       " 'CO_1237117784445219970',\n",
       " 'CO_1468472854203672825',\n",
       " 'CO_1124320808212685002',\n",
       " 'CO_1821925493611813331',\n",
       " 'CO_601509636474949497',\n",
       " 'CO_912009420124007261',\n",
       " 'CO_1494780808415931392',\n",
       " 'CO_1403158312970507576',\n",
       " 'CO_20849942039424142',\n",
       " 'CO_1104833403634277976',\n",
       " 'CO_951815840370588926',\n",
       " 'CO_1917839230195585289',\n",
       " 'CO_971692101039880917',\n",
       " 'CO_1061491240403909913',\n",
       " 'CO_763270811126569362',\n",
       " 'CO_50427677475165609',\n",
       " 'CO_1600796444846193332',\n",
       " 'CO_906187616971780319',\n",
       " 'CO_365429718281347454',\n",
       " 'CO_516380871341206916',\n",
       " 'CO_1895958545411444310',\n",
       " 'CO_1080520866354403001',\n",
       " 'CO_381203781975058546',\n",
       " 'CO_153252925514316201',\n",
       " 'CO_1077612087363386138',\n",
       " 'CO_2171275415592713213',\n",
       " 'CO_982768393366126034',\n",
       " 'CO_1206810844080883447',\n",
       " 'CO_2034571551147300441',\n",
       " 'CO_2240664794038762666',\n",
       " 'CO_1137227685877716352',\n",
       " 'CO_918591165610805644',\n",
       " 'CO_1624208251506468746',\n",
       " 'CO_920478338197525487',\n",
       " 'CO_1799576886260024079',\n",
       " 'CO_1168506740114140977',\n",
       " 'CO_750472254644610956',\n",
       " 'CO_2113556516588740754',\n",
       " 'CO_779576839666913223',\n",
       " 'CO_2273533802794700678',\n",
       " 'CO_2264583373716417857',\n",
       " 'CO_842737115311798632',\n",
       " 'CO_1564968955911122276',\n",
       " 'CO_1839931676097361543',\n",
       " 'CO_1275051484582824231',\n",
       " 'CO_2176503379579281399',\n",
       " 'CO_1503998266792028943',\n",
       " 'CO_937387713209560568',\n",
       " 'CO_1246622966509387129',\n",
       " 'CO_334486328787228368',\n",
       " 'CO_1185008918886820290',\n",
       " 'CO_1076606474378172454',\n",
       " 'CO_384372257787257147',\n",
       " 'CO_2168704655770514911',\n",
       " 'CO_1401335341541141604',\n",
       " 'CO_1830296313831894205',\n",
       " 'CO_1514216346219238394',\n",
       " 'CO_685656583641195950',\n",
       " 'CO_1599462865766008951',\n",
       " 'CO_2270199460947461890',\n",
       " 'CO_849068749575650045',\n",
       " 'CO_357469289591193620',\n",
       " 'CO_1423299888855492129',\n",
       " 'CO_637356494108731673',\n",
       " 'CO_2252402650310929503',\n",
       " 'CO_891241669637995508',\n",
       " 'CO_2199460819471737317',\n",
       " 'CO_806210187199546472',\n",
       " 'CO_1852516169461628861',\n",
       " 'CO_1780691063938594260',\n",
       " 'CO_1158099378675166276',\n",
       " 'CO_2290979542296657142',\n",
       " 'CO_2019621858334179284',\n",
       " 'CO_605493801191901626',\n",
       " 'CO_1662478049811561230',\n",
       " 'CO_1558307069770244418',\n",
       " 'CO_1619345539412059620',\n",
       " 'CO_1462466156823772115',\n",
       " 'CO_1309284912670375106',\n",
       " 'CO_2222343269020898709',\n",
       " 'CO_370933857262204248',\n",
       " 'CO_2293273111314556040',\n",
       " 'CO_528776201358487566',\n",
       " 'CO_69785439384286699',\n",
       " 'CO_1431128310836418435',\n",
       " 'CO_876868057357222355',\n",
       " 'CO_1909328010021748965',\n",
       " 'CO_1031130143252282631',\n",
       " 'CO_181793291095598998',\n",
       " 'CO_1042068790362438767',\n",
       " 'CO_231425781459182500',\n",
       " 'CO_770164740305349787',\n",
       " 'CO_1885590513379337131',\n",
       " 'CO_2140078193026612095',\n",
       " 'CO_253785150710126654',\n",
       " 'CO_1801184867081247106',\n",
       " 'CO_266060454493008047',\n",
       " 'CO_1180460251434048281',\n",
       " 'CO_637864212272889189',\n",
       " 'CO_218437630528112003',\n",
       " 'CO_1336180443914584534',\n",
       " 'CO_954293708213390421',\n",
       " 'CO_634494768998651964',\n",
       " 'CO_69039887789955870',\n",
       " 'CO_1103582794349310985',\n",
       " 'CO_2210527902931935375',\n",
       " 'CO_814313280826471590',\n",
       " 'CO_1105243275873850085',\n",
       " 'CO_2231677083882940792',\n",
       " 'CO_2190657931712603944',\n",
       " 'CO_452960911356759591',\n",
       " 'CO_2153912730329413098',\n",
       " 'CO_48009766790374649',\n",
       " 'CO_989251941841913773',\n",
       " 'CO_1163228430940830078',\n",
       " 'CO_1702345218633972409',\n",
       " 'CO_1775719704658963208',\n",
       " 'CO_2217566450058881568',\n",
       " 'CO_239620502613809178',\n",
       " 'CO_445625727163482698',\n",
       " 'CO_1355482634016492426',\n",
       " 'CO_2139956905270493425',\n",
       " 'CO_2179406303283234717',\n",
       " 'CO_342993658517572458',\n",
       " 'CO_348813827807272235',\n",
       " 'CO_1944043817737722089',\n",
       " 'CO_162275118564591448',\n",
       " 'CO_2237534546058898209',\n",
       " 'CO_328945637478722320',\n",
       " 'CO_1064208714760455136',\n",
       " 'CO_1125551863709980813',\n",
       " 'CO_1370093611269645611',\n",
       " 'CO_58444173190224256',\n",
       " 'CO_266439292292651210',\n",
       " 'CO_2079029933535514981',\n",
       " 'CO_1895248329543098356',\n",
       " 'CO_1270460233791768030',\n",
       " 'CO_526162973036127988',\n",
       " 'CO_1188838383149665216',\n",
       " 'CO_661785998238918052',\n",
       " 'CO_1670688652657087614',\n",
       " 'CO_23749661583301302',\n",
       " 'CO_1925691416399705524',\n",
       " 'CO_664931981139328125',\n",
       " 'CO_859999131438711762',\n",
       " 'CO_1298010341444387916',\n",
       " 'CO_1751300504640982533',\n",
       " 'CO_801221524495373249',\n",
       " 'CO_299751399080303090',\n",
       " 'CO_1083419220335843744',\n",
       " 'CO_1910704645897837131',\n",
       " 'CO_1348784629861165664',\n",
       " 'CO_1004470219968986392',\n",
       " 'CO_312142644956977577',\n",
       " 'CO_2263551516822461629',\n",
       " 'CO_1628345890636884590',\n",
       " 'CO_692197032301269822',\n",
       " 'CO_1578118702088688380',\n",
       " 'CO_1644357731197687234',\n",
       " 'CO_868168573850637700',\n",
       " 'CO_2078947144545644657',\n",
       " 'CO_992284526641448363',\n",
       " 'CO_512966701658576749',\n",
       " 'CO_1982754303329081358',\n",
       " 'CO_1175511995492536291',\n",
       " 'CO_55818266075687051',\n",
       " 'CO_298718111742265725',\n",
       " 'CO_961566699887992345',\n",
       " 'CO_1074069393395812920',\n",
       " 'CO_765822037118001630',\n",
       " 'CO_593997917283408807',\n",
       " 'CO_31884471988879183',\n",
       " 'CO_897374621993886838',\n",
       " 'CO_2053873087251535120',\n",
       " 'CO_389763341249052702',\n",
       " 'CO_2275234381327085106',\n",
       " 'CO_1481248849849457645',\n",
       " 'CO_2189465496834694218',\n",
       " 'CO_1663794780082651614',\n",
       " 'CO_712598291740716201',\n",
       " 'CO_1484529474298461278',\n",
       " 'CO_589767605027485700',\n",
       " 'CO_2288977030353196430',\n",
       " 'CO_1347127817249241271',\n",
       " 'CO_1289681826134722332',\n",
       " 'CO_491302497378635662',\n",
       " 'CO_1912570622732118657',\n",
       " 'CO_345449234474056820',\n",
       " 'CO_188634761051980769',\n",
       " 'CO_1934771581797272319',\n",
       " 'CO_823424656567663693',\n",
       " 'CO_433704407721750759',\n",
       " 'CO_1098721230748679065',\n",
       " 'CO_1458378122835677469',\n",
       " 'CO_2115393205125604979',\n",
       " 'CO_229347831182344167',\n",
       " 'CO_1197349452337620831',\n",
       " 'CO_1358333501576304303',\n",
       " 'CO_1600005373804086897',\n",
       " 'CO_1981212861714055419',\n",
       " 'CO_1877959345531977984',\n",
       " 'CO_855053981224980381',\n",
       " 'CO_876165232330907134',\n",
       " 'CO_311581721998700787',\n",
       " 'CO_643929402679133337',\n",
       " 'CO_1442067090496248109',\n",
       " 'CO_596270641651279231',\n",
       " 'CO_249777712526444122',\n",
       " 'CO_492060383563181290',\n",
       " 'CO_2921294178808758',\n",
       " 'CO_1545213877596533539',\n",
       " 'CO_431417815437061504',\n",
       " 'CO_1545180301138703335',\n",
       " 'CO_687933076365610673',\n",
       " 'CO_1467586570150418060',\n",
       " 'CO_235221144274483011',\n",
       " 'CO_850601106162615965',\n",
       " 'CO_704686166797618076',\n",
       " 'CO_2059864940683975012',\n",
       " 'CO_557867826633951431',\n",
       " 'CO_684580675367263212',\n",
       " 'CO_2238043370888667422',\n",
       " 'CO_1304297067347209282',\n",
       " 'CO_1302504886933257873',\n",
       " 'CO_1947812865315496134',\n",
       " 'CO_1954305719534780456',\n",
       " 'CO_1352976641622257959',\n",
       " 'CO_1781760580015183229',\n",
       " 'CO_429254148634685870',\n",
       " 'CO_1703953658401853952',\n",
       " 'CO_1537749577515104711',\n",
       " 'CO_1564083527047526358',\n",
       " 'CO_480462271854159506',\n",
       " 'CO_1338369609079274974',\n",
       " 'CO_1988020154472545507',\n",
       " 'CO_2206454330551876089',\n",
       " 'CO_909633925095352052',\n",
       " 'CO_428612044426711699',\n",
       " 'CO_457656883388602721',\n",
       " 'CO_353434611197920173',\n",
       " 'CO_678940369263261793',\n",
       " 'CO_1543688529764311443',\n",
       " 'CO_139257057887069718',\n",
       " 'CO_1596931976688568391',\n",
       " 'CO_560318872401022473',\n",
       " 'CO_1059510151133214434',\n",
       " 'CO_568366284948988402',\n",
       " 'CO_1417867950097591727',\n",
       " 'CO_1543579512551951789',\n",
       " 'CO_2128312614063496269',\n",
       " 'CO_648379428118093202',\n",
       " 'CO_2291375758065737713',\n",
       " 'CO_245852862398297862',\n",
       " 'CO_1350358395830982369',\n",
       " 'CO_528215792671280163',\n",
       " 'CO_1168475433360798683',\n",
       " 'CO_1722715214797412099',\n",
       " 'CO_929451939467600508',\n",
       " 'CO_985818668838257615',\n",
       " 'CO_1779357127705003291',\n",
       " 'CO_367697149613231728',\n",
       " 'CO_589211698604790913',\n",
       " 'CO_832390285703280322',\n",
       " 'CO_777602516918340364',\n",
       " 'CO_1101929757846321294',\n",
       " 'CO_1843615503584816498',\n",
       " 'CO_1222558625392572007',\n",
       " 'CO_2066033517418575582',\n",
       " 'CO_244069943726174453',\n",
       " 'CO_1452614367964780388',\n",
       " 'CO_1491218654557831673',\n",
       " 'CO_818467510633647255',\n",
       " 'CO_496798431051110329',\n",
       " 'CO_1977635870607692531',\n",
       " 'CO_286271344593281277',\n",
       " 'CO_1635073262904679778',\n",
       " 'CO_73741235150779986',\n",
       " 'CO_1526107597705765234',\n",
       " 'CO_840503110641957914',\n",
       " 'CO_1232785165751886283',\n",
       " 'CO_1977836582060513812',\n",
       " 'CO_70513016140555619',\n",
       " 'CO_611354084862046675',\n",
       " 'CO_894694647918498370',\n",
       " 'CO_1826166698296702363',\n",
       " 'CO_1411519695877627514',\n",
       " 'CO_854221054810611696',\n",
       " 'CO_2266268189055981150',\n",
       " 'CO_496580329396076283',\n",
       " 'CO_644891726520426398',\n",
       " 'CO_383605625700173416',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Row(element='Ga', ratio=0.012887595268940222), Row(element='I', ratio=0.016706765146289347), Row(element='Pt', ratio=0.012332385551087706), Row(element='Se', ratio=0.016555344314147753), Row(element='Tl', ratio=0.006023184211854569), Row(element='Ni', ratio=0.017144203105809514), Row(element='Os', ratio=0.011339737873715026), Row(element='Co', ratio=0.014014839241549877), Row(element='Fe', ratio=0.016269327186769184), Row(element='Ru', ratio=0.012214613792755354), Row(element='Mg', ratio=0.010919124451099483), Row(element='Ti', ratio=0.02444605212241533), Row(element='Ag', ratio=0.008883355485640258), Row(element='H', ratio=0.07577771421841614), Row(element='Te', ratio=0.012988542490367953), Row(element='Al', ratio=0.018389218836751518), Row(element='C', ratio=0.01552904756296583), Row(element='S', ratio=0.027171627100964046), Row(element='Li', ratio=0.021552231774820397), Row(element='Ca', ratio=0.007991655029695307), Row(element='Zr', ratio=0.010077897605868398), Row(element='Cd', ratio=0.011104194357050323), Row(element='B', ratio=0.01663946699867086), Row(element='K', ratio=0.012231438329659975), Row(element='Nb', ratio=0.018456516984370005), Row(element='Tc', ratio=0.014418628127260797), Row(element='P', ratio=0.018254622541514543), Row(element='Rb', ratio=0.006309201339233138), Row(element='F', ratio=0.029426115046183355), Row(element='Cl', ratio=0.02343657990813803), Row(element='Hf', ratio=0.009775055941585209), Row(element='Br', ratio=0.024496525733129194), Row(element='Be', ratio=0.02158588084862964), Row(element='Cs', ratio=0.005013711997577267), Row(element='O', ratio=0.024412403048606087), Row(element='V', ratio=0.02474889378669852), Row(element='Y', ratio=0.008008479566599929), Row(element='In', ratio=0.009724582330871343), Row(element='N', ratio=0.0200043743795952), Row(element='Sb', ratio=0.013425980449888117), Row(element='Ir', ratio=0.01228191194037384), Row(element='Sn', ratio=0.011541632316570486), Row(element='Rh', ratio=0.01810320170937295), Row(element='Pb', ratio=0.006410148560660868), Row(element='Hg', ratio=0.009724582330871343), Row(element='Ta', ratio=0.009522687888015883), Row(element='Mn', ratio=0.014805592476067097), Row(element='Cr', ratio=0.015512223026061207), Row(element='Cu', ratio=0.011205141578478052), Row(element='Sc', ratio=0.010902299914194861), Row(element='Ge', ratio=0.014216733684405337), Row(element='Re', ratio=0.013762471187980551), Row(element='Ba', ratio=0.004929589313054158), Row(element='Na', ratio=0.029762605784275788), Row(element='As', ratio=0.02067735585578007), Row(element='Bi', ratio=0.008630987432070933), Row(element='Si', ratio=0.041876272355603414), Row(element='Mo', ratio=0.01157528139037973), Row(element='Au', ratio=0.011794000370139812), Row(element='Zn', ratio=0.012618402678466275), Row(element='Pd', ratio=0.011861298517758299), Row(element='W', ratio=0.01366152396655282), Row(element='Sr', ratio=0.003936941635681478)]\n",
      "[0.008883355485640258, 0.018389218836751518, 0.02067735585578007, 0.011794000370139812, 0.01663946699867086, 0.004929589313054158, 0.02158588084862964, 0.008630987432070933, 0.024496525733129194, 0.01552904756296583, 0.007991655029695307, 0.011104194357050323, 0.02343657990813803, 0.014014839241549877, 0.015512223026061207, 0.005013711997577267, 0.011205141578478052, 0.029426115046183355, 0.016269327186769184, 0.012887595268940222, 0.014216733684405337, 0.07577771421841614, 0.009775055941585209, 0.009724582330871343, 0.016706765146289347, 0.009724582330871343, 0.01228191194037384, 0.012231438329659975, 0.021552231774820397, 0.010919124451099483, 0.014805592476067097, 0.01157528139037973, 0.0200043743795952, 0.029762605784275788, 0.018456516984370005, 0.017144203105809514, 0.024412403048606087, 0.011339737873715026, 0.018254622541514543, 0.006410148560660868, 0.011861298517758299, 0.012332385551087706, 0.006309201339233138, 0.013762471187980551, 0.01810320170937295, 0.012214613792755354, 0.027171627100964046, 0.013425980449888117, 0.010902299914194861, 0.016555344314147753, 0.041876272355603414, 0.011541632316570486, 0.003936941635681478, 0.009522687888015883, 0.014418628127260797, 0.012988542490367953, 0.02444605212241533, 0.006023184211854569, 0.02474889378669852, 0.01366152396655282, 0.008008479566599929, 0.012618402678466275, 0.010077897605868398]\n",
      "[0.008883355485640258, 0.018389218836751518, 0.02067735585578007, 0.011794000370139812, 0.01663946699867086, 0.004929589313054158, 0.02158588084862964, 0.008630987432070933, 0.024496525733129194, 0.01552904756296583, 0.007991655029695307, 0.011104194357050323, 0.02343657990813803, 0.014014839241549877, 0.015512223026061207, 0.005013711997577267, 0.011205141578478052, 0.029426115046183355, 0.016269327186769184, 0.012887595268940222, 0.014216733684405337, 0.07577771421841614, 0.009775055941585209, 0.009724582330871343, 0.016706765146289347, 0.009724582330871343, 0.01228191194037384, 0.012231438329659975, 0.021552231774820397, 0.010919124451099483, 0.014805592476067097, 0.01157528139037973, 0.0200043743795952, 0.029762605784275788, 0.018456516984370005, 0.017144203105809514, 0.024412403048606087, 0.011339737873715026, 0.018254622541514543, 0.006410148560660868, 0.011861298517758299, 0.012332385551087706, 0.006309201339233138, 0.013762471187980551, 0.01810320170937295, 0.012214613792755354, 0.027171627100964046, 0.013425980449888117, 0.010902299914194861, 0.016555344314147753, 0.041876272355603414, 0.011541632316570486, 0.003936941635681478, 0.009522687888015883, 0.014418628127260797, 0.012988542490367953, 0.02444605212241533, 0.006023184211854569, 0.02474889378669852, 0.01366152396655282, 0.008008479566599929, 0.012618402678466275, 0.010077897605868398]\n"
     ]
    }
   ],
   "source": [
    "CS = ConfigurationSet(\n",
    "    name=\"test\", config_df=config_set_query, description=\"test description\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_co_rows_cs_id(self, co_ids: list[str], cs_id: str):\n",
    "    with psycopg.connect(\n",
    "        \"\"\"dbname=colabfit user=%s password=%s host=localhost port=5432\"\"\"\n",
    "        % (\n",
    "            user,\n",
    "            password,\n",
    "        )\n",
    "    ) as conn:\n",
    "        # dbname=self.database_name,\n",
    "        # user=self.properties[\"user\"],\n",
    "        # password=self.properties[\"password\"],\n",
    "        # host=\"localhost\",\n",
    "        # port=\"5432\",\n",
    "        cur = conn.execute(\n",
    "            \"\"\"UPDATE configurations\n",
    "                SET configuration_set_ids = \n",
    "            \"\"\"\n",
    "        )\n",
    "        cur = conn.execute(\n",
    "            \"\"\"UPDATE configurations\n",
    "                SET configuration_set_ids = concat(%s::text, \n",
    "                rtrim(ltrim(replace(configuration_set_ids,%s,''), \n",
    "                \n",
    "                '['),']') || ', ', %s::text)\n",
    "            WHERE id = ANY(%s)\"\"\",\n",
    "            (\"[\", f\"{cs_id}\", f\"{cs_id}]\", co_ids),\n",
    "            # (\"[\", f\", {cs_id}\", f\", {cs_id}]\"),\n",
    "        )\n",
    "        # cur.fetchall()\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You were trying to get  postgresql to recognize the WHERE id = ANY() array syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_co_rows_cs_id(loader, co_ids, CS.spark_row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'CS_258512216210800474',\n",
       " 'hash': 258512216210800474,\n",
       " 'last_modified': None,\n",
       " 'nconfigurations': 110,\n",
       " 'nsites': 1594,\n",
       " 'nelements': 62,\n",
       " 'elements': ['Ag',\n",
       "  'Al',\n",
       "  'As',\n",
       "  'Au',\n",
       "  'B',\n",
       "  'Ba',\n",
       "  'Be',\n",
       "  'Bi',\n",
       "  'Br',\n",
       "  'C',\n",
       "  'Ca',\n",
       "  'Cd',\n",
       "  'Cl',\n",
       "  'Co',\n",
       "  'Cr',\n",
       "  'Cs',\n",
       "  'Cu',\n",
       "  'F',\n",
       "  'Fe',\n",
       "  'Ga',\n",
       "  'Ge',\n",
       "  'H',\n",
       "  'Hf',\n",
       "  'Hg',\n",
       "  'I',\n",
       "  'In',\n",
       "  'Ir',\n",
       "  'K',\n",
       "  'Li',\n",
       "  'Mg',\n",
       "  'Mn',\n",
       "  'Mo',\n",
       "  'N',\n",
       "  'Na',\n",
       "  'Nb',\n",
       "  'Ni',\n",
       "  'O',\n",
       "  'Os',\n",
       "  'P',\n",
       "  'Pb',\n",
       "  'Pd',\n",
       "  'Pt',\n",
       "  'Rb',\n",
       "  'Re',\n",
       "  'Rh',\n",
       "  'Ru',\n",
       "  'S',\n",
       "  'Sb',\n",
       "  'Sc',\n",
       "  'Se',\n",
       "  'Si',\n",
       "  'Sn',\n",
       "  'Ta',\n",
       "  'Tc',\n",
       "  'Te',\n",
       "  'Ti',\n",
       "  'Tl',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y',\n",
       "  'Zn',\n",
       "  'Zr'],\n",
       " 'dataset_id': None,\n",
       " 'name': 'test',\n",
       " 'description': 'test description',\n",
       " 'total_elements_ratios': [0.013801756587202008,\n",
       "  0.006273525721455458,\n",
       "  0.009410288582183186,\n",
       "  0.010037641154328732,\n",
       "  0.016938519447929738,\n",
       "  0.006273525721455458,\n",
       "  0.014429109159347553,\n",
       "  0.01819322459222083,\n",
       "  0.027603513174404015,\n",
       "  0.012547051442910916,\n",
       "  0.003136762860727729,\n",
       "  0.03450439146800502,\n",
       "  0.02132998745294856,\n",
       "  0.014429109159347553,\n",
       "  0.028858218318695106,\n",
       "  0.0075282308657465494,\n",
       "  0.0056461731493099125,\n",
       "  0.037641154328732745,\n",
       "  0.006273525721455458,\n",
       "  0.009410288582183186,\n",
       "  0.020075282308657464,\n",
       "  0.05144291091593475,\n",
       "  0.00878293601003764,\n",
       "  0.0056461731493099125,\n",
       "  0.03889585947302384,\n",
       "  0.0056461731493099125,\n",
       "  0.009410288582183186,\n",
       "  0.01819322459222083,\n",
       "  0.006273525721455458,\n",
       "  0.00878293601003764,\n",
       "  0.02132998745294856,\n",
       "  0.011292346298619825,\n",
       "  0.03450439146800502,\n",
       "  0.05144291091593475,\n",
       "  0.021957340025094103,\n",
       "  0.01944792973651192,\n",
       "  0.012547051442910916,\n",
       "  0.01819322459222083,\n",
       "  0.01819322459222083,\n",
       "  0.0056461731493099125,\n",
       "  0.01066499372647428,\n",
       "  0.006900878293601004,\n",
       "  0.01819322459222083,\n",
       "  0.010037641154328732,\n",
       "  0.03136762860727729,\n",
       "  0.0037641154328732747,\n",
       "  0.029485570890840654,\n",
       "  0.005018820577164366,\n",
       "  0.0075282308657465494,\n",
       "  0.02070263488080301,\n",
       "  0.01756587202007528,\n",
       "  0.006273525721455458,\n",
       "  0.003136762860727729,\n",
       "  0.01944792973651192,\n",
       "  0.00439146800501882,\n",
       "  0.0370138017565872,\n",
       "  0.006900878293601004,\n",
       "  0.021957340025094103,\n",
       "  0.01756587202007528,\n",
       "  0.0018820577164366374,\n",
       "  0.018820577164366373,\n",
       "  0.009410288582183186]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS.spark_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabfit.tools.utilities import _empty_dict_from_schema\n",
    "from colabfit.tools.schema import configuration_set_schema\n",
    "import dateutil.parser\n",
    "\n",
    "cs = _empty_dict_from_schema(configuration_set_schema)\n",
    "cs[\"nconfigurations\"] = 200\n",
    "cs[\"dataset_id\"] = carmat_ds_id\n",
    "cs[\"name\"] = \"test\"\n",
    "cs[\"description\"] = \"test description for test\"\n",
    "cs[\"nelements\"] = 25\n",
    "cs[\"last_modified\"] = dateutil.parser.parse(\n",
    "    datetime.datetime.now(tz=datetime.timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    ")\n",
    "cs[\"id\"] = \"CS_y7nrdsjtuw0g_0\"\n",
    "cs[\"hash\"] = hash(cs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.write_table([cs], \"configuration_sets\", configuration_set_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ids = [x[0] for x in config_set_query.select(\"id\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data to PostgreSQL: : 0batch [00:00, ?batch/s]24/05/14 18:12:58 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 13.0 in stage 0.0 (TID 13)2]\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_425343146072841686'),('425343146072841686'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ge2LiRh6Zr'),('Ge2LiRh6Zr'),('A6B2CD'),('[''Ge'', ''Li'', ''Rh'', ''Zr'']'),('[0.2, 0.1, 0.6, 0.1]'),('[32, 32, 3, 45, 45, 45, 45, 45, 45, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.32863268, 0.0, 0.0], [3.164316340000001, 5.4807566721003935, 0.0], [3.164316340000001, 1.8269188907001317, 5.167306945167471]]'),('[0, 0, 0]'),('[False, False, False]'),('[[9.492949020000003, 5.4807566721003935, 3.8754802088756035], [3.1643163400000005, 1.8269188907001312, 1.2918267362918678], [6.328632680000001, 3.6538377814002625, 2.5836534725837357], [6.328632680000001, 5.345107286775108, 3.779561608648307], [6.328632680000001, 1.9625682760254166, 1.387745336519164], [7.79331503630056, 4.499472534087685, 1.387745336519164], [4.863950323699442, 2.80820302871284, 3.779561608648307], [7.79331503630056, 2.80820302871284, 3.779561608648307], [4.863950323699442, 4.499472534087685, 1.387745336519164], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_425343146072841686) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_425343146072841686) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1111065732538864085'),('1111065732538864085'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ir6NaSi2Tl'),('Ir6NaSi2Tl'),('A6B2CD'),('[''Ir'', ''Na'', ''Si'', ''Tl'']'),('[0.6, 0.1, 0.2, 0.1]'),('[77, 77, 77, 77, 77, 77, 11, 14, 14, 81]'),('10'::int4),('4'::int4),('0'::int4),('[[6.34298013, 0.0, 0.0], [3.171490065000001, 5.49318192827992, 0.0], [3.171490065000001, 1.831060642759974, 5.179021589037503]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.5857450325000004, 0.915530321379987, 2.5895107945187514], [4.757235097500001, 0.915530321379987, 2.5895107945187514], [4.757235097500001, 2.74659096413996, 0.0], [1.5857450325000004, 2.74659096413996, 0.0], [3.171490065000001, 3.662121285519947, 2.5895107945187514], [3.171490065, 0.0, 0.0], [0.0, 0.0, 0.0], [9.514470195000001, 5.49318192827992, 3.884266191778127], [3.1714900650000004, 1.8310606427599736, 1.2947553972593757], [6.342980130000001, 3.662121285519947, 2.5895107945187514]]'),('[''carolina_materials_125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1111065732538864085) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1111065732538864085) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 12.0 in stage 0.0 (TID 12)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1244094913989693186'),('1244094913989693186'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Au2InSb6Ti'),('Au2InSb6Ti'),('A6B2CD'),('[''Au'', ''In'', ''Sb'', ''Ti'']'),('[0.2, 0.1, 0.6, 0.1]'),('[79, 79, 49, 51, 51, 51, 51, 51, 51, 22]'),('10'::int4),('4'::int4),('0'::int4),('[[7.62370169, 0.0, 0.0], [3.811850845000001, 6.602319334414357, 0.0], [3.811850845000001, 2.200773111471453, 6.2247263638979256]]'),('[0, 0, 0]'),('[False, False, False]'),('[[11.435552535, 6.602319334414357, 4.668544772923444], [3.8118508450000004, 2.2007731114714524, 1.5561815909744814], [0.0, 0.0, 0.0], [1.9059254225000004, 1.1003865557357264, 3.1123631819489628], [5.717776267500001, 1.1003865557357264, 3.1123631819489628], [5.717776267500001, 3.3011596672071786, 0.0], [1.9059254225000004, 3.3011596672071786, 0.0], [3.811850845000001, 4.401546222942905, 3.1123631819489628], [3.811850845, 0.0, 0.0], [7.623701690000001, 4.401546222942905, 3.1123631819489628]]'),('[''carolina_materials_1500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1244094913989693186) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1244094913989693186) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 3.0 in stage 0.0 (TID 3)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_477694363814657591'),('477694363814657591'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H24Pt4Rh4Te4'),('H6PtRhTe'),('A6BCD'),('[''H'', ''Pt'', ''Rh'', ''Te'']'),('[0.6666666666666666, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111]'),('[52, 52, 52, 52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 78, 78, 78, 78, 45, 45, 45, 45]'),('36'::int4),('4'::int4),('0'::int4),('[[6.98051536, 0.0, 0.0], [0.0, 6.98051536, 0.0], [0.0, 0.0, 6.98051536]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.74512884, 1.74512884, 5.2353865200000005], [1.74512884, 5.2353865200000005, 1.74512884], [5.2353865200000005, 1.74512884, 1.74512884], [5.2353865200000005, 5.2353865200000005, 5.2353865200000005], [3.49025768, 1.7238541837270207, 0.0], [0.0, 1.766403496272979, 0.0], [1.766403496272979, 0.0, 0.0], [5.214111863727021, 0.0, 0.0], [3.49025768, 0.0, 5.256661176272979], [3.49025768, 0.0, 1.7238541837270207], [3.49025768, 5.214111863727021, 3.49025768], [0.0, 5.256661176272979, 3.49025768], [1.766403496272979, 3.49025768, 3.49025768], [5.214111863727021, 3.49025768, 3.49025768], [3.49025768, 3.49025768, 1.766403496272979], [3.49025768, 3.49025768, 5.214111863727021], [0.0, 1.7238541837270207, 3.49025768], [3.49025768, 1.766403496272979, 3.49025768], [5.256661176272979, 0.0, 3.49025768], [1.7238541837270207, 0.0, 3.49025768], [0.0, 0.0, 1.766403496272979], [0.0, 0.0, 5.214111863727021], [0.0, 5.214111863727021, 0.0], [3.49025768, 5.256661176272979, 0.0], [5.256661176272979, 3.49025768, 0.0], [1.7238541837270207, 3.49025768, 0.0], [0.0, 3.49025768, 5.256661176272979], [0.0, 3.49025768, 1.7238541837270207], [3.49025768, 0.0, 0.0], [3.49025768, 3.49025768, 3.49025768], [0.0, 0.0, 3.49025768], [0.0, 3.49025768, 0.0], [1.74512884, 1.74512884, 1.74512884], [1.74512884, 5.2353865200000005, 5.2353865200000005], [5.2353865200000005, 1.74512884, 5.2353865200000005], [5.2353865200000005, 5.2353865200000005, 1.74512884]]'),('[''carolina_materials_375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_477694363814657591) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_477694363814657591) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 24.0 in stage 0.0 (TID 24)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1924170301885722002'),('1924170301885722002'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('CaIPt6Sc2'),('CaIPt6Sc2'),('A6B2CD'),('[''Ca'', ''I'', ''Pt'', ''Sc'']'),('[0.1, 0.1, 0.6, 0.2]'),('[20, 53, 78, 78, 78, 78, 78, 78, 21, 21]'),('10'::int4),('4'::int4),('0'::int4),('[[6.95281606, 0.0, 0.0], [3.476408030000001, 6.02131533580043, 0.0], [3.476408030000001, 2.007105111933477, 5.676950540809383]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.952816060000002, 4.014210223866954, 2.8384752704046914], [0.0, 0.0, 0.0], [1.7382040150000004, 1.0035525559667384, 2.8384752704046914], [5.214612045000001, 1.0035525559667384, 2.8384752704046914], [5.214612045000001, 3.010657667900215, 0.0], [1.7382040150000004, 3.010657667900215, 0.0], [3.476408030000001, 4.014210223866954, 2.8384752704046914], [3.47640803, 0.0, 0.0], [10.429224090000002, 6.02131533580043, 4.257712905607037], [3.476408030000001, 2.007105111933477, 1.4192376352023457]]'),('[''carolina_materials_3000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1924170301885722002) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1924170301885722002) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 16.0 in stage 0.0 (TID 16)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1057937176403445841'),('1057937176403445841'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Al2F6PbZr'),('Al2F6PbZr'),('A6B2CD'),('[''Al'', ''F'', ''Pb'', ''Zr'']'),('[0.2, 0.6, 0.1, 0.1]'),('[13, 13, 9, 9, 9, 9, 9, 9, 82, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.67126287, 0.0, 0.0], [3.3356314350000007, 5.777483120743883, 0.0], [3.3356314350000007, 1.925827706914628, 5.447063323825088]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.006894305000001, 5.7774831207438835, 4.085297492868816], [3.335631435, 1.9258277069146277, 1.361765830956272], [6.671262870000001, 5.525218179084053, 3.906919241965521], [6.6712628700000005, 2.1780926485744576, 1.5401440818595662], [8.120610739538389, 4.688436796456655, 1.5401440818595662], [5.221915000461613, 3.0148740312018565, 3.906919241965521], [8.120610739538389, 3.0148740312018565, 3.906919241965521], [5.221915000461613, 4.688436796456655, 1.5401440818595662], [0.0, 0.0, 0.0], [6.67126287, 3.8516554138292554, 2.723531661912544]]'),('[''carolina_materials_2000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1057937176403445841) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1057937176403445841) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 5.0 in stage 0.0 (TID 5)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_381203781975058546'),('381203781975058546'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cs4Si24Tl4Y4'),('CsSi6TlY'),('A6BCD'),('[''Cs'', ''Si'', ''Tl'', ''Y'']'),('[0.1111111111111111, 0.6666666666666666, 0.1111111111111111, 0.1111111111111111]'),('[55, 55, 55, 55, 39, 39, 39, 39, 81, 81, 81, 81, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]'),('36'::int4),('4'::int4),('0'::int4),('[[11.39046649, 0.0, 0.0], [0.0, 11.39046649, 0.0], [0.0, 0.0, 11.39046649]]'),('[0, 0, 0]'),('[False, False, False]'),('[[2.8476166225, 2.8476166225, 8.5428498675], [2.8476166225, 8.5428498675, 2.8476166225], [8.5428498675, 2.8476166225, 2.8476166225], [8.5428498675, 8.5428498675, 8.5428498675], [2.8476166225, 2.8476166225, 2.8476166225], [2.8476166225, 8.5428498675, 8.5428498675], [8.5428498675, 2.8476166225, 8.5428498675], [8.5428498675, 8.5428498675, 2.8476166225], [0.0, 0.0, 0.0], [0.0, 5.695233245, 5.695233245], [5.695233245, 0.0, 5.695233245], [5.695233245, 5.695233245, 0.0], [5.4029841735074635, 2.8476166225, 2.8476166225], [2.8476166225, 2.8476166225, 0.2922490714925366], [0.2922490714925366, 2.8476166225, 2.8476166225], [2.8476166225, 2.8476166225, 5.4029841735074635], [2.8476166225, 5.4029841735074635, 2.8476166225], [2.8476166225, 0.2922490714925366, 2.8476166225], [5.4029841735074635, 8.5428498675, 8.5428498675], [2.8476166225, 8.5428498675, 5.987482316492536], [0.2922490714925366, 8.5428498675, 8.5428498675], [2.8476166225, 8.5428498675, 11.098217418507463], [2.8476166225, 11.098217418507463, 8.5428498675], [2.8476166225, 5.987482316492536, 8.5428498675], [11.098217418507463, 2.8476166225, 8.5428498675], [8.5428498675, 2.8476166225, 5.987482316492536], [5.987482316492536, 2.8476166225, 8.5428498675], [8.5428498675, 2.8476166225, 11.098217418507463], [8.5428498675, 5.4029841735074635, 8.5428498675], [8.5428498675, 0.2922490714925366, 8.5428498675], [11.098217418507463, 8.5428498675, 2.8476166225], [8.5428498675, 8.5428498675, 0.2922490714925366], [5.987482316492536, 8.5428498675, 2.8476166225], [8.5428498675, 8.5428498675, 5.4029841735074635], [8.5428498675, 11.098217418507463, 2.8476166225], [8.5428498675, 5.987482316492536, 2.8476166225]]'),('[''carolina_materials_625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_381203781975058546) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_381203781975058546) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 11.0 in stage 0.0 (TID 11)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_552325948467825839'),('552325948467825839'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BCr2Pt6Y'),('BCr2Pt6Y'),('A6B2CD'),('[''B'', ''Cr'', ''Pt'', ''Y'']'),('[0.1, 0.2, 0.6, 0.1]'),('[5, 24, 24, 78, 78, 78, 78, 78, 78, 39]'),('10'::int4),('4'::int4),('0'::int4),('[[6.52988503, 0.0, 0.0], [3.264942513939749, 5.655045431264416, 0.0], [3.2649417460602366, 1.8850152915333334, 5.331628381134078]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.529884644999993, 3.7700303613988746, 2.665814190567039], [9.794826967499988, 5.6550455420983115, 3.998721285850559], [3.2649423224999965, 1.8850151806994373, 1.3329070952835196], [1.6324708730301183, 0.9425076457666667, 2.665814190567039], [4.8974133880301185, 0.9425076457666667, 2.665814190567039], [4.897413771969875, 2.827522715632208, 0.0], [1.6324712569698745, 2.827522715632208, 0.0], [3.2649421299999926, 3.7700303613988746, 2.665814190567039], [3.264942515, 0.0, 0.0], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_552325948467825839) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_552325948467825839) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 4.0 in stage 0.0 (TID 4)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_606536193855871962'),('606536193855871962'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('FeO6Pd2Tc'),('FeO6Pd2Tc'),('A6B2CD'),('[''Fe'', ''O'', ''Pd'', ''Tc'']'),('[0.1, 0.6, 0.2, 0.1]'),('[26, 8, 8, 8, 8, 8, 8, 46, 46, 43]'),('10'::int4),('4'::int4),('0'::int4),('[[5.5419642, 0.0, 0.0], [2.7709821000000003, 4.799481784063903, 0.0], [2.7709821000000003, 1.5998272613546347, 4.52499482092386]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.541964200000001, 3.1996545227092685, 2.26249741046193], [1.3854910500000002, 0.7999136306773174, 2.26249741046193], [4.15647315, 0.7999136306773174, 2.26249741046193], [4.15647315, 2.3997408920319514, 0.0], [1.3854910500000002, 2.3997408920319514, 0.0], [2.7709821000000003, 3.1996545227092685, 2.26249741046193], [2.7709821, 0.0, 0.0], [8.3129463, 4.799481784063903, 3.393746115692895], [2.7709821000000003, 1.5998272613546343, 1.131248705230965], [0.0, 0.0, 0.0]]'),('[''carolina_materials_500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_606536193855871962) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_606536193855871962) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 17.0 in stage 0.0 (TID 17)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2054710369908306893'),('2054710369908306893'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('IrSc2Ta6Zr'),('IrSc2Ta6Zr'),('A6B2CD'),('[''Ir'', ''Sc'', ''Ta'', ''Zr'']'),('[0.1, 0.2, 0.6, 0.1]'),('[77, 21, 21, 73, 73, 73, 73, 73, 73, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.94830574, 0.0, 0.0], [3.474152868381627, 6.017408442104194, 0.0], [3.4741521416183603, 2.005802953900427, 5.673267481707873]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.948305374999994, 4.0116056980023105, 2.8366337408539364], [10.42245806249999, 6.017408547003465, 4.254950611280904], [3.474152687499997, 2.0058028490011552, 1.4183168704269682], [6.948305194190722, 5.998826227785521, 4.241810926664545], [6.948305555809266, 2.0243851682190996, 1.4314565550433274], [8.669289227532333, 5.005215910930189, 1.4314565550433274], [5.227321522467654, 3.017995485074433, 4.241810926664545], [8.66928886751717, 3.017995485074433, 4.241810926664545], [5.227321882482817, 5.005215910930189, 1.4314565550433274], [0.0, 0.0, 0.0]]'),('[''carolina_materials_2125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2054710369908306893) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2054710369908306893) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 10.0 in stage 0.0 (TID 10)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1347332179920036108'),('1347332179920036108'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Au2MgPPd6'),('Au2MgPPd6'),('A6B2CD'),('[''Au'', ''Mg'', ''P'', ''Pd'']'),('[0.2, 0.1, 0.1, 0.6]'),('[79, 79, 12, 15, 46, 46, 46, 46, 46, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[7.01043863, 0.0, 0.0], [3.505219315000001, 6.071217945251777, 0.0], [3.505219315000001, 2.023739315083926, 5.723999172198651]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.515657945000003, 6.071217945251777, 4.292999379148988], [3.5052193150000006, 2.023739315083926, 1.4309997930496627], [7.010438630000001, 4.047478630167852, 2.8619995860993255], [0.0, 0.0, 0.0], [1.7526096575000005, 1.011869657541963, 2.8619995860993255], [5.2578289725000005, 1.011869657541963, 2.8619995860993255], [5.2578289725000005, 3.0356089726258886, 0.0], [1.7526096575000005, 3.0356089726258886, 0.0], [3.505219315000001, 4.047478630167852, 2.8619995860993255], [3.505219315, 0.0, 0.0]]'),('[''carolina_materials_1250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1347332179920036108) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1347332179920036108) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 30.0 in stage 0.0 (TID 30)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_631649292482264830'),('631649292482264830'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ca2N6NiSn'),('Ca2N6NiSn'),('A6B2CD'),('[''Ca'', ''N'', ''Ni'', ''Sn'']'),('[0.2, 0.6, 0.1, 0.1]'),('[20, 20, 7, 7, 7, 7, 7, 7, 28, 50]'),('10'::int4),('4'::int4),('0'::int4),('[[5.62397912, 0.0, 0.0], [2.8119895600000007, 4.870508788273252, 0.0], [2.8119895600000007, 1.6235029294244177, 4.591959722688921]]'),('[0, 0, 0]'),('[False, False, False]'),('[[8.435968680000002, 4.870508788273252, 3.443969792016691], [2.8119895600000007, 1.6235029294244174, 1.1479899306722303], [5.62397912, 4.791701813055124, 3.3882448454351524], [5.62397912, 1.7023099046425454, 1.203714877253769], [6.961725057465691, 4.019353835951979, 1.203714877253769], [4.2862331825343105, 2.4746578817456903, 3.3882448454351524], [6.961725057465691, 2.4746578817456903, 3.3882448454351524], [4.2862331825343105, 4.019353835951979, 1.203714877253769], [5.623979120000001, 3.247005858848835, 2.2959798613444606], [0.0, 0.0, 0.0]]'),('[''carolina_materials_3750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_631649292482264830) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_631649292482264830) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 26.0 in stage 0.0 (TID 26)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_352674541625369570'),('352674541625369570'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BRh6SiZn2'),('BRh6SiZn2'),('A6B2CD'),('[''B'', ''Rh'', ''Si'', ''Zn'']'),('[0.1, 0.6, 0.1, 0.2]'),('[5, 45, 45, 45, 45, 45, 45, 14, 30, 30]'),('10'::int4),('4'::int4),('0'::int4),('[[5.99358369, 0.0, 0.0], [2.9967918450000006, 5.190595735248076, 0.0], [2.9967918450000006, 1.7301985784160256, 4.893740590389183]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.993583690000001, 3.460397156832051, 2.4468702951945915], [5.993583690000001, 5.112531390044126, 3.6151056149292864], [5.99358369, 1.808262923619976, 1.278634975459897], [7.424373906423582, 4.286464273438088, 1.278634975459897], [4.56279347357642, 2.6343300402260135, 3.6151056149292864], [7.424373906423582, 2.6343300402260135, 3.6151056149292864], [4.56279347357642, 4.286464273438088, 1.278634975459897], [0.0, 0.0, 0.0], [8.990375535000002, 5.190595735248076, 3.6703054427918875], [2.9967918450000006, 1.7301985784160254, 1.2234351475972958]]'),('[''carolina_materials_3250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_352674541625369570) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_352674541625369570) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 8.0 in stage 0.0 (TID 8)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_532900385002343283'),('532900385002343283'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuBi6Cl2Zn'),('AuBi6Cl2Zn'),('A6B2CD'),('[''Au'', ''Bi'', ''Cl'', ''Zn'']'),('[0.1, 0.6, 0.2, 0.1]'),('[79, 83, 83, 83, 83, 83, 83, 17, 17, 30]'),('10'::int4),('4'::int4),('0'::int4),('[[7.78270575, 0.0, 0.0], [3.891352875000001, 6.740020889679222, 0.0], [3.891352875000001, 2.2466736298930745, 6.354552635241553]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.782705750000001, 4.493347259786148, 3.1772763176207763], [1.9456764375000004, 1.1233368149465373, 3.1772763176207763], [5.8370293125, 1.1233368149465373, 3.1772763176207763], [5.8370293125, 3.370010444839611, 0.0], [1.9456764375000004, 3.370010444839611, 0.0], [3.891352875000001, 4.493347259786148, 3.1772763176207763], [3.891352875, 0.0, 0.0], [11.674058625, 6.740020889679222, 4.765914476431164], [3.8913528750000004, 2.246673629893074, 1.5886381588103882], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_532900385002343283) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_532900385002343283) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 25.0 in stage 0.0 (TID 25)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_157904001041651026'),('157904001041651026'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Al2BrCdPd6'),('Al2BrCdPd6'),('A6B2CD'),('[''Al'', ''Br'', ''Cd'', ''Pd'']'),('[0.2, 0.1, 0.1, 0.6]'),('[13, 13, 35, 48, 46, 46, 46, 46, 46, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[6.55614559, 0.0, 0.0], [3.278072795000001, 5.6777886318493165, 0.0], [3.278072795000001, 1.8925962106164391, 5.353070458299388]]'),('[0, 0, 0]'),('[False, False, False]'),('[[9.834218385000002, 5.6777886318493165, 4.014802843724541], [3.278072795, 1.892596210616439, 1.338267614574847], [6.55614559, 3.785192421232878, 2.676535229149694], [0.0, 0.0, 0.0], [1.6390363975000004, 0.9462981053082196, 2.676535229149694], [4.9171091925, 0.9462981053082196, 2.676535229149694], [4.9171091925, 2.8388943159246582, 0.0], [1.6390363975000004, 2.8388943159246582, 0.0], [3.278072795000001, 3.785192421232878, 2.676535229149694], [3.278072795, 0.0, 0.0]]'),('[''carolina_materials_3125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_157904001041651026) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_157904001041651026) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 20.0 in stage 0.0 (TID 20)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1485067041409263491'),('1485067041409263491'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('As6Au2FSi'),('As6Au2FSi'),('A6B2CD'),('[''As'', ''Au'', ''F'', ''Si'']'),('[0.6, 0.2, 0.1, 0.1]'),('[33, 33, 33, 33, 33, 33, 79, 79, 9, 14]'),('10'::int4),('4'::int4),('0'::int4),('[[7.08554115, 0.0, 0.0], [3.542770575000001, 6.136258635460005, 0.0], [3.542770575000001, 2.0454195451533357, 5.785320122997708]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.7713852875000005, 1.0227097725766678, 2.892660061498854], [5.314155862500001, 1.0227097725766678, 2.892660061498854], [5.314155862500001, 3.0681293177300026, 0.0], [1.7713852875000005, 3.0681293177300026, 0.0], [3.542770575000001, 4.0908390903066705, 2.892660061498854], [3.542770575, 0.0, 0.0], [10.628311725000001, 6.136258635460005, 4.338990092248281], [3.5427705750000005, 2.0454195451533352, 1.446330030749427], [0.0, 0.0, 0.0], [7.085541150000001, 4.0908390903066705, 2.892660061498854]]'),('[''carolina_materials_2500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1485067041409263491) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1485067041409263491) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 9.0 in stage 0.0 (TID 9)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2195656563737071413'),('2195656563737071413'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Be6Cd2NPb'),('Be6Cd2NPb'),('A6B2CD'),('[''Be'', ''Cd'', ''N'', ''Pb'']'),('[0.6, 0.2, 0.1, 0.1]'),('[4, 4, 4, 4, 4, 4, 48, 48, 7, 82]'),('10'::int4),('4'::int4),('0'::int4),('[[5.9350509, 0.0, 0.0], [2.967525451670129, 5.139904123728094, 0.0], [2.9675248183298595, 1.7133014964624584, 4.845948425462543]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.935050462103095, 4.763488058658801, 3.368294888097259], [5.9350507078968935, 2.0897175615317516, 1.4776535373652842], [7.092827439237489, 4.095045398711648, 1.4776535373652842], [4.7772737307624995, 2.7581602214789034, 3.368294888097259], [7.092827192140492, 2.7581602214789034, 3.368294888097259], [4.777273977859497, 4.095045398711648, 1.4776535373652842], [8.902575877499991, 5.139904215142915, 3.6344613190969075], [2.9675252924999973, 1.713301405047638, 1.2114871063656358], [5.935050584999995, 3.426602810095276, 2.4229742127312717], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2195656563737071413) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2195656563737071413) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 28.0 in stage 0.0 (TID 28)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_198392400113100761'),('198392400113100761'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Be6Na2VW'),('Be6Na2VW'),('A6B2CD'),('[''Be'', ''Na'', ''V'', ''W'']'),('[0.6, 0.2, 0.1, 0.1]'),('[4, 4, 4, 4, 4, 4, 11, 11, 23, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.40413484, 0.0, 0.0], [3.202067418664565, 5.5461423876004785, 0.0], [3.2020664913354127, 1.8487143076648076, 5.228953693705294]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.404134139859937, 5.5671347448412165, 3.9365590148665133], [6.404134610140042, 1.8277219504240703, 1.2923946788387806], [8.02334812128314, 4.632281478552759, 1.2923946788387806], [4.784920628716837, 2.7625752167125275, 3.9365590148665133], [8.023347652353635, 2.7625752167125275, 3.9365590148665133], [4.784921097646343, 4.632281478552759, 1.2923946788387806], [9.606201562499983, 5.546142521448965, 3.9217152702789706], [3.2020671874999946, 1.8487141738163215, 1.3072384234263235], [6.404134374999989, 3.697428347632643, 2.614476846852647], [0.0, 0.0, 0.0]]'),('[''carolina_materials_3500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_198392400113100761) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_198392400113100761) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 6.0 in stage 0.0 (TID 6)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1270460233791768030'),('1270460233791768030'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('C6BrLiRb2'),('BrC6LiRb2'),('A6B2CD'),('[''Br'', ''C'', ''Li'', ''Rb'']'),('[0.1, 0.6, 0.1, 0.2]'),('[35, 6, 6, 6, 6, 6, 6, 3, 37, 37]'),('10'::int4),('4'::int4),('0'::int4),('[[6.22002281, 0.0, 0.0], [3.1100114050000007, 5.386697765578668, 0.0], [3.1100114050000007, 1.7955659218595563, 5.078627357657466]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [6.220022810000001, 5.57274224019876, 3.940523827849255], [6.220022810000001, 1.6095214472394637, 1.1381035298082107], [7.93614775375473, 4.581937041958936, 1.1381035298082107], [4.503897866245271, 2.6003266454792877, 3.940523827849255], [7.93614775375473, 2.6003266454792877, 3.940523827849255], [4.503897866245271, 4.581937041958936, 1.1381035298082107], [6.2200228100000015, 3.591131843719112, 2.539313678828733], [9.330034215000001, 5.386697765578669, 3.8089705182430995], [3.1100114050000007, 1.795565921859556, 1.2696568394143666]]'),('[''carolina_materials_750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1270460233791768030) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1270460233791768030) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 27.0 in stage 0.0 (TID 27)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_415786485584637102'),('415786485584637102'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuNi2PtW6'),('AuNi2PtW6'),('A6B2CD'),('[''Au'', ''Ni'', ''Pt'', ''W'']'),('[0.1, 0.2, 0.1, 0.6]'),('[79, 28, 28, 78, 74, 74, 74, 74, 74, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.76500733, 0.0, 0.0], [3.382503665000001, 5.8586682045679375, 0.0], [3.382503665000001, 1.9528894015226461, 5.523605354896004]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.765007330000001, 3.905778803045292, 2.761802677448002], [10.147510995000003, 5.8586682045679375, 4.142704016172003], [3.3825036650000007, 1.952889401522646, 1.380901338724001], [0.0, 0.0, 0.0], [6.765007330000001, 5.888349701888224, 4.1636920042029475], [6.76500733, 1.9232079042023595, 1.3599133506930563], [8.481964093201729, 4.897064252466758, 1.3599133506930563], [5.048050566798273, 2.914493353623826, 4.1636920042029475], [8.481964093201729, 2.914493353623826, 4.1636920042029475], [5.048050566798273, 4.897064252466758, 1.3599133506930563]]'),('[''carolina_materials_3375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_415786485584637102) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_415786485584637102) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 31.0 in stage 0.0 (TID 31)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1292185044023496505'),('1292185044023496505'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cs24Mn4O24'),('Cs6MnO6'),('A6B6C'),('[''Cs'', ''Mn'', ''O'']'),('[0.46153846153846156, 0.07692307692307693, 0.46153846153846156]'),('[55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 25, 25, 25, 25, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]'),('52'::int4),('3'::int4),('0'::int4),('[[11.05343824, 0.0, 0.0], [0.0, 11.05343824, 0.0], [0.0, 0.0, 11.05343824]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 8.29007868, 8.29007868], [2.76335956, 0.0, 8.29007868], [0.0, 2.76335956, 8.29007868], [8.29007868, 0.0, 8.29007868], [2.76335956, 8.29007868, 0.0], [2.76335956, 2.76335956, 0.0], [0.0, 2.76335956, 2.76335956], [2.76335956, 5.52671912, 2.76335956], [0.0, 8.29007868, 2.76335956], [8.29007868, 5.52671912, 2.76335956], [2.76335956, 2.76335956, 5.52671912], [2.76335956, 8.29007868, 5.52671912], [5.52671912, 8.29007868, 2.76335956], [8.29007868, 0.0, 2.76335956], [5.52671912, 2.76335956, 2.76335956], [2.76335956, 0.0, 2.76335956], [8.29007868, 8.29007868, 5.52671912], [8.29007868, 2.76335956, 5.52671912], [5.52671912, 2.76335956, 8.29007868], [8.29007868, 5.52671912, 8.29007868], [5.52671912, 8.29007868, 8.29007868], [2.76335956, 5.52671912, 8.29007868], [8.29007868, 2.76335956, 0.0], [8.29007868, 8.29007868, 0.0], [5.52671912, 0.0, 0.0], [5.52671912, 5.52671912, 5.52671912], [0.0, 0.0, 5.52671912], [0.0, 5.52671912, 0.0], [5.52671912, 0.0, 9.151814341681668], [0.0, 0.0, 7.428343018318332], [3.625095221681669, 0.0, 0.0], [7.428343018318332, 0.0, 0.0], [5.52671912, 9.151814341681668, 0.0], [5.52671912, 1.9016238983183313, 0.0], [5.52671912, 5.52671912, 3.625095221681669], [0.0, 5.52671912, 1.9016238983183313], [3.625095221681669, 5.52671912, 5.52671912], [7.428343018318332, 5.52671912, 5.52671912], [5.52671912, 3.625095221681669, 5.52671912], [5.52671912, 7.428343018318332, 5.52671912], [0.0, 0.0, 3.625095221681669], [5.52671912, 0.0, 1.9016238983183313], [9.151814341681668, 0.0, 5.52671912], [1.9016238983183313, 0.0, 5.52671912], [0.0, 9.151814341681668, 5.52671912], [0.0, 1.9016238983183313, 5.52671912], [0.0, 5.52671912, 9.151814341681668], [5.52671912, 5.52671912, 7.428343018318332], [9.151814341681668, 5.52671912, 0.0], [1.9016238983183313, 5.52671912, 0.0], [0.0, 3.625095221681669, 0.0], [0.0, 7.428343018318332, 0.0]]'),('[''carolina_materials_3875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1292185044023496505) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1292185044023496505) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2035392092515548233) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 14.0 in stage 0.0 (TID 14)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_500162048421940762'),('500162048421940762'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AgGeO6Re2'),('AgGeO6Re2'),('A6B2CD'),('[''Ag'', ''Ge'', ''O'', ''Re'']'),('[0.1, 0.1, 0.6, 0.2]'),('[47, 32, 8, 8, 8, 8, 8, 8, 75, 75]'),('10'::int4),('4'::int4),('0'::int4),('[[5.51715877, 0.0, 0.0], [2.7585793850000004, 4.777999651532107, 0.0], [2.7585793850000004, 1.5926665505107025, 4.504741272140418]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.517158770000001, 3.1853331010214045, 2.252370636070209], [0.0, 0.0, 0.0], [5.51715877, 4.870971688831493, 3.444297112140438], [5.517158770000001, 1.499694513211316, 1.0604441599999799], [6.976964608642864, 4.028152394926448, 1.0604441599999799], [4.057352931357137, 2.3425138071163603, 3.444297112140438], [6.976964608642864, 2.3425138071163603, 3.444297112140438], [4.057352931357137, 4.028152394926448, 1.0604441599999799], [8.275738155, 4.777999651532107, 3.3785559541053134], [2.7585793850000004, 1.5926665505107023, 1.1261853180351045]]'),('[''carolina_materials_1750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_500162048421940762) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_500162048421940762) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 21.0 in stage 0.0 (TID 21)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_71400504959801900'),('71400504959801900'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ga2IrPtW6'),('Ga2IrPtW6'),('A6B2CD'),('[''Ga'', ''Ir'', ''Pt'', ''W'']'),('[0.2, 0.1, 0.1, 0.6]'),('[31, 31, 77, 78, 74, 74, 74, 74, 74, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.76833052, 0.0, 0.0], [3.3841652618080778, 5.86154537374226, 0.0], [3.38416456819191, 1.953848591400618, 5.526318353564524]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.152495262499992, 5.861545473857158, 4.144738765173393], [3.384165087499997, 1.9538484912857195, 1.381579588391131], [6.768330174999994, 3.907696982571439, 2.763159176782262], [0.0, 0.0, 0.0], [6.768330004844791, 5.834986733161172, 4.125958898565209], [6.768330345155198, 1.9804072319817059, 1.4003594549993152], [8.437412429174053, 4.871341808489289, 1.4003594549993152], [5.099247920825936, 2.944052156653589, 4.125958898565209], [8.437412087080146, 2.944052156653589, 4.125958898565209], [5.0992482629198435, 4.871341808489289, 1.4003594549993152]]'),('[''carolina_materials_2625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_71400504959801900) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_71400504959801900) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 19.0 in stage 0.0 (TID 19)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_267228750714462887'),('267228750714462887'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuGa6Tc2Zr'),('AuGa6Tc2Zr'),('A6B2CD'),('[''Au'', ''Ga'', ''Tc'', ''Zr'']'),('[0.1, 0.6, 0.2, 0.1]'),('[79, 31, 31, 31, 31, 31, 31, 43, 43, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.93008826, 0.0, 0.0], [3.4650441300000008, 6.001632483628297, 0.0], [3.4650441300000008, 2.000544161209433, 5.658393369817373]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [6.930088260000001, 6.046923283024517, 4.275820458741457], [6.930088260000001, 1.9552533618132135, 1.3825729110759173], [8.70183330783483, 5.024005802721691, 1.3825729110759173], [5.15834321216517, 2.9781708421160396, 4.275820458741457], [8.701833307834832, 2.9781708421160396, 4.275820458741457], [5.15834321216517, 5.024005802721691, 1.3825729110759173], [10.39513239, 6.001632483628297, 4.24379502736303], [3.4650441300000003, 2.0005441612094326, 1.4145983424543433], [6.930088260000001, 4.001088322418865, 2.8291966849086867]]'),('[''carolina_materials_2375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_267228750714462887) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_267228750714462887) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 29.0 in stage 0.0 (TID 29)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_228316522959754558'),('228316522959754558'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('As6InIrTe2'),('As6InIrTe2'),('A6B2CD'),('[''As'', ''In'', ''Ir'', ''Te'']'),('[0.6, 0.1, 0.1, 0.2]'),('[33, 33, 33, 33, 33, 33, 49, 77, 52, 52]'),('10'::int4),('4'::int4),('0'::int4),('[[7.17621399, 0.0, 0.0], [3.588106995000001, 6.214783618333287, 0.0], [3.588106995000001, 2.0715945394444293, 5.859354186840714]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.176213990000002, 6.106190881166955, 4.317728979292614], [7.176213990000001, 2.1801872766107615, 1.5416252075481005], [8.87622341844747, 5.124689980027907, 1.5416252075481005], [5.476204561552531, 3.16168817774981, 4.317728979292614], [8.87622341844747, 3.16168817774981, 4.317728979292614], [5.476204561552532, 5.124689980027907, 1.5416252075481005], [0.0, 0.0, 0.0], [7.176213990000001, 4.143189078888859, 2.929677093420357], [10.764320985000001, 6.214783618333288, 4.394515640130535], [3.5881069950000004, 2.0715945394444293, 1.4648385467101785]]'),('[''carolina_materials_3625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_228316522959754558) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_228316522959754558) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 22.0 in stage 0.0 (TID 22)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1981575329244962223'),('1981575329244962223'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('CoHg6SZr2'),('CoHg6SZr2'),('A6B2CD'),('[''Co'', ''Hg'', ''S'', ''Zr'']'),('[0.1, 0.6, 0.1, 0.2]'),('[27, 80, 80, 80, 80, 80, 80, 16, 40, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[7.86184303, 0.0, 0.0], [3.930921515000001, 6.808555784545624, 0.0], [3.930921515000001, 2.2695185948485417, 6.419167953785474]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.861843030000001, 4.539037189697083, 3.209583976892737], [1.9654607575000005, 1.1347592974242708, 3.209583976892737], [5.8963822725, 1.1347592974242708, 3.209583976892737], [5.8963822725, 3.404277892272812, 0.0], [1.9654607575000005, 3.404277892272812, 0.0], [3.930921515000001, 4.539037189697083, 3.209583976892737], [3.930921515, 0.0, 0.0], [0.0, 0.0, 0.0], [11.792764545000002, 6.808555784545624, 4.814375965339105], [3.9309215150000005, 2.2695185948485417, 1.6047919884463684]]'),('[''carolina_materials_2750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1981575329244962223) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1981575329244962223) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 15.0 in stage 0.0 (TID 15)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_879064004920091671'),('879064004920091671'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BiGe6Nb2Pd'),('BiGe6Nb2Pd'),('A6B2CD'),('[''Bi'', ''Ge'', ''Nb'', ''Pd'']'),('[0.1, 0.6, 0.2, 0.1]'),('[83, 32, 32, 32, 32, 32, 32, 41, 41, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[7.10760297, 0.0, 0.0], [3.553801485000001, 6.155364732033726, 0.0], [3.553801485000001, 2.051788244011242, 5.80333352359675]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.107602970000001, 4.103576488022484, 2.901666761798375], [7.107602970000002, 6.270664479976759, 4.434029376337181], [7.10760297, 1.9364884960682087, 1.369304147259569], [8.98435622326861, 5.187120483999621, 1.369304147259569], [5.230849716731392, 3.0200324920453463, 4.434029376337181], [8.98435622326861, 3.0200324920453463, 4.434029376337181], [5.230849716731392, 5.187120483999621, 1.369304147259569], [10.661404455000001, 6.155364732033726, 4.352500142697563], [3.5538014850000006, 2.051788244011242, 1.4508333808991876], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_879064004920091671) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_879064004920091671) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 23.0 in stage 0.0 (TID 23)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_294096661948121832'),('294096661948121832'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H24Ge4Ru4Sc4'),('GeH6RuSc'),('A6BCD'),('[''Ge'', ''H'', ''Ru'', ''Sc'']'),('[0.1111111111111111, 0.6666666666666666, 0.1111111111111111, 0.1111111111111111]'),('[21, 21, 21, 21, 32, 32, 32, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44, 44, 44, 44]'),('36'::int4),('4'::int4),('0'::int4),('[[6.53079114, 0.0, 0.0], [0.0, 6.53079114, 0.0], [0.0, 0.0, 6.53079114]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.632697785, 1.632697785, 4.898093355], [1.632697785, 4.898093355, 1.632697785], [4.898093355, 1.632697785, 1.632697785], [4.898093355, 4.898093355, 4.898093355], [0.0, 0.0, 0.0], [0.0, 3.26539557, 3.26539557], [3.26539557, 0.0, 3.26539557], [3.26539557, 3.26539557, 0.0], [2.9710431477493127, 1.632697785, 1.632697785], [1.632697785, 1.632697785, 0.2943524222506872], [0.2943524222506872, 1.632697785, 1.632697785], [1.632697785, 1.632697785, 2.9710431477493127], [1.632697785, 2.9710431477493127, 1.632697785], [1.632697785, 0.2943524222506872, 1.632697785], [2.9710431477493127, 4.898093355, 4.898093355], [1.632697785, 4.898093355, 3.5597479922506876], [0.2943524222506872, 4.898093355, 4.898093355], [1.632697785, 4.898093355, 6.236438717749312], [1.632697785, 6.236438717749312, 4.898093355], [1.632697785, 3.5597479922506876, 4.898093355], [6.236438717749312, 1.632697785, 4.898093355], [4.898093355, 1.632697785, 3.5597479922506876], [3.5597479922506876, 1.632697785, 4.898093355], [4.898093355, 1.632697785, 6.236438717749312], [4.898093355, 2.9710431477493127, 4.898093355], [4.898093355, 0.2943524222506872, 4.898093355], [6.236438717749312, 4.898093355, 1.632697785], [4.898093355, 4.898093355, 0.2943524222506872], [3.5597479922506876, 4.898093355, 1.632697785], [4.898093355, 4.898093355, 2.9710431477493127], [4.898093355, 6.236438717749312, 1.632697785], [4.898093355, 3.5597479922506876, 1.632697785], [3.26539557, 0.0, 0.0], [3.26539557, 3.26539557, 3.26539557], [0.0, 0.0, 3.26539557], [0.0, 3.26539557, 0.0]]'),('[''carolina_materials_2875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_294096661948121832) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_294096661948121832) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 7.0 in stage 0.0 (TID 7)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_229347831182344167'),('229347831182344167'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BaGe2RhSe6'),('BaGe2RhSe6'),('A6B2CD'),('[''Ba'', ''Ge'', ''Rh'', ''Se'']'),('[0.1, 0.2, 0.1, 0.6]'),('[56, 32, 32, 45, 34, 34, 34, 34, 34, 34]'),('10'::int4),('4'::int4),('0'::int4),('[[7.13503554, 0.0, 0.0], [3.5675177700000007, 6.17912203454482, 0.0], [3.5675177700000007, 2.0597073448482734, 5.8257321232078105]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.1350355400000005, 4.119414689696547, 2.9128660616039053], [10.702553309999999, 6.179122034544821, 4.369299092405858], [3.5675177700000003, 2.0597073448482734, 1.4564330308019526], [0.0, 0.0, 0.0], [1.7837588850000003, 1.0298536724241367, 2.9128660616039053], [5.351276655, 1.0298536724241367, 2.9128660616039053], [5.351276655, 3.08956101727241, 0.0], [1.7837588850000003, 3.08956101727241, 0.0], [3.5675177700000007, 4.119414689696547, 2.9128660616039053], [3.56751777, 0.0, 0.0]]'),('[''carolina_materials_875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_229347831182344167) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_229347831182344167) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 18.0 in stage 0.0 (TID 18)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1398328425570851091'),('1398328425570851091'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cd6Co2ISc'),('Cd6Co2ISc'),('A6B2CD'),('[''Cd'', ''Co'', ''I'', ''Sc'']'),('[0.6, 0.2, 0.1, 0.1]'),('[48, 48, 48, 48, 48, 48, 27, 27, 53, 21]'),('10'::int4),('4'::int4),('0'::int4),('[[7.07251383, 0.0, 0.0], [3.536256915000001, 6.124976645396776, 0.0], [3.536256915000001, 2.041658881798926, 5.774683360759056]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.7681284575000005, 1.020829440899463, 2.887341680379528], [5.3043853725000005, 1.020829440899463, 2.887341680379528], [5.3043853725000005, 3.062488322698388, 0.0], [1.7681284575000005, 3.062488322698388, 0.0], [3.536256915000001, 4.083317763597851, 2.887341680379528], [3.536256915, 0.0, 0.0], [10.608770745000001, 6.124976645396776, 4.331012520569292], [3.5362569150000005, 2.0416588817989254, 1.443670840189764], [0.0, 0.0, 0.0], [7.072513830000001, 4.083317763597851, 2.887341680379528]]'),('[''carolina_materials_2250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1398328425570851091) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1398328425570851091) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_644395201296824972'),('644395201296824972'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('C6GaGeRh2'),('C6GaGeRh2'),('A6B2CD'),('[''C'', ''Ga'', ''Ge'', ''Rh'']'),('[0.6, 0.1, 0.1, 0.2]'),('[6, 6, 6, 6, 6, 6, 31, 32, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.52952029, 0.0, 0.0], [2.764760145471036, 4.788704672105368, 0.0], [2.764759824528962, 1.5962349524671298, 4.514834237025945]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.529520050613048, 4.77647257879541, 3.3774762486348493], [5.529520209386949, 1.6084670457770878, 1.1373579883910958], [6.901306993034689, 3.9844711725563196, 1.1373579883910958], [4.157733266965308, 2.400468452016178, 3.3774762486348493], [6.901306778498158, 2.400468452016178, 3.3774762486348493], [4.157733481501839, 3.9844711725563196, 1.1373579883910958], [0.0, 0.0, 0.0], [5.529520129999999, 3.192469812286249, 2.2574171185129726], [8.294280194999999, 4.788704718429373, 3.386125677769459], [2.7647600649999995, 1.5962349061431245, 1.1287085592564863]]'),('[''carolina_materials_250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_644395201296824972) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_644395201296824972) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2035392092515548233) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 2.0 in stage 0.0 (TID 2) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_644395201296824972'),('644395201296824972'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('C6GaGeRh2'),('C6GaGeRh2'),('A6B2CD'),('[''C'', ''Ga'', ''Ge'', ''Rh'']'),('[0.6, 0.1, 0.1, 0.2]'),('[6, 6, 6, 6, 6, 6, 31, 32, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.52952029, 0.0, 0.0], [2.764760145471036, 4.788704672105368, 0.0], [2.764759824528962, 1.5962349524671298, 4.514834237025945]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.529520050613048, 4.77647257879541, 3.3774762486348493], [5.529520209386949, 1.6084670457770878, 1.1373579883910958], [6.901306993034689, 3.9844711725563196, 1.1373579883910958], [4.157733266965308, 2.400468452016178, 3.3774762486348493], [6.901306778498158, 2.400468452016178, 3.3774762486348493], [4.157733481501839, 3.9844711725563196, 1.1373579883910958], [0.0, 0.0, 0.0], [5.529520129999999, 3.192469812286249, 2.2574171185129726], [8.294280194999999, 4.788704718429373, 3.386125677769459], [2.7647600649999995, 1.5962349061431245, 1.1287085592564863]]'),('[''carolina_materials_250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_644395201296824972) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_644395201296824972) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 10.0 in stage 0.0 (TID 10) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1347332179920036108'),('1347332179920036108'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Au2MgPPd6'),('Au2MgPPd6'),('A6B2CD'),('[''Au'', ''Mg'', ''P'', ''Pd'']'),('[0.2, 0.1, 0.1, 0.6]'),('[79, 79, 12, 15, 46, 46, 46, 46, 46, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[7.01043863, 0.0, 0.0], [3.505219315000001, 6.071217945251777, 0.0], [3.505219315000001, 2.023739315083926, 5.723999172198651]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.515657945000003, 6.071217945251777, 4.292999379148988], [3.5052193150000006, 2.023739315083926, 1.4309997930496627], [7.010438630000001, 4.047478630167852, 2.8619995860993255], [0.0, 0.0, 0.0], [1.7526096575000005, 1.011869657541963, 2.8619995860993255], [5.2578289725000005, 1.011869657541963, 2.8619995860993255], [5.2578289725000005, 3.0356089726258886, 0.0], [1.7526096575000005, 3.0356089726258886, 0.0], [3.505219315000001, 4.047478630167852, 2.8619995860993255], [3.505219315, 0.0, 0.0]]'),('[''carolina_materials_1250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1347332179920036108) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1347332179920036108) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 25.0 in stage 0.0 (TID 25) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_157904001041651026'),('157904001041651026'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Al2BrCdPd6'),('Al2BrCdPd6'),('A6B2CD'),('[''Al'', ''Br'', ''Cd'', ''Pd'']'),('[0.2, 0.1, 0.1, 0.6]'),('[13, 13, 35, 48, 46, 46, 46, 46, 46, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[6.55614559, 0.0, 0.0], [3.278072795000001, 5.6777886318493165, 0.0], [3.278072795000001, 1.8925962106164391, 5.353070458299388]]'),('[0, 0, 0]'),('[False, False, False]'),('[[9.834218385000002, 5.6777886318493165, 4.014802843724541], [3.278072795, 1.892596210616439, 1.338267614574847], [6.55614559, 3.785192421232878, 2.676535229149694], [0.0, 0.0, 0.0], [1.6390363975000004, 0.9462981053082196, 2.676535229149694], [4.9171091925, 0.9462981053082196, 2.676535229149694], [4.9171091925, 2.8388943159246582, 0.0], [1.6390363975000004, 2.8388943159246582, 0.0], [3.278072795000001, 3.785192421232878, 2.676535229149694], [3.278072795, 0.0, 0.0]]'),('[''carolina_materials_3125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_157904001041651026) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_157904001041651026) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 9.0 in stage 0.0 (TID 9) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2195656563737071413'),('2195656563737071413'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Be6Cd2NPb'),('Be6Cd2NPb'),('A6B2CD'),('[''Be'', ''Cd'', ''N'', ''Pb'']'),('[0.6, 0.2, 0.1, 0.1]'),('[4, 4, 4, 4, 4, 4, 48, 48, 7, 82]'),('10'::int4),('4'::int4),('0'::int4),('[[5.9350509, 0.0, 0.0], [2.967525451670129, 5.139904123728094, 0.0], [2.9675248183298595, 1.7133014964624584, 4.845948425462543]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.935050462103095, 4.763488058658801, 3.368294888097259], [5.9350507078968935, 2.0897175615317516, 1.4776535373652842], [7.092827439237489, 4.095045398711648, 1.4776535373652842], [4.7772737307624995, 2.7581602214789034, 3.368294888097259], [7.092827192140492, 2.7581602214789034, 3.368294888097259], [4.777273977859497, 4.095045398711648, 1.4776535373652842], [8.902575877499991, 5.139904215142915, 3.6344613190969075], [2.9675252924999973, 1.713301405047638, 1.2114871063656358], [5.935050584999995, 3.426602810095276, 2.4229742127312717], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2195656563737071413) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2195656563737071413) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 22.0 in stage 0.0 (TID 22) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1981575329244962223'),('1981575329244962223'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('CoHg6SZr2'),('CoHg6SZr2'),('A6B2CD'),('[''Co'', ''Hg'', ''S'', ''Zr'']'),('[0.1, 0.6, 0.1, 0.2]'),('[27, 80, 80, 80, 80, 80, 80, 16, 40, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[7.86184303, 0.0, 0.0], [3.930921515000001, 6.808555784545624, 0.0], [3.930921515000001, 2.2695185948485417, 6.419167953785474]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.861843030000001, 4.539037189697083, 3.209583976892737], [1.9654607575000005, 1.1347592974242708, 3.209583976892737], [5.8963822725, 1.1347592974242708, 3.209583976892737], [5.8963822725, 3.404277892272812, 0.0], [1.9654607575000005, 3.404277892272812, 0.0], [3.930921515000001, 4.539037189697083, 3.209583976892737], [3.930921515, 0.0, 0.0], [0.0, 0.0, 0.0], [11.792764545000002, 6.808555784545624, 4.814375965339105], [3.9309215150000005, 2.2695185948485417, 1.6047919884463684]]'),('[''carolina_materials_2750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1981575329244962223) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1981575329244962223) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 29.0 in stage 0.0 (TID 29) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_228316522959754558'),('228316522959754558'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('As6InIrTe2'),('As6InIrTe2'),('A6B2CD'),('[''As'', ''In'', ''Ir'', ''Te'']'),('[0.6, 0.1, 0.1, 0.2]'),('[33, 33, 33, 33, 33, 33, 49, 77, 52, 52]'),('10'::int4),('4'::int4),('0'::int4),('[[7.17621399, 0.0, 0.0], [3.588106995000001, 6.214783618333287, 0.0], [3.588106995000001, 2.0715945394444293, 5.859354186840714]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.176213990000002, 6.106190881166955, 4.317728979292614], [7.176213990000001, 2.1801872766107615, 1.5416252075481005], [8.87622341844747, 5.124689980027907, 1.5416252075481005], [5.476204561552531, 3.16168817774981, 4.317728979292614], [8.87622341844747, 3.16168817774981, 4.317728979292614], [5.476204561552532, 5.124689980027907, 1.5416252075481005], [0.0, 0.0, 0.0], [7.176213990000001, 4.143189078888859, 2.929677093420357], [10.764320985000001, 6.214783618333288, 4.394515640130535], [3.5881069950000004, 2.0715945394444293, 1.4648385467101785]]'),('[''carolina_materials_3625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_228316522959754558) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_228316522959754558) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 18.0 in stage 0.0 (TID 18) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1398328425570851091'),('1398328425570851091'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cd6Co2ISc'),('Cd6Co2ISc'),('A6B2CD'),('[''Cd'', ''Co'', ''I'', ''Sc'']'),('[0.6, 0.2, 0.1, 0.1]'),('[48, 48, 48, 48, 48, 48, 27, 27, 53, 21]'),('10'::int4),('4'::int4),('0'::int4),('[[7.07251383, 0.0, 0.0], [3.536256915000001, 6.124976645396776, 0.0], [3.536256915000001, 2.041658881798926, 5.774683360759056]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.7681284575000005, 1.020829440899463, 2.887341680379528], [5.3043853725000005, 1.020829440899463, 2.887341680379528], [5.3043853725000005, 3.062488322698388, 0.0], [1.7681284575000005, 3.062488322698388, 0.0], [3.536256915000001, 4.083317763597851, 2.887341680379528], [3.536256915, 0.0, 0.0], [10.608770745000001, 6.124976645396776, 4.331012520569292], [3.5362569150000005, 2.0416588817989254, 1.443670840189764], [0.0, 0.0, 0.0], [7.072513830000001, 4.083317763597851, 2.887341680379528]]'),('[''carolina_materials_2250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1398328425570851091) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1398328425570851091) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 28.0 in stage 0.0 (TID 28) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_198392400113100761'),('198392400113100761'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Be6Na2VW'),('Be6Na2VW'),('A6B2CD'),('[''Be'', ''Na'', ''V'', ''W'']'),('[0.6, 0.2, 0.1, 0.1]'),('[4, 4, 4, 4, 4, 4, 11, 11, 23, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.40413484, 0.0, 0.0], [3.202067418664565, 5.5461423876004785, 0.0], [3.2020664913354127, 1.8487143076648076, 5.228953693705294]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.404134139859937, 5.5671347448412165, 3.9365590148665133], [6.404134610140042, 1.8277219504240703, 1.2923946788387806], [8.02334812128314, 4.632281478552759, 1.2923946788387806], [4.784920628716837, 2.7625752167125275, 3.9365590148665133], [8.023347652353635, 2.7625752167125275, 3.9365590148665133], [4.784921097646343, 4.632281478552759, 1.2923946788387806], [9.606201562499983, 5.546142521448965, 3.9217152702789706], [3.2020671874999946, 1.8487141738163215, 1.3072384234263235], [6.404134374999989, 3.697428347632643, 2.614476846852647], [0.0, 0.0, 0.0]]'),('[''carolina_materials_3500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_198392400113100761) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_198392400113100761) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 26.0 in stage 0.0 (TID 26) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_352674541625369570'),('352674541625369570'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BRh6SiZn2'),('BRh6SiZn2'),('A6B2CD'),('[''B'', ''Rh'', ''Si'', ''Zn'']'),('[0.1, 0.6, 0.1, 0.2]'),('[5, 45, 45, 45, 45, 45, 45, 14, 30, 30]'),('10'::int4),('4'::int4),('0'::int4),('[[5.99358369, 0.0, 0.0], [2.9967918450000006, 5.190595735248076, 0.0], [2.9967918450000006, 1.7301985784160256, 4.893740590389183]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.993583690000001, 3.460397156832051, 2.4468702951945915], [5.993583690000001, 5.112531390044126, 3.6151056149292864], [5.99358369, 1.808262923619976, 1.278634975459897], [7.424373906423582, 4.286464273438088, 1.278634975459897], [4.56279347357642, 2.6343300402260135, 3.6151056149292864], [7.424373906423582, 2.6343300402260135, 3.6151056149292864], [4.56279347357642, 4.286464273438088, 1.278634975459897], [0.0, 0.0, 0.0], [8.990375535000002, 5.190595735248076, 3.6703054427918875], [2.9967918450000006, 1.7301985784160254, 1.2234351475972958]]'),('[''carolina_materials_3250'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_352674541625369570) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_352674541625369570) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 13.0 in stage 0.0 (TID 13) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_425343146072841686'),('425343146072841686'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ge2LiRh6Zr'),('Ge2LiRh6Zr'),('A6B2CD'),('[''Ge'', ''Li'', ''Rh'', ''Zr'']'),('[0.2, 0.1, 0.6, 0.1]'),('[32, 32, 3, 45, 45, 45, 45, 45, 45, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.32863268, 0.0, 0.0], [3.164316340000001, 5.4807566721003935, 0.0], [3.164316340000001, 1.8269188907001317, 5.167306945167471]]'),('[0, 0, 0]'),('[False, False, False]'),('[[9.492949020000003, 5.4807566721003935, 3.8754802088756035], [3.1643163400000005, 1.8269188907001312, 1.2918267362918678], [6.328632680000001, 3.6538377814002625, 2.5836534725837357], [6.328632680000001, 5.345107286775108, 3.779561608648307], [6.328632680000001, 1.9625682760254166, 1.387745336519164], [7.79331503630056, 4.499472534087685, 1.387745336519164], [4.863950323699442, 2.80820302871284, 3.779561608648307], [7.79331503630056, 2.80820302871284, 3.779561608648307], [4.863950323699442, 4.499472534087685, 1.387745336519164], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_425343146072841686) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_425343146072841686) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 31.0 in stage 0.0 (TID 31) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1292185044023496505'),('1292185044023496505'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cs24Mn4O24'),('Cs6MnO6'),('A6B6C'),('[''Cs'', ''Mn'', ''O'']'),('[0.46153846153846156, 0.07692307692307693, 0.46153846153846156]'),('[55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 25, 25, 25, 25, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]'),('52'::int4),('3'::int4),('0'::int4),('[[11.05343824, 0.0, 0.0], [0.0, 11.05343824, 0.0], [0.0, 0.0, 11.05343824]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 8.29007868, 8.29007868], [2.76335956, 0.0, 8.29007868], [0.0, 2.76335956, 8.29007868], [8.29007868, 0.0, 8.29007868], [2.76335956, 8.29007868, 0.0], [2.76335956, 2.76335956, 0.0], [0.0, 2.76335956, 2.76335956], [2.76335956, 5.52671912, 2.76335956], [0.0, 8.29007868, 2.76335956], [8.29007868, 5.52671912, 2.76335956], [2.76335956, 2.76335956, 5.52671912], [2.76335956, 8.29007868, 5.52671912], [5.52671912, 8.29007868, 2.76335956], [8.29007868, 0.0, 2.76335956], [5.52671912, 2.76335956, 2.76335956], [2.76335956, 0.0, 2.76335956], [8.29007868, 8.29007868, 5.52671912], [8.29007868, 2.76335956, 5.52671912], [5.52671912, 2.76335956, 8.29007868], [8.29007868, 5.52671912, 8.29007868], [5.52671912, 8.29007868, 8.29007868], [2.76335956, 5.52671912, 8.29007868], [8.29007868, 2.76335956, 0.0], [8.29007868, 8.29007868, 0.0], [5.52671912, 0.0, 0.0], [5.52671912, 5.52671912, 5.52671912], [0.0, 0.0, 5.52671912], [0.0, 5.52671912, 0.0], [5.52671912, 0.0, 9.151814341681668], [0.0, 0.0, 7.428343018318332], [3.625095221681669, 0.0, 0.0], [7.428343018318332, 0.0, 0.0], [5.52671912, 9.151814341681668, 0.0], [5.52671912, 1.9016238983183313, 0.0], [5.52671912, 5.52671912, 3.625095221681669], [0.0, 5.52671912, 1.9016238983183313], [3.625095221681669, 5.52671912, 5.52671912], [7.428343018318332, 5.52671912, 5.52671912], [5.52671912, 3.625095221681669, 5.52671912], [5.52671912, 7.428343018318332, 5.52671912], [0.0, 0.0, 3.625095221681669], [5.52671912, 0.0, 1.9016238983183313], [9.151814341681668, 0.0, 5.52671912], [1.9016238983183313, 0.0, 5.52671912], [0.0, 9.151814341681668, 5.52671912], [0.0, 1.9016238983183313, 5.52671912], [0.0, 5.52671912, 9.151814341681668], [5.52671912, 5.52671912, 7.428343018318332], [9.151814341681668, 5.52671912, 0.0], [1.9016238983183313, 5.52671912, 0.0], [0.0, 3.625095221681669, 0.0], [0.0, 7.428343018318332, 0.0]]'),('[''carolina_materials_3875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1292185044023496505) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1292185044023496505) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 11.0 in stage 0.0 (TID 11) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_552325948467825839'),('552325948467825839'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BCr2Pt6Y'),('BCr2Pt6Y'),('A6B2CD'),('[''B'', ''Cr'', ''Pt'', ''Y'']'),('[0.1, 0.2, 0.6, 0.1]'),('[5, 24, 24, 78, 78, 78, 78, 78, 78, 39]'),('10'::int4),('4'::int4),('0'::int4),('[[6.52988503, 0.0, 0.0], [3.264942513939749, 5.655045431264416, 0.0], [3.2649417460602366, 1.8850152915333334, 5.331628381134078]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.529884644999993, 3.7700303613988746, 2.665814190567039], [9.794826967499988, 5.6550455420983115, 3.998721285850559], [3.2649423224999965, 1.8850151806994373, 1.3329070952835196], [1.6324708730301183, 0.9425076457666667, 2.665814190567039], [4.8974133880301185, 0.9425076457666667, 2.665814190567039], [4.897413771969875, 2.827522715632208, 0.0], [1.6324712569698745, 2.827522715632208, 0.0], [3.2649421299999926, 3.7700303613988746, 2.665814190567039], [3.264942515, 0.0, 0.0], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_552325948467825839) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_552325948467825839) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 27.0 in stage 0.0 (TID 27) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_415786485584637102'),('415786485584637102'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuNi2PtW6'),('AuNi2PtW6'),('A6B2CD'),('[''Au'', ''Ni'', ''Pt'', ''W'']'),('[0.1, 0.2, 0.1, 0.6]'),('[79, 28, 28, 78, 74, 74, 74, 74, 74, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.76500733, 0.0, 0.0], [3.382503665000001, 5.8586682045679375, 0.0], [3.382503665000001, 1.9528894015226461, 5.523605354896004]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.765007330000001, 3.905778803045292, 2.761802677448002], [10.147510995000003, 5.8586682045679375, 4.142704016172003], [3.3825036650000007, 1.952889401522646, 1.380901338724001], [0.0, 0.0, 0.0], [6.765007330000001, 5.888349701888224, 4.1636920042029475], [6.76500733, 1.9232079042023595, 1.3599133506930563], [8.481964093201729, 4.897064252466758, 1.3599133506930563], [5.048050566798273, 2.914493353623826, 4.1636920042029475], [8.481964093201729, 2.914493353623826, 4.1636920042029475], [5.048050566798273, 4.897064252466758, 1.3599133506930563]]'),('[''carolina_materials_3375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_415786485584637102) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_415786485584637102) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 20.0 in stage 0.0 (TID 20) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1485067041409263491'),('1485067041409263491'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('As6Au2FSi'),('As6Au2FSi'),('A6B2CD'),('[''As'', ''Au'', ''F'', ''Si'']'),('[0.6, 0.2, 0.1, 0.1]'),('[33, 33, 33, 33, 33, 33, 79, 79, 9, 14]'),('10'::int4),('4'::int4),('0'::int4),('[[7.08554115, 0.0, 0.0], [3.542770575000001, 6.136258635460005, 0.0], [3.542770575000001, 2.0454195451533357, 5.785320122997708]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.7713852875000005, 1.0227097725766678, 2.892660061498854], [5.314155862500001, 1.0227097725766678, 2.892660061498854], [5.314155862500001, 3.0681293177300026, 0.0], [1.7713852875000005, 3.0681293177300026, 0.0], [3.542770575000001, 4.0908390903066705, 2.892660061498854], [3.542770575, 0.0, 0.0], [10.628311725000001, 6.136258635460005, 4.338990092248281], [3.5427705750000005, 2.0454195451533352, 1.446330030749427], [0.0, 0.0, 0.0], [7.085541150000001, 4.0908390903066705, 2.892660061498854]]'),('[''carolina_materials_2500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1485067041409263491) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1485067041409263491) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 23.0 in stage 0.0 (TID 23) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_294096661948121832'),('294096661948121832'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H24Ge4Ru4Sc4'),('GeH6RuSc'),('A6BCD'),('[''Ge'', ''H'', ''Ru'', ''Sc'']'),('[0.1111111111111111, 0.6666666666666666, 0.1111111111111111, 0.1111111111111111]'),('[21, 21, 21, 21, 32, 32, 32, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44, 44, 44, 44]'),('36'::int4),('4'::int4),('0'::int4),('[[6.53079114, 0.0, 0.0], [0.0, 6.53079114, 0.0], [0.0, 0.0, 6.53079114]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.632697785, 1.632697785, 4.898093355], [1.632697785, 4.898093355, 1.632697785], [4.898093355, 1.632697785, 1.632697785], [4.898093355, 4.898093355, 4.898093355], [0.0, 0.0, 0.0], [0.0, 3.26539557, 3.26539557], [3.26539557, 0.0, 3.26539557], [3.26539557, 3.26539557, 0.0], [2.9710431477493127, 1.632697785, 1.632697785], [1.632697785, 1.632697785, 0.2943524222506872], [0.2943524222506872, 1.632697785, 1.632697785], [1.632697785, 1.632697785, 2.9710431477493127], [1.632697785, 2.9710431477493127, 1.632697785], [1.632697785, 0.2943524222506872, 1.632697785], [2.9710431477493127, 4.898093355, 4.898093355], [1.632697785, 4.898093355, 3.5597479922506876], [0.2943524222506872, 4.898093355, 4.898093355], [1.632697785, 4.898093355, 6.236438717749312], [1.632697785, 6.236438717749312, 4.898093355], [1.632697785, 3.5597479922506876, 4.898093355], [6.236438717749312, 1.632697785, 4.898093355], [4.898093355, 1.632697785, 3.5597479922506876], [3.5597479922506876, 1.632697785, 4.898093355], [4.898093355, 1.632697785, 6.236438717749312], [4.898093355, 2.9710431477493127, 4.898093355], [4.898093355, 0.2943524222506872, 4.898093355], [6.236438717749312, 4.898093355, 1.632697785], [4.898093355, 4.898093355, 0.2943524222506872], [3.5597479922506876, 4.898093355, 1.632697785], [4.898093355, 4.898093355, 2.9710431477493127], [4.898093355, 6.236438717749312, 1.632697785], [4.898093355, 3.5597479922506876, 1.632697785], [3.26539557, 0.0, 0.0], [3.26539557, 3.26539557, 3.26539557], [0.0, 0.0, 3.26539557], [0.0, 3.26539557, 0.0]]'),('[''carolina_materials_2875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_294096661948121832) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_294096661948121832) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 24.0 in stage 0.0 (TID 24) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1924170301885722002'),('1924170301885722002'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('CaIPt6Sc2'),('CaIPt6Sc2'),('A6B2CD'),('[''Ca'', ''I'', ''Pt'', ''Sc'']'),('[0.1, 0.1, 0.6, 0.2]'),('[20, 53, 78, 78, 78, 78, 78, 78, 21, 21]'),('10'::int4),('4'::int4),('0'::int4),('[[6.95281606, 0.0, 0.0], [3.476408030000001, 6.02131533580043, 0.0], [3.476408030000001, 2.007105111933477, 5.676950540809383]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.952816060000002, 4.014210223866954, 2.8384752704046914], [0.0, 0.0, 0.0], [1.7382040150000004, 1.0035525559667384, 2.8384752704046914], [5.214612045000001, 1.0035525559667384, 2.8384752704046914], [5.214612045000001, 3.010657667900215, 0.0], [1.7382040150000004, 3.010657667900215, 0.0], [3.476408030000001, 4.014210223866954, 2.8384752704046914], [3.47640803, 0.0, 0.0], [10.429224090000002, 6.02131533580043, 4.257712905607037], [3.476408030000001, 2.007105111933477, 1.4192376352023457]]'),('[''carolina_materials_3000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1924170301885722002) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1924170301885722002) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 8.0 in stage 0.0 (TID 8) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_532900385002343283'),('532900385002343283'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuBi6Cl2Zn'),('AuBi6Cl2Zn'),('A6B2CD'),('[''Au'', ''Bi'', ''Cl'', ''Zn'']'),('[0.1, 0.6, 0.2, 0.1]'),('[79, 83, 83, 83, 83, 83, 83, 17, 17, 30]'),('10'::int4),('4'::int4),('0'::int4),('[[7.78270575, 0.0, 0.0], [3.891352875000001, 6.740020889679222, 0.0], [3.891352875000001, 2.2466736298930745, 6.354552635241553]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.782705750000001, 4.493347259786148, 3.1772763176207763], [1.9456764375000004, 1.1233368149465373, 3.1772763176207763], [5.8370293125, 1.1233368149465373, 3.1772763176207763], [5.8370293125, 3.370010444839611, 0.0], [1.9456764375000004, 3.370010444839611, 0.0], [3.891352875000001, 4.493347259786148, 3.1772763176207763], [3.891352875, 0.0, 0.0], [11.674058625, 6.740020889679222, 4.765914476431164], [3.8913528750000004, 2.246673629893074, 1.5886381588103882], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_532900385002343283) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_532900385002343283) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 5.0 in stage 0.0 (TID 5) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_381203781975058546'),('381203781975058546'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Cs4Si24Tl4Y4'),('CsSi6TlY'),('A6BCD'),('[''Cs'', ''Si'', ''Tl'', ''Y'']'),('[0.1111111111111111, 0.6666666666666666, 0.1111111111111111, 0.1111111111111111]'),('[55, 55, 55, 55, 39, 39, 39, 39, 81, 81, 81, 81, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]'),('36'::int4),('4'::int4),('0'::int4),('[[11.39046649, 0.0, 0.0], [0.0, 11.39046649, 0.0], [0.0, 0.0, 11.39046649]]'),('[0, 0, 0]'),('[False, False, False]'),('[[2.8476166225, 2.8476166225, 8.5428498675], [2.8476166225, 8.5428498675, 2.8476166225], [8.5428498675, 2.8476166225, 2.8476166225], [8.5428498675, 8.5428498675, 8.5428498675], [2.8476166225, 2.8476166225, 2.8476166225], [2.8476166225, 8.5428498675, 8.5428498675], [8.5428498675, 2.8476166225, 8.5428498675], [8.5428498675, 8.5428498675, 2.8476166225], [0.0, 0.0, 0.0], [0.0, 5.695233245, 5.695233245], [5.695233245, 0.0, 5.695233245], [5.695233245, 5.695233245, 0.0], [5.4029841735074635, 2.8476166225, 2.8476166225], [2.8476166225, 2.8476166225, 0.2922490714925366], [0.2922490714925366, 2.8476166225, 2.8476166225], [2.8476166225, 2.8476166225, 5.4029841735074635], [2.8476166225, 5.4029841735074635, 2.8476166225], [2.8476166225, 0.2922490714925366, 2.8476166225], [5.4029841735074635, 8.5428498675, 8.5428498675], [2.8476166225, 8.5428498675, 5.987482316492536], [0.2922490714925366, 8.5428498675, 8.5428498675], [2.8476166225, 8.5428498675, 11.098217418507463], [2.8476166225, 11.098217418507463, 8.5428498675], [2.8476166225, 5.987482316492536, 8.5428498675], [11.098217418507463, 2.8476166225, 8.5428498675], [8.5428498675, 2.8476166225, 5.987482316492536], [5.987482316492536, 2.8476166225, 8.5428498675], [8.5428498675, 2.8476166225, 11.098217418507463], [8.5428498675, 5.4029841735074635, 8.5428498675], [8.5428498675, 0.2922490714925366, 8.5428498675], [11.098217418507463, 8.5428498675, 2.8476166225], [8.5428498675, 8.5428498675, 0.2922490714925366], [5.987482316492536, 8.5428498675, 2.8476166225], [8.5428498675, 8.5428498675, 5.4029841735074635], [8.5428498675, 11.098217418507463, 2.8476166225], [8.5428498675, 5.987482316492536, 2.8476166225]]'),('[''carolina_materials_625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_381203781975058546) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_381203781975058546) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 12.0 in stage 0.0 (TID 12) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1244094913989693186'),('1244094913989693186'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Au2InSb6Ti'),('Au2InSb6Ti'),('A6B2CD'),('[''Au'', ''In'', ''Sb'', ''Ti'']'),('[0.2, 0.1, 0.6, 0.1]'),('[79, 79, 49, 51, 51, 51, 51, 51, 51, 22]'),('10'::int4),('4'::int4),('0'::int4),('[[7.62370169, 0.0, 0.0], [3.811850845000001, 6.602319334414357, 0.0], [3.811850845000001, 2.200773111471453, 6.2247263638979256]]'),('[0, 0, 0]'),('[False, False, False]'),('[[11.435552535, 6.602319334414357, 4.668544772923444], [3.8118508450000004, 2.2007731114714524, 1.5561815909744814], [0.0, 0.0, 0.0], [1.9059254225000004, 1.1003865557357264, 3.1123631819489628], [5.717776267500001, 1.1003865557357264, 3.1123631819489628], [5.717776267500001, 3.3011596672071786, 0.0], [1.9059254225000004, 3.3011596672071786, 0.0], [3.811850845000001, 4.401546222942905, 3.1123631819489628], [3.811850845, 0.0, 0.0], [7.623701690000001, 4.401546222942905, 3.1123631819489628]]'),('[''carolina_materials_1500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1244094913989693186) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1244094913989693186) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_606536193855871962'),('606536193855871962'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('FeO6Pd2Tc'),('FeO6Pd2Tc'),('A6B2CD'),('[''Fe'', ''O'', ''Pd'', ''Tc'']'),('[0.1, 0.6, 0.2, 0.1]'),('[26, 8, 8, 8, 8, 8, 8, 46, 46, 43]'),('10'::int4),('4'::int4),('0'::int4),('[[5.5419642, 0.0, 0.0], [2.7709821000000003, 4.799481784063903, 0.0], [2.7709821000000003, 1.5998272613546347, 4.52499482092386]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.541964200000001, 3.1996545227092685, 2.26249741046193], [1.3854910500000002, 0.7999136306773174, 2.26249741046193], [4.15647315, 0.7999136306773174, 2.26249741046193], [4.15647315, 2.3997408920319514, 0.0], [1.3854910500000002, 2.3997408920319514, 0.0], [2.7709821000000003, 3.1996545227092685, 2.26249741046193], [2.7709821, 0.0, 0.0], [8.3129463, 4.799481784063903, 3.393746115692895], [2.7709821000000003, 1.5998272613546343, 1.131248705230965], [0.0, 0.0, 0.0]]'),('[''carolina_materials_500'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_606536193855871962) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_606536193855871962) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 3.0 in stage 0.0 (TID 3) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_477694363814657591'),('477694363814657591'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H24Pt4Rh4Te4'),('H6PtRhTe'),('A6BCD'),('[''H'', ''Pt'', ''Rh'', ''Te'']'),('[0.6666666666666666, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111]'),('[52, 52, 52, 52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 78, 78, 78, 78, 45, 45, 45, 45]'),('36'::int4),('4'::int4),('0'::int4),('[[6.98051536, 0.0, 0.0], [0.0, 6.98051536, 0.0], [0.0, 0.0, 6.98051536]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.74512884, 1.74512884, 5.2353865200000005], [1.74512884, 5.2353865200000005, 1.74512884], [5.2353865200000005, 1.74512884, 1.74512884], [5.2353865200000005, 5.2353865200000005, 5.2353865200000005], [3.49025768, 1.7238541837270207, 0.0], [0.0, 1.766403496272979, 0.0], [1.766403496272979, 0.0, 0.0], [5.214111863727021, 0.0, 0.0], [3.49025768, 0.0, 5.256661176272979], [3.49025768, 0.0, 1.7238541837270207], [3.49025768, 5.214111863727021, 3.49025768], [0.0, 5.256661176272979, 3.49025768], [1.766403496272979, 3.49025768, 3.49025768], [5.214111863727021, 3.49025768, 3.49025768], [3.49025768, 3.49025768, 1.766403496272979], [3.49025768, 3.49025768, 5.214111863727021], [0.0, 1.7238541837270207, 3.49025768], [3.49025768, 1.766403496272979, 3.49025768], [5.256661176272979, 0.0, 3.49025768], [1.7238541837270207, 0.0, 3.49025768], [0.0, 0.0, 1.766403496272979], [0.0, 0.0, 5.214111863727021], [0.0, 5.214111863727021, 0.0], [3.49025768, 5.256661176272979, 0.0], [5.256661176272979, 3.49025768, 0.0], [1.7238541837270207, 3.49025768, 0.0], [0.0, 3.49025768, 5.256661176272979], [0.0, 3.49025768, 1.7238541837270207], [3.49025768, 0.0, 0.0], [3.49025768, 3.49025768, 3.49025768], [0.0, 0.0, 3.49025768], [0.0, 3.49025768, 0.0], [1.74512884, 1.74512884, 1.74512884], [1.74512884, 5.2353865200000005, 5.2353865200000005], [5.2353865200000005, 1.74512884, 5.2353865200000005], [5.2353865200000005, 5.2353865200000005, 1.74512884]]'),('[''carolina_materials_375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_477694363814657591) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_477694363814657591) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 6.0 in stage 0.0 (TID 6) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1270460233791768030'),('1270460233791768030'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('C6BrLiRb2'),('BrC6LiRb2'),('A6B2CD'),('[''Br'', ''C'', ''Li'', ''Rb'']'),('[0.1, 0.6, 0.1, 0.2]'),('[35, 6, 6, 6, 6, 6, 6, 3, 37, 37]'),('10'::int4),('4'::int4),('0'::int4),('[[6.22002281, 0.0, 0.0], [3.1100114050000007, 5.386697765578668, 0.0], [3.1100114050000007, 1.7955659218595563, 5.078627357657466]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [6.220022810000001, 5.57274224019876, 3.940523827849255], [6.220022810000001, 1.6095214472394637, 1.1381035298082107], [7.93614775375473, 4.581937041958936, 1.1381035298082107], [4.503897866245271, 2.6003266454792877, 3.940523827849255], [7.93614775375473, 2.6003266454792877, 3.940523827849255], [4.503897866245271, 4.581937041958936, 1.1381035298082107], [6.2200228100000015, 3.591131843719112, 2.539313678828733], [9.330034215000001, 5.386697765578669, 3.8089705182430995], [3.1100114050000007, 1.795565921859556, 1.2696568394143666]]'),('[''carolina_materials_750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1270460233791768030) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1270460233791768030) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 17.0 in stage 0.0 (TID 17) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2054710369908306893'),('2054710369908306893'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('IrSc2Ta6Zr'),('IrSc2Ta6Zr'),('A6B2CD'),('[''Ir'', ''Sc'', ''Ta'', ''Zr'']'),('[0.1, 0.2, 0.6, 0.1]'),('[77, 21, 21, 73, 73, 73, 73, 73, 73, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.94830574, 0.0, 0.0], [3.474152868381627, 6.017408442104194, 0.0], [3.4741521416183603, 2.005802953900427, 5.673267481707873]]'),('[0, 0, 0]'),('[False, False, False]'),('[[6.948305374999994, 4.0116056980023105, 2.8366337408539364], [10.42245806249999, 6.017408547003465, 4.254950611280904], [3.474152687499997, 2.0058028490011552, 1.4183168704269682], [6.948305194190722, 5.998826227785521, 4.241810926664545], [6.948305555809266, 2.0243851682190996, 1.4314565550433274], [8.669289227532333, 5.005215910930189, 1.4314565550433274], [5.227321522467654, 3.017995485074433, 4.241810926664545], [8.66928886751717, 3.017995485074433, 4.241810926664545], [5.227321882482817, 5.005215910930189, 1.4314565550433274], [0.0, 0.0, 0.0]]'),('[''carolina_materials_2125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2054710369908306893) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_2054710369908306893) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 30.0 in stage 0.0 (TID 30) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_631649292482264830'),('631649292482264830'),('2024-05-14 18:12:57-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ca2N6NiSn'),('Ca2N6NiSn'),('A6B2CD'),('[''Ca'', ''N'', ''Ni'', ''Sn'']'),('[0.2, 0.6, 0.1, 0.1]'),('[20, 20, 7, 7, 7, 7, 7, 7, 28, 50]'),('10'::int4),('4'::int4),('0'::int4),('[[5.62397912, 0.0, 0.0], [2.8119895600000007, 4.870508788273252, 0.0], [2.8119895600000007, 1.6235029294244177, 4.591959722688921]]'),('[0, 0, 0]'),('[False, False, False]'),('[[8.435968680000002, 4.870508788273252, 3.443969792016691], [2.8119895600000007, 1.6235029294244174, 1.1479899306722303], [5.62397912, 4.791701813055124, 3.3882448454351524], [5.62397912, 1.7023099046425454, 1.203714877253769], [6.961725057465691, 4.019353835951979, 1.203714877253769], [4.2862331825343105, 2.4746578817456903, 3.3882448454351524], [6.961725057465691, 2.4746578817456903, 3.3882448454351524], [4.2862331825343105, 4.019353835951979, 1.203714877253769], [5.623979120000001, 3.247005858848835, 2.2959798613444606], [0.0, 0.0, 0.0]]'),('[''carolina_materials_3750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_631649292482264830) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_631649292482264830) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 15.0 in stage 0.0 (TID 15) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_879064004920091671'),('879064004920091671'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BiGe6Nb2Pd'),('BiGe6Nb2Pd'),('A6B2CD'),('[''Bi'', ''Ge'', ''Nb'', ''Pd'']'),('[0.1, 0.6, 0.2, 0.1]'),('[83, 32, 32, 32, 32, 32, 32, 41, 41, 46]'),('10'::int4),('4'::int4),('0'::int4),('[[7.10760297, 0.0, 0.0], [3.553801485000001, 6.155364732033726, 0.0], [3.553801485000001, 2.051788244011242, 5.80333352359675]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.107602970000001, 4.103576488022484, 2.901666761798375], [7.107602970000002, 6.270664479976759, 4.434029376337181], [7.10760297, 1.9364884960682087, 1.369304147259569], [8.98435622326861, 5.187120483999621, 1.369304147259569], [5.230849716731392, 3.0200324920453463, 4.434029376337181], [8.98435622326861, 3.0200324920453463, 4.434029376337181], [5.230849716731392, 5.187120483999621, 1.369304147259569], [10.661404455000001, 6.155364732033726, 4.352500142697563], [3.5538014850000006, 2.051788244011242, 1.4508333808991876], [0.0, 0.0, 0.0]]'),('[''carolina_materials_1875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_879064004920091671) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_879064004920091671) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 14.0 in stage 0.0 (TID 14) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_500162048421940762'),('500162048421940762'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AgGeO6Re2'),('AgGeO6Re2'),('A6B2CD'),('[''Ag'', ''Ge'', ''O'', ''Re'']'),('[0.1, 0.1, 0.6, 0.2]'),('[47, 32, 8, 8, 8, 8, 8, 8, 75, 75]'),('10'::int4),('4'::int4),('0'::int4),('[[5.51715877, 0.0, 0.0], [2.7585793850000004, 4.777999651532107, 0.0], [2.7585793850000004, 1.5926665505107025, 4.504741272140418]]'),('[0, 0, 0]'),('[False, False, False]'),('[[5.517158770000001, 3.1853331010214045, 2.252370636070209], [0.0, 0.0, 0.0], [5.51715877, 4.870971688831493, 3.444297112140438], [5.517158770000001, 1.499694513211316, 1.0604441599999799], [6.976964608642864, 4.028152394926448, 1.0604441599999799], [4.057352931357137, 2.3425138071163603, 3.444297112140438], [6.976964608642864, 2.3425138071163603, 3.444297112140438], [4.057352931357137, 4.028152394926448, 1.0604441599999799], [8.275738155, 4.777999651532107, 3.3785559541053134], [2.7585793850000004, 1.5926665505107023, 1.1261853180351045]]'),('[''carolina_materials_1750'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_500162048421940762) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_500162048421940762) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 19.0 in stage 0.0 (TID 19) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_267228750714462887'),('267228750714462887'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('AuGa6Tc2Zr'),('AuGa6Tc2Zr'),('A6B2CD'),('[''Au'', ''Ga'', ''Tc'', ''Zr'']'),('[0.1, 0.6, 0.2, 0.1]'),('[79, 31, 31, 31, 31, 31, 31, 43, 43, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.93008826, 0.0, 0.0], [3.4650441300000008, 6.001632483628297, 0.0], [3.4650441300000008, 2.000544161209433, 5.658393369817373]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [6.930088260000001, 6.046923283024517, 4.275820458741457], [6.930088260000001, 1.9552533618132135, 1.3825729110759173], [8.70183330783483, 5.024005802721691, 1.3825729110759173], [5.15834321216517, 2.9781708421160396, 4.275820458741457], [8.701833307834832, 2.9781708421160396, 4.275820458741457], [5.15834321216517, 5.024005802721691, 1.3825729110759173], [10.39513239, 6.001632483628297, 4.24379502736303], [3.4650441300000003, 2.0005441612094326, 1.4145983424543433], [6.930088260000001, 4.001088322418865, 2.8291966849086867]]'),('[''carolina_materials_2375'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_267228750714462887) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_267228750714462887) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 1.0 in stage 0.0 (TID 1) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1111065732538864085'),('1111065732538864085'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ir6NaSi2Tl'),('Ir6NaSi2Tl'),('A6B2CD'),('[''Ir'', ''Na'', ''Si'', ''Tl'']'),('[0.6, 0.1, 0.2, 0.1]'),('[77, 77, 77, 77, 77, 77, 11, 14, 14, 81]'),('10'::int4),('4'::int4),('0'::int4),('[[6.34298013, 0.0, 0.0], [3.171490065000001, 5.49318192827992, 0.0], [3.171490065000001, 1.831060642759974, 5.179021589037503]]'),('[0, 0, 0]'),('[False, False, False]'),('[[1.5857450325000004, 0.915530321379987, 2.5895107945187514], [4.757235097500001, 0.915530321379987, 2.5895107945187514], [4.757235097500001, 2.74659096413996, 0.0], [1.5857450325000004, 2.74659096413996, 0.0], [3.171490065000001, 3.662121285519947, 2.5895107945187514], [3.171490065, 0.0, 0.0], [0.0, 0.0, 0.0], [9.514470195000001, 5.49318192827992, 3.884266191778127], [3.1714900650000004, 1.8310606427599736, 1.2947553972593757], [6.342980130000001, 3.662121285519947, 2.5895107945187514]]'),('[''carolina_materials_125'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1111065732538864085) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1111065732538864085) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 7.0 in stage 0.0 (TID 7) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_229347831182344167'),('229347831182344167'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('BaGe2RhSe6'),('BaGe2RhSe6'),('A6B2CD'),('[''Ba'', ''Ge'', ''Rh'', ''Se'']'),('[0.1, 0.2, 0.1, 0.6]'),('[56, 32, 32, 45, 34, 34, 34, 34, 34, 34]'),('10'::int4),('4'::int4),('0'::int4),('[[7.13503554, 0.0, 0.0], [3.5675177700000007, 6.17912203454482, 0.0], [3.5675177700000007, 2.0597073448482734, 5.8257321232078105]]'),('[0, 0, 0]'),('[False, False, False]'),('[[7.1350355400000005, 4.119414689696547, 2.9128660616039053], [10.702553309999999, 6.179122034544821, 4.369299092405858], [3.5675177700000003, 2.0597073448482734, 1.4564330308019526], [0.0, 0.0, 0.0], [1.7837588850000003, 1.0298536724241367, 2.9128660616039053], [5.351276655, 1.0298536724241367, 2.9128660616039053], [5.351276655, 3.08956101727241, 0.0], [1.7837588850000003, 3.08956101727241, 0.0], [3.5675177700000007, 4.119414689696547, 2.9128660616039053], [3.56751777, 0.0, 0.0]]'),('[''carolina_materials_875'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_229347831182344167) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_229347831182344167) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 16.0 in stage 0.0 (TID 16) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_1057937176403445841'),('1057937176403445841'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Al2F6PbZr'),('Al2F6PbZr'),('A6B2CD'),('[''Al'', ''F'', ''Pb'', ''Zr'']'),('[0.2, 0.6, 0.1, 0.1]'),('[13, 13, 9, 9, 9, 9, 9, 9, 82, 40]'),('10'::int4),('4'::int4),('0'::int4),('[[6.67126287, 0.0, 0.0], [3.3356314350000007, 5.777483120743883, 0.0], [3.3356314350000007, 1.925827706914628, 5.447063323825088]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.006894305000001, 5.7774831207438835, 4.085297492868816], [3.335631435, 1.9258277069146277, 1.361765830956272], [6.671262870000001, 5.525218179084053, 3.906919241965521], [6.6712628700000005, 2.1780926485744576, 1.5401440818595662], [8.120610739538389, 4.688436796456655, 1.5401440818595662], [5.221915000461613, 3.0148740312018565, 3.906919241965521], [8.120610739538389, 3.0148740312018565, 3.906919241965521], [5.221915000461613, 4.688436796456655, 1.5401440818595662], [0.0, 0.0, 0.0], [6.67126287, 3.8516554138292554, 2.723531661912544]]'),('[''carolina_materials_2000'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1057937176403445841) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_1057937176403445841) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "24/05/14 18:13:01 WARN TaskSetManager: Lost task 21.0 in stage 0.0 (TID 21) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_71400504959801900'),('71400504959801900'),('2024-05-14 18:12:56-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('Ga2IrPtW6'),('Ga2IrPtW6'),('A6B2CD'),('[''Ga'', ''Ir'', ''Pt'', ''W'']'),('[0.2, 0.1, 0.1, 0.6]'),('[31, 31, 77, 78, 74, 74, 74, 74, 74, 74]'),('10'::int4),('4'::int4),('0'::int4),('[[6.76833052, 0.0, 0.0], [3.3841652618080778, 5.86154537374226, 0.0], [3.38416456819191, 1.953848591400618, 5.526318353564524]]'),('[0, 0, 0]'),('[False, False, False]'),('[[10.152495262499992, 5.861545473857158, 4.144738765173393], [3.384165087499997, 1.9538484912857195, 1.381579588391131], [6.768330174999994, 3.907696982571439, 2.763159176782262], [0.0, 0.0, 0.0], [6.768330004844791, 5.834986733161172, 4.125958898565209], [6.768330345155198, 1.9804072319817059, 1.4003594549993152], [8.437412429174053, 4.871341808489289, 1.4003594549993152], [5.099247920825936, 2.944052156653589, 4.125958898565209], [8.437412087080146, 2.944052156653589, 4.125958898565209], [5.0992482629198435, 4.871341808489289, 1.4003594549993152]]'),('[''carolina_materials_2625'']'),('[5, ''fcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_71400504959801900) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n",
      "  Detail: Key (id)=(CO_71400504959801900) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n",
      "\t... 21 more\n",
      "\n",
      "Loading data to PostgreSQL: : 0batch [00:05, ?batch/s]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o46.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n\t... 21 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1037)\n\tat org.apache.spark.sql.Dataset.$anonfun$foreachPartition$1(Dataset.scala:3514)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:4309)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:4307)\n\tat org.apache.spark.sql.Dataset.foreachPartition(Dataset.scala:3514)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n\t... 21 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_to_pg_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/colabfit-tools/colabfit/tools/database.py:266\u001b[0m, in \u001b[0;36mDataManager.load_data_to_pg_in_batches\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mco_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     loader\u001b[38;5;241m.\u001b[39mwrite_table(\n\u001b[1;32m    272\u001b[0m         po_rows,\n\u001b[1;32m    273\u001b[0m         loader\u001b[38;5;241m.\u001b[39mprop_object_table,\n\u001b[1;32m    274\u001b[0m         property_object_schema,\n\u001b[1;32m    275\u001b[0m     )\n",
      "File \u001b[0;32m~/colabfit-tools/colabfit/tools/database.py:117\u001b[0m, in \u001b[0;36mPGDataLoader.write_table\u001b[0;34m(self, spark_rows, table_name, schema)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, spark_rows: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m], table_name: \u001b[38;5;28mstr\u001b[39m, schema: StructType):\n\u001b[1;32m    115\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mcreateDataFrame(spark_rows, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:1984\u001b[0m, in \u001b[0;36mDataFrameWriter.jdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[1;32m   1983\u001b[0m     jprop\u001b[38;5;241m.\u001b[39msetProperty(k, properties[k])\n\u001b[0;32m-> 1984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjprop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o46.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (mart4.physics.nyu.edu executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n\t... 21 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1037)\n\tat org.apache.spark.sql.Dataset.$anonfun$foreachPartition$1(Dataset.scala:3514)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.Dataset.$anonfun$withNewRDDExecutionId$1(Dataset.scala:4309)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:4307)\n\tat org.apache.spark.sql.Dataset.foreachPartition(Dataset.scala:3514)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO configurations (\"id\",\"hash\",\"last_modified\",\"dataset_ids\",\"metadata\",\"chemical_formula_hill\",\"chemical_formula_reduced\",\"chemical_formula_anonymous\",\"elements\",\"elements_ratios\",\"atomic_numbers\",\"nsites\",\"nelements\",\"nperiodic_dimensions\",\"cell\",\"dimension_types\",\"pbc\",\"positions\",\"names\",\"labels\",\"configuration_set_ids\") VALUES (('CO_2035392092515548233'),('2035392092515548233'),('2024-05-14 18:12:55-04'::timestamp),('[''DS_y7nrdsjtuw0g_0'']'),(NULL),('H6BrCaRh2'),('BrCaH6Rh2'),('A6B2CD'),('[''Br'', ''Ca'', ''H'', ''Rh'']'),('[0.1, 0.1, 0.6, 0.2]'),('[35, 20, 1, 1, 1, 1, 1, 1, 45, 45]'),('10'::int4),('4'::int4),('0'::int4),('[[5.39874426, 0.0, 0.0], [2.6993721300000004, 4.67544967769542, 0.0], [2.6993721300000004, 1.5584832258984738, 4.4080562295931855]]'),('[0, 0, 0]'),('[False, False, False]'),('[[0.0, 0.0, 0.0], [5.398744260000001, 3.116966451796947, 2.2040281147965928], [5.398744260000001, 4.84493341938597, 3.4258852752451454], [5.39874426, 1.3889994842079243, 0.9821709543480398], [6.895207550832455, 3.980949935591458, 0.9821709543480398], [3.902280969167545, 2.252982968002436, 3.4258852752451454], [6.895207550832455, 2.252982968002436, 3.4258852752451454], [3.902280969167545, 3.980949935591458, 0.9821709543480398], [8.098116390000001, 4.67544967769542, 3.306042172194889], [2.6993721300000004, 1.5584832258984735, 1.1020140573982964]]'),('[''carolina_materials_0'']'),('[0, ''bcc'']'),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:751)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1039)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1039)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"idkey\"\n  Detail: Key (id)=(CO_2035392092515548233) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n\t... 21 more\n"
     ]
    }
   ],
   "source": [
    "dm.load_data_to_pg_in_batches(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(\n",
    "    dbname=\"colabfit\",\n",
    "    user=os.environ.get(\"PGS_USER\"),\n",
    "    password=os.environ.get(\"PGS_PASS\"),\n",
    "    host=\"localhost\",\n",
    ") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        # cur.execute(\n",
    "        #     \"UPDATE configurations SET configuration_set_ids = configuration_set_ids || %(cs_id)s WHERE id = ANY(%(co_ids)s)\",\n",
    "        #     {\"cs_id\": cs[\"id\"], \"co_ids\": co_ids},\n",
    "        # )\n",
    "        # data = cur.fetchall()\n",
    "        cur.execute(\n",
    "            \"SELECT * FROM public.configurations WHERE id = ANY(%s)\",\n",
    "            [co_ids],\n",
    "        )\n",
    "        data2 = cur.fetchall()\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ids.append(\"CO_215290934057753943\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm2.load_data_to_pg_in_batches(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsert appears to be this for postgres:\n",
    "```\n",
    "update the_table\n",
    "    set id = id || array[5,6]\n",
    "where id = 4;\n",
    "```\n",
    "* ~~Check for upsert function from pyspark to concatenate lists of relationships instead of primary key id collision~~\n",
    "* There is no pyspark-upsert function. Will have to manage this possibly through a different sql-based library\n",
    "* Written: find duplicates, but convert to access database, not download full dataframe\n",
    "* I see this being used with batches of hashes during upload: something like\n",
    "    ``` for batch in batches:\n",
    "            hash_duplicates = find_duplicates(batch, loader/database)\n",
    "            hash_duplicates.make_change_to_append_dataset-ids\n",
    "            hash_duplicates.write-to-database\n",
    "* Where would be the best place to catch duplicates? Keeping in mind that this might be a bulk operation (i.e. on the order of millions, like with ANI1/ANI2x variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JARFILE = os.environ.get(\"CLASSPATH\")\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgreSQL Connection with PySpark\")\n",
    "    .config(\"spark.jars\", JARFILE)\n",
    "    .getOrCreate()\n",
    ")\n",
    "url = \"jdbc:postgresql://localhost:5432/colabfit\"\n",
    "user = os.environ.get(\"PGS_USER\")\n",
    "password = os.environ.get(\"PGS_PASS\")\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "loader = PGDataLoader(appname=\"colabfit\", env=\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carmat_ds_id = \"DS_y7nrdsjtuw0g_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import colabfit.tools.dataset\n",
    "import colabfit.tools.database\n",
    "\n",
    "reload(colabfit.tools.dataset)\n",
    "reload(colabfit.tools.database)\n",
    "DataManager = colabfit.tools.database.DataManager\n",
    "\n",
    "Dataset = colabfit.tools.dataset.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_hash(spark_rows: dict, loader):\n",
    "    # hashes = loader.spark.createDataFrame([x[\"hash\"] for x in spark_rows])\n",
    "    hashes = [x[\"hash\"] for x in spark_rows]\n",
    "    duplicates = loader.spark.read.jdbc(\n",
    "        url=url,\n",
    "        table=\"configurations\",\n",
    "        properties=properties,\n",
    "    ).filter(sf.col(\"hash\").isin(hashes))\n",
    "    # dupl_hashes = df.filter(df.hash.isin(hashes)).select(\"hash\").collect()\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_rows = [x.spark_row for x in dm_dup.configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = (\n",
    "    loader.spark.read.jdbc(\n",
    "        url=loader.url, table=loader.config_table, properties=loader.properties\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"ds_ids_unstrung\",\n",
    "        sf.from_json(sf.col(\"dataset_ids\"), sf.ArrayType(sf.StringType())),\n",
    "    )\n",
    "    .filter(sf.array_contains(\"ds_ids_unstrung\", dm.dataset_id))\n",
    "    .drop(\"ds_ids_unstrung\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes = find_duplicate_hash(dupl_rows, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_hashes.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[\"hash\"] for x in dup_hashes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can we make the configuration and the property instance/data object at the same time?\n",
    "In this way, we would only have to pass through the data one time.\n",
    "\n",
    "Workflow:\n",
    "create database access object\n",
    "create data reader as function? of the database access object\n",
    "reader returns ase.Atoms-style objects (AtomicConfiguration)\n",
    "DOs and PIs are now one object\n",
    "These DOs point to a configuration\n",
    "The configuration may already exist in the database, so we keep track of the hash added to the DO\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = json.load(Path(\"sample_db/co_ds1.json\").open(\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"sample_db/co_ds1.json\"), \"r\") as f:\n",
    "    co_json = spark.sparkContext.parallelize(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = co_json.map(_parse_config).map(stringify_lists)\n",
    "co_df = spark.createDataFrame(co, config_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_configs(co_path, spark):\n",
    "    with open(co_path, \"r\") as f:\n",
    "        co_json = spark.sparkContext.parallelize(json.load(f))\n",
    "    co = co_json.map(_parse_config).map(stringify_lists)\n",
    "    co_df = spark.createDataFrame(co, config_schema)\n",
    "    return co_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_configs(\"sample_db/co_ds1.json\", spark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
